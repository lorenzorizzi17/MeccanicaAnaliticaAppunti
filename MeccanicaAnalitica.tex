\documentclass[a4paper,openany]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{float}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
\usepackage{subfigure}
\usepackage{textcomp}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{pgfkeys}
\usepackage{amssymb}
\usepackage{tcolorbox}
\tikzstyle{mybox} = [draw=black, very thick, rectangle, rounded corners, inner ysep=5pt, inner xsep=5pt]
\usepackage{geometry}
\geometry{a4paper, right=3cm, left=3cm,bottom=4cm}
\makeglossary
\title{Appunti dal corso di Meccanica Analitica }
\author{Lorenzo Rizzi
\\
Se volete offrirmi un caffè e farmi felice, \url{https://www.paypal.me/lorenzorizzi17} :)  }
\date{A.A. 2022/2023 }
\begin{document}
	\newpage
	\maketitle
	\newpage
	\tableofcontents
	\section{Introduzione alla meccanica analitica}
	\subsection{I Principi di Newton}
	La meccanica classica, intesa come studio dei fenomeni fisici non quantistici e non relativistici di natura dinamica, è stata studiata in maniera approfondita da Newton nel diciassettesimo secolo, il quale ha posto a fondamento della sua teoria alcuni principi. Li riprendiamo, per completezza e perché costituiscono una base assiomatica della meccanica classica:
	\begin{itemize}
		\item  Primo principio della dinamica: esiste un insieme di sistemi di riferimento, detti \textit{inerziali}, nei quali le leggi della meccanica classica sono covarianti e, dunque, non c'è modo di distinguere fra di essi. In tali sistemi di riferimento, lo spazio è assoluto, omogeneo e isotropo e il tempo è assoluto.
		\item Secondo principio della dinamica: in tali sistemi di riferimento, vige la relazione:
		$$
		\vec{F} = m\vec{a}
		$$
		dove $\vec{F}$ è un vettore, detto \textit{forza}, che riassume le proprietà di interazione fra corpi
		\item Terzo principio della dinamica: se un corpo $A$ esprime una forza $\vec{F}$ su di un corpo $B$, allora il corpo $B$ esprime una forza $-\vec{F}$ sul corpo $A$
	\end{itemize}
	La meccanica analitica si occupa di generalizzare ulteriormente le intuizioni di Newton fornendo strumenti e metodi spesso più efficaci.
	Partiamo allora dal secondo principio della dinamica, il cuore pulsante di tutta la meccanica. Tale affermazione, di origine ovviamente sperimentale, stabilisce in primis l'esistenza di una entità fisica, detta \textit{forza} e ci dà alcune informazioni sulla sua natura:
	\begin{itemize}
		\item La forza $\vec{F}$ non può dipendere dall'accelerazione poiché viene essa stessa determinata dall'accelerazione. 
		\item La forza $\vec{F}$ è un vettore e ne eredita le proprietà e le operazioni ammissibili. Tale legge è dunque di natura vettoriale e non dipende dalle coordinate che vengono impiegate nella descrizione del fenomeno. Non solo: poiché le leggi della meccanica devono esser covarianti, allora la forza è un vettore in senso fisico (cioè covaria per trasformazioni galileiane)	
	\end{itemize}
	
	In generale, perciò, l'equazione di Newton è un'equazione differenziale del secondo ordine:
	\begin{equation}
		\vec{F}(\vec{x},\vec{v},t) = m\dfrac{d^{2}}{dt^{2}}\vec{x}(t)
		\label{NewtonEquation}
	\end{equation}
	L'equazione differenziale (\ref{NewtonEquation}) è alla base del modello newtoniano della meccanica classica e consente di fare predizioni e validare la teoria\footnote{Questa è una parte fondamentale del processo scientifico-fisico. Devo sempre confrontarmi coi dati sperimentali}. 
	
	Quando Newton per primo lavorò con tale modello, la forza considerarata era quella gravitazionale per cui Newton stesso scoprì che:
	\begin{equation}
		\vec{F} = -\dfrac{G m_{1}m_{2}}{r^{2}}\hat{r}
		\label{GravitationLaw}
	\end{equation} 
	Sostituendo questa espressione della forza nella (\ref{NewtonEquation}), Newton era in grado di ricavare in maniera abbastanza agile un'equazione analitica per la traiettoria $\vec{x}(t)$ e poteva caratterizzare l'evoluzione futura dei sistemi meccanici gravitativi. A questo punto, per Newton fu un gioco da ragazzi dimostrare la validità analitica delle tre leggi di Keplero, formulate su pure basi sperimentali qualche tempo prima dal fisico tedesco. La teoria coincideva perfettamente con le osservazioni.
	
	In realtà Newton fu molto fortunato: finché ci sono solo 2 corpi, il problema della gravitazione è uno dei pochi casi in cui l'equazione (\ref{NewtonEquation}) si può risolvere facilmente a mano e tramite funzioni elementari (polinomiali, logaritmiche, trigonometriche, ...). Se vivessimo, ad esempio, in un sistema  binario di stelle, la soluzione generale del moto della Terra sarebbe stato molto più complicata rispetto a quella reale e Newton non sarebbe stato in grado di isolarne la forma (Poincaré dimostrerà che tale problema è analiticamente insolubile). Riassumendo, cioè, \textit{l'equazione di Newton non è poi così facile da risolvere analiticamente}.
	
	Tuttavia, possiamo caratterizzare alcune proprietà delle soluzioni dell'equazione di Newton anche senza svolgere propriamente i conti grazie ai teoremi matematici di esistenza ed unicità. Infatti, date delle condizioni iniziali per il moto di un punto materiale:
	$$
	\vec{x}(0) = \vec{x}_{0}, \mbox{      }
	\vec{v}(0) = \vec{v}_{0}
	$$
	allora l'equazione differenziale (\ref{NewtonEquation}) ammette un'unica soluzione. Si tratta del cosiddetto \textit{determinismo classico}.
	
	Sorge però, a questo punto, un altro problema, su cui non ci soffermeremo più di tanto. I valori iniziali di posizione e velocità, nella teoria dell'analisi matematica che ci permette di risolvere il problema di Cauchy, sono rappresentati matematicamente da numeri reali. Ad ogni modo, è impossibile misurare con infinita precisione un numero reale e quello a cui possiamo ambire è, al massimo, un intervallo di valori in cui confidiamo si trovino le quantità iniziali di posizione e di velocità. Questa semplice considerazione porta con sè molte problematiche, in primis l'impossibilità per alcuni sistemi di essere completamente predicibili (quella piccole incertezza iniziale evolve nel tempo amplificandosi a dismisura). Il determinismo classico, cioè, funzione sulla carta. 
	
	Non è banale assumere di avere sempre a disposizione dei valori iniziali con arbitraria precisione: d'ora in poi, però, faremo finta di poter accedere ad una rappresentazione in numeri reali delle grandezze fisiche e ignoreremo il problema della predicibilità dei sistemi meccanici. Le grandezze meccaniche, cioè, saranno note con una precisione arbitraria.
	\subsection{Lo spazio delle fasi}
	Un concetto molto potente e di fondamentale importanza per tutta la trattazione che segue è quello di \textit{spazio delle fasi}. Si tratta di un'entità geometrica molto astratta, uno spazio vettoriale in cui ogni punto definisce in maniera univoca lo stato del sistema ad un dato istante temporale. Questa definizione si adatta anche a sistemi non prettamente fisici. Lo spazio delle fasi esiste ogni volta che posso determinare in maniera univoca delle coordinate che descrivano lo stato del sistema, qualunque esso sia, non per forza di natura fisica. Ad esempio, un sistema può essere rappresentato da una popolazione di due specie animali e lo spazio delle fasi associato, isomorfo a $\mathbb{R}^{2}$, viene identificato dalle coordinate che definiscono il numero di animali per ogni specie. Se però consideriamo sistemi dinamici, propri della fisica, allora possiamo considerare la coppia di grandezze posizione-impulso $(\vec{x},\vec{p})$: una volta note queste $6$ informazioni scalare, io conosco tutto quello che c'è da conoscere sul sistema stesso e ne posso caratterizzare perfettamente l'evoluzione futura senza incorrere in ambiguità (infatti, usando l'equazione di Newton, a partire dallo stato iniziale posso ricavare tutti gli stati futuri e passati). Poiché l'equazione di Newton è del secondo ordine, in genere ho bisogno di due quantità iniziali, così che non sarebbe possibile risolvere l'equazione conoscendo solo la posizione di un oggetto (è fermo? Si sta muovendo? Mi mancano informazioni vitali).\footnote{Perché l'impulso e non, per esempio, la velocità? Al momento, non c'è ragione di preferire l'uno all'altro, visto che i due sono collegate da una semplice relazione di proporzionalità tramite la massa, $\vec{p} = m\vec{v}$. Vedremo più avanti, però, che è preferibile utilizzare l'impulso $p$}
	In generale, perciò, lo spazio delle fasi di un sistema dinamico è uno spazio vettoriale di dimensione pari $2n = 2\cdot dof$ formato dal sottospazio delle coordinate e dal sottospazio dei loro momenti (sinonimi, in qualche modo, delle componenti della quantità di moto). In una situazione unidimensionale a $1$ grado di libertà, possiamo rappresentare graficamente lo spazio delle fasi tramite un piano cartesiano di coordinate $(x,p)$, con $p = m\dot{x}$. La generica evoluzione dinamica del sistema $\vec{x}(t)$ può essere facilmente rappresentata dalla traiettoria tracciata nello spazio delle fasi\footnote{Useremo in maniera molto confusionaria la variabile $x$ sia per indicare la posizione sia per indicare il generico vettore che vive nello spazio delle fasi}:
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (0,0) -- (3,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,3) node[above] {$p$};
			\draw[fill= black] (2,1) circle (1.5pt) node[anchor = north west]{$x_{0}$};
			\draw[->] (2,1) .. controls (1.5,1.5) .. (1,1.8) node[anchor = south east]{$x(t)$};
		}
		\caption{\textit{Il punto $\vec{x}_{0} \in \Gamma$ rappresenta lo stato iniziale. L'evoluzione dinamica del sistema può essere raffigurata tramite una traiettoria $\vec{x}(t)$ nello spazio delle fasi, che a sua volte ha una componente spaziale e una componente di momenti. Lo spazio delle fasi assomiglia, almeno concettualmente, al piano di Clapeyron tipico della termodinamica, col quale si rappresentava in maniera biunivoca ogni possibile stato di un sistema attraverso alcune coordinate termodinamiche macroscopiche.}}
	\end{figure}
	
	Lo spazio delle fasi è molto comodo per comprendere la naturale evoluzione nel tempo di un sistema dinamico. Sappiamo, infatti, che ai fini della risoluzione dell'equazione di Newton, sono sufficienti e necessari le informazioni su posizione e momento iniziale. Dunque, scelto un punto nello spazio delle fasi, che costituisce il mio stato iniziale, questo modifica la propria configurazione (cambia posizione/velocità) e tale variazione è univocamente definita per i teoremi di esistenza ed unicità.
	
	Posso allora tracciare, nello spazio delle fasi, tutte le possibili traiettorie di un sistema dinamico, così da ottenere una rappresentazione visiva di tutte le evoluzioni dinamiche del sistema, da qualsiasi punto iniziale dello spazio stesso.
	La geometria dello spazio delle fasi è fortemente influenzata dal \textit{teorema di unicità ed esistenza}. Questo ci dice che, data un'equazione differenziale del secondo ordine di cui conosco le due condizioni iniziali, la soluzione esiste ed è unica. Tradotto in termini geometrici, questa considerazione vieta alcune traiettorie possibili che vivono nello spazio delle fasi: non può infatti essere che in dato punto $x$ passino due diverse traiettorie. Se infatti $x$ fosse il punto iniziale, ci sarebbero due differenti evoluzioni ammissibili, ma questo è vietato dal teorema matematico. In altre parole, lo spazio delle fasi deve essere tassellato da curve (che rappresentazione le evoluzioni temporali) che non si intersecano mai.
	%DISEGNO%
	\subsection{Flusso di fase}
	Definiamo ora il \textit{flusso di fase} $\phi$. Come suggerisce il nome, si tratta di un concetto astratto che ci permette di capire come "fluisce" nel tempo lo stato del sistema, come evolve. Se $x_{0}$ è il generico stato iniziale del sistema, possiamo scrivere che lo stato del sistema $x(t)$ al tempo $t$ è:
	$$
	x(t) = \phi^{t}(x_{0})
	$$
	Questa uguaglianza fornisce la definizione di \textit{flusso di fase}, una sorta di trasformazione nello spazio delle fasi che corrisponde, a livello fisico, alla sequenza di stati in cui il sistema dinamico si porta. Il termine $\phi^{t}$ è dunque una trasformazione parametrizzata al tempo che agisce sugli stati del sistema e ne fornisce l'evoluzione temporale.
	In un certo senso, il flusso di fase è un propagatore nel tempo del sistema: applicando $\phi^{t}$ al generico stato iniziale $(x_{0},p_{0})$ punto dello spazio delle fasi, otteniamo lo stato in cui si trova il sistema al tempo $t$.
	\begin{equation}
		\begin{pmatrix}
			x(t) \\
			p(t)
		\end{pmatrix} 
		=
		\phi^{t}
		\begin{pmatrix}
			x_{0} \\
			p_{0}
		\end{pmatrix}
	\end{equation}
	Il flusso di fase riassume in sè due diversi aspetti. Fissando un certo tempo $t=t_{0}$, il flusso $\phi^{t_{0}}$ è funzione di $x_{0}$ e restituisce lo stato evoluto del sistema dopo $t_{0}$ unità di tempo dall'origine temporale. In questo caso, $\phi^{t_{0}}$ può essere interpretata come una trasformazione dello spazio delle fasi in se stesso (endomorfismo differenziabile) e la variabile è $x_{0}$ (ossia quale stato iniziale scelgo).
	$$
	\phi^{t_0} : \mathbb{R}^{2}\rightarrow\mathbb{R}^{2}
	$$
	Alternativamente, fissando un $x_{0}$, la funzione $\phi^{t}(x_{0})$ dipende unicamente dal tempo e descrive l'evoluzione del sistema a partire dalla configurazione iniziale $x_{0}$, tracciando una curva nello spazio delle fasi.
	\subsubsection{Proprietà del flusso di fase}
	Matematicamente il flusso di fase è dunque una trasformazione dello spazio delle fasi in se stesso che gode di alcune proprietà di regolarità (differenziabilità, invertibilità) ma non solo. Infatti dovrà valere che:
	\begin{equation}
		\phi^{0} = I
	\end{equation}
	ossia il flusso di fase valutato nell'istante iniziale deve restituire l'operatore identità. Questo è ovvio considerata l'interpretazione del flusso di fase. Quando $t=0$, il sistema si trova ancora nelle condizioni iniziali e perciò il flusso in $t=0$ dovrà trasformare qualsiasi vettore $x_{0}$ in se stesso. Inoltre, deve valere la composizione temporale: lo stato del sistema valutato al tempo $t+s$ deve essere uguale allo stato del sistema dopo $s$ unità di tempo dallo stato in $t$, cioè:
	\begin{equation}
		\phi^{t+s} = \phi^{t} \circ \phi^{s}
	\end{equation}
	C'è una condizione aggiuntiva da imporre (che assumiamo ora per definire i sistemi dinamici ma che è implicita nell'equazione di Newton), ossia che il flusso di fase deve preservare il volume (o, meglio, l'iper-volume) nello spazio delle fasi:
	\begin{equation}
		\int_{A}d\mu = \int_{\phi^{t}(A)}d\mu
	\end{equation}
	A livello pratico, tale condizioni equivale a richiedere che:
	\begin{equation}
		\Bigl|\dfrac{\partial \phi^{t}}{\partial x_{0}}\Bigl| = 1, \>\>\>\>\>\>\>\>\> \forall t
		\label{Det1}
	\end{equation}
	intendendo con $|\bullet|$ il determinante e con $\partial \phi^{t}(x_{0})/\partial x_{0}$ lo jacobiano del flusso di fase fatto rispetto alle coordinate di stato ($\phi$ è in questo caso funzione di $x_{0}$, mantengo costante il tempo. È come se, per ogni istante temporale, avessi una trasformazione dello spazio, $\phi^{t_{0}}(x_{0})$, il cui jacobiano ha determinante unitario).
	
	Dimostriamo brevemente la (\ref{Det1}). Vogliamo che valga:
	$$
	Vol(\phi^{t}(A)) = Vol(A)
	$$
	Consideriamo l'evoluto di $A$ e calcoliamone il volume, cioè:
	$$
	Vol(\phi^{t}(A)) = \int_{\phi^{t}(A)}dx
	$$
	Riscriviamo tale integrale passando dalle coordinate $x$ generiche del tempo $t$ alle coordinate $x_{0}$ proprie di $t=0$, sapendo che $x_{0} = \phi^{-t}(x)$. Per il teorema del cambiamento di variabile,
	$$
	\int_{\phi^{t}(A)}dx = \int_{A} \Bigl|\dfrac{\partial \phi^{t}(x_{0})}{\partial x_{0}}\Bigl| dx_{0}
	$$
	Dovendo quest'ultimo termine essere uguale a:
	$$
	Vol(A) = \int_{A} dx_{0}
	$$
	Ottengo la tesi.
	Da tale conservazione della misura dello spazio delle fasi si deduce la reversibilità temporale dei sistemi dinamici. Cosa vuol dire? 
	
	
	Si può dimostrare, infatti, che la conservazione della misura dello spazio delle fasi come richiesto in precedenza è strettamente collegato con la natura temporalmente reversibile dei fenomeni fisici. Un processo fisico è time-reversable se non è possibile stabilire con certezza il verso di percorrenza con cui il fenomeno sta avvenendo. Detto in parole più semplici, possiamo immaginare di registrare il processo in esame attraverso una videocamera e riprodurlo ad un amico in senso opposto. Se l'amico non è in grado di stabilire il verso del filmato, allora il processo avviene con perfetta simmetria temporale e si dice time-reversable. Il moto di un pianeta è reversibile, perché non c'è modo di capire se si va indietro nel tempo o in avanti. Al contrario, il moto di un pendolo smorzato dall'attrito non è reversibile. Osservando il filmato di un pendolo che da fermo comincia a oscillare aumentando man mano l'ampiezza del moto, saremo subito in grado di affermare con certezza che ci si sta muovendo indietro nel tempo e non in avanti.
	\subsubsection{Un esempio}
	Forniamo un esempio iniziale. Prendiamo un sistema generico (non per forza fisico) le cui coordinate di stato sono $x,p$ e il cui flusso di fase $\phi$ è definito come:
	\begin{equation}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
		= 
		\begin{pmatrix}
			cos(\omega t) & sin(\omega t)\\
			-sin(\omega t) & cos(\omega t)
		\end{pmatrix}
		\begin{pmatrix}
			x_{0} \\ p_{0}
		\end{pmatrix}
		=
		\begin{pmatrix}
			x_{0}cos(\omega t) + p_{0}sin(\omega t) \\
			-x_{0}sin(\omega t) + p_{0}cos(\omega t)
		\end{pmatrix}
		\label{Rotatore}
	\end{equation}
	Effettivamente $\phi$ è un flusso di fase poiché rispetta le condizioni esposte poco sopra. Si tratta di una trasformazione lineare che, infatti, posso rappresentare con una matrice. In particolare, stiamo parlando di una rotazione rigida del piano delle fasi che chiaramente preserva l'area (il determinate è pari a $1$ in qualsiasi tempo) e rispetta la composizione temporale richiesta. Attenzione! Le coordinate $x \mbox{ e } p$ non sono la coppia posizione-impulso (non tornerebbe dimensionalmente). Ricordiamo che lo spazio delle fasi e, di conseguenza, il flusso, sono concetti definibili per qualsiasi sistema, non necessariamente fisico. La definizione (\ref{Rotatore}) è propria di tutti quei sistemi detti \textit{rotatori}, proprio perché, nello spazio delle fasi, le due coordinate $x,p$ ruotano e si alternano ciclicamente. Un esempio è l'alternarsi ciclico della popolazione delle due specie di animali all'interno. Vedremo che il rotatore ha rilevanza anche nei sistemi meccanici, ma più avanti. 
	\subsection{Dal flusso di fase all'equazione differenziale}
	Le singole forme analitiche dell'operatore flusso di fase dipendono dalla specifica dinamica del sistema in esame. La domanda che ci poniamo è la seguente: come possiamo passare dal flusso di fase di un sistema alle equazioni differenziali che lo governano?
	
	Valuto la quantità vettoriale $a(x_{0})$ definita come:
	\begin{equation}
		a(x_{0})=\dfrac{d\phi^{t}(x_{0})}{dt}\Bigl|_{t=0} 
	\end{equation}  
	Questa grandezza rappresenta geometricamente la tangente (vettore tangente) alla traiettoria $x(t)$ in $x_{0}$ al tempo $t=0$. La generica quantità $a(x)$, definita:
	\begin{equation}
		a(x) = \dfrac{d}{dt}\Bigl|_{t=0}\phi^{t}(x)
	\end{equation}
	rappresenta dunque un vero e proprio campo vettoriale che ha la proprietà di essere tangente alla traiettoria in ogni punto dello spazio delle fasi. È importante specificare $t=0$ o, in generale, fissare un tempo. In pratica, fisso il tempo all'istante iniziale e associo allo spazio delle fasi un campo vettoriale che, per ogni punto, mi fornisce il vettore tangente alla traiettoria che per quel punto passa (e la forma della traiettoria è chiaramente individuata istantaneamente dal flusso di fase). Quello che la quantità $a(x_{0})$ mi dice è come evolve istantaneamente ogni singolo punto $x_{0}$ dello spazio delle fasi all'istante di tempo iniziale\footnote{Non solo all'istante iniziale, ma sempre! Se infatti la dinamica del sistema è simmetrica nel tempo, allora non c'è differenze nell'istante in cui studio la dinamica del piano. Prendiamo due punti materiali, entrambi che si trovano in questo preciso istante nello stato $x_0$, ma il primo corpo proviene ha già percorso altri stati in precedenza nel tempo mentre il secondo comincia ora il moto da $x_0$. I due corpi hanno dunque storie diverse, ma la fisica fondamentale non ha memoria ed entrambi i corpi, se in questo istante sono nello stesso stato dinamico, procederanno ad evolvere nella stessa identica maniera. Infatti la scelta di porre $t=0$ è del tutto arbitraria, potevo prendere un qualsiasi istante temporale (purché siano tutti equivalenti). L'equazione di Newton, in fondo, non contiene termini assoluti di tempo (ma solo $dt$.)} (in prima approssimazione, essendo un vettore tangente). Per questa ragione, il campo $a$ è detto \textit{generatore} del flusso di fase.
	
	A questo punto considero l'equazione:
	\begin{equation}
		\dot{x}(t) = a(x(t))
		\label{Flusso-eq}
	\end{equation}
	La soluzione di questa equazione, cui aggiungo le condizioni iniziali, coincide proprio con la traiettoria nello spazio delle fasi. Questa equazione mi dice che, dato l'attuale stato $x(t)$ del sistema ad un certo tempo t, la derivata in quel punto (cioè il vettore tangente) è uguale ad $a$ ivi calcolato.
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[step = 0.5, very thin,color= gray] (-0.1,-0.1) grid (3.9,3.9);
			\draw[->] (0,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,4) node[above] {$p$};
			\draw[fill= black] (2,1) circle (1.5pt) node[anchor = north west]{$x_{0}$};
			\draw[->] (2,1) -- (2.357771,1.715542);
			\draw[->] (1.5,1.5) -- (1.957771,2.215542);
			\draw[->] (2.5,0.5) -- (2.757771,1.315542);
			\draw[->] (2.5,2) -- (2.71771,2.715542);
			\draw[->] (2.75,1.5) -- (2.957771,2.215542);
			\draw[->] (2.05,2.5) -- (2.357771,3.215542);
			\draw[->] (2.775,3) -- (2.975,3.6155)
		}
		\tikz{
			\draw[step = 0.5,very thin,color=gray] (-0.1,-0.1) grid (3.9,3.9);
			\draw[->] (0,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,4) node[above] {$p$};
			\draw[fill= black] (2,1) circle (1.5pt) node[anchor = north west]{$x_{0}$};
			\draw[red] (2,1) .. controls (2.5,2) .. (2.775,3) node[anchor = south east]{$x(t)$};
			\draw[->] (2.775,3) -- (2.975,3.6155);
			\draw[->] (2.48,2) -- (2.76771,2.715542);
			\draw[->](2,1) -- (2.427771,1.715542);
		}
		\caption{\textit{A sinistra, il campo vettoriale $a$, inteso come derivata del flusso di fase al tempo $t=0$, ossia la direzione di evoluzione iniziale per ogni possibile stato iniziale $x_{0}$. In altre parole, il campo $a$ ci dice come evolve inizialmente l'intero spazio delle fasi. Questa informazione, però, equivale a sapere come evolve a qualsiasi tempo un punto nello spazio delle fasi. A destra, la traiettoria nel tempo che, per quando detto sopra, è tangente al campo $a$.}}
	\end{figure}
	Perciò conoscendo come evolve istantaneamente l'intero spazio delle fasi in un determinato istante temporale (ad esempio in $t=0$) so anche come evolve temporalmente un qualsiasi stato iniziale (noto $a(x)$, conosco $\dot{x}$). Questo è conseguenza del fatto che c'è simmetria temporale.
	Dimostriamo la (\ref{Flusso-eq}). Poiché so che
	$$
	x(t) = \phi^{t}(x_{0})
	$$
	allora la sua derivata rispetto al tempo è:
	$$
	\dot{x}(t) = \dfrac{d}{dt}\phi^{t}(x_{0}) = \lim_{\Delta t \to 0} \dfrac{1}{\Delta t}(\phi^{t+\Delta t}(x_{0})-\phi^{\Delta t}(x_{0}))
	$$
	esplicitando la definizione di derivata tramite rapporto incrementale. Sfruttando le proprietà di composizione del flusso di fase,
	$$
	\dfrac{1}{\Delta t}(\phi^{t+\Delta t}(x_{0})-\phi^{\Delta t}(x_{0})) = \dfrac{\phi^{\Delta t}(\phi^{t}(x_{0}))-\phi^{0}(\phi^{t}(x_{0}))}{\Delta t}
	$$
	cioè:
	$$
	\dot{x}(t) = \dfrac{d}{dt}\Bigl|_{t=0} \phi^{t}(\phi^{t}(x_{0})) = \dfrac{d}{dt}\Bigl|_{t=0} \phi^{t}(x(t)) = a(x)
	$$
	L'equazione (\ref{Flusso-eq}) costituisce l'equazione differenziale (o il sistema di queste) che genera il flusso di fase $\phi^{t}$.
	Proviamo ad applicare quanto detto nel caso del rotatore già presentato, ovvero:
	\begin{equation}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
		= 
		\begin{pmatrix}
			cos(\omega t) & sin(\omega t)\\
			-sin(\omega t) & cos(\omega t)
		\end{pmatrix}
		\begin{pmatrix}
			x_{0} \\ p_{0}
		\end{pmatrix}
		= \phi^{t} (x_{0})
		\label{ExampleRotation}
	\end{equation}
	Calcoliamo il campo $a$, dunque:
	$$
	a(x) = \dfrac{d}{dt}\Bigl|_{t=0}\phi^{t}(x)
	$$
	A rigore dovremmo moltiplicare la matrice di rotazione in (\ref{ExampleRotation}) per il vettore delle condizioni iniziali e derivare componente per componente:
	$$
	\phi^{t}(x) =
	\begin{pmatrix}
		xcos(\omega t) + psin(\omega t) \\
		-xsin(\omega t) + pcos(\omega t)
	\end{pmatrix}
	$$
	derivo in $t$ e calcolo in $t=0$:
	$$
	\dfrac{d}{dt}\Bigl|_{t=0}\phi^{t}(x) =
	\begin{pmatrix}
		-x\omega sin(0) + p\omega cos(0) \\
		-x\omega cos(0) + p\omega sin(0)
	\end{pmatrix}
	=
	\begin{pmatrix}
		p\omega  \\
		-x\omega
	\end{pmatrix}
	$$
	Questo procedimento è formalmente identico a derivare innanzitutto la matrice\footnote{Qualsiasi cosa significhi, derivare un operatore. Se è una matrice, basta derivare componente per componente}, calcolare in $t=0$ e applicare a $(x,p)$:
	$$
	\dfrac{d}{dt}\Bigl|_{t=0} \phi^{t}(x) =
	\begin{pmatrix}
		0 &  \omega \\
		-\omega & 0
	\end{pmatrix}
	\begin{pmatrix}
		x \\
		p
	\end{pmatrix}
	= a (x,p)
	$$
	Impiegando l'equazione (\ref{Flusso-eq}), ho che:
	$$
	\begin{pmatrix}
		0 &  \omega \\
		-\omega & 0
	\end{pmatrix}
	\begin{pmatrix}
		x \\
		p
	\end{pmatrix}
	= 
	\begin{pmatrix}
		\dot{x} \\ \dot{p}
	\end{pmatrix}
	$$
	che corrisponde al set di equazioni differenziali:
	\begin{equation}
		\begin{cases}
			\dot{x} = \omega p \\
			\dot{p} = -\omega x
		\end{cases}
	\end{equation}
	Il concetto di flusso di fase e di campo $a$ sono dunque fortemente imparentati: una volta stabilito l'uno, anche l'altro è definito. Il campo $a$ costituisce la forma analitica delle equazioni differenziali cui il sistema è soggetto mentre il flusso di fase ne rappresenta la "soluzione", cioè l'evoluzione temporale. È molto facile risalire dal flusso di fase all'equazione differenziale costitutiva (è proprio quello che abbiamo appena fatto) mentre non si può dire lo stesso del passaggio inverso (da $a$ a $\phi$). Questo perché l'equazione differenziale mi dà informazioni su un comportamente locale (cosa accade nel prossimo $dt$) mentre il flusso di fase codifica in sè un'informazione globale ($\forall t$). Ricostruire una proprietà del sistema ed estenderla su tutto l'asse dei tempi non è così faciòe. Vedremo in seguito come risolvere alcuni sistemi dinamici particolari.
	\subsection{Proprietà del campo $a$}
	Quali proprietà eredita il campo $a$? Per scoprirlo, scrivo il flusso di fase valutato in $x_{0}$ ad un istante $\Delta t$ e espando in termini di Taylor (qua la variabile è il tempo, non le coordinate dello spazio delle fasi. Mi tengo fisso in $x_{0}$):
	\begin{equation}
		\phi^{\Delta t}(x_{0}) = x_{0} + a(x_{0})\Delta t + o(\Delta t)
	\end{equation}
	Volendo allora calcolare lo jacobiano\footnote{Lo jacobiano è inteso nelle coordinate spaziali! Posso vedere il flusso di fase $\phi$ come una trasformazione dello spazio delle fasi che dall'argomento $x_{0}$ restituisce un $x(t)$. La variabile spaziale è dunque $x_{0}$. Per non appesantire la notazione (già pesante di suo), a volte confondiamo $x_{0}$ con $x$, intendendo però sempre il punto di applicazione del flusso di fase, le condizioni iniziali. Nell'equazione (\ref{EqDiv}) le varie coordinate sono scritte come $x_{0} = (x_{1}, x_{2}, ...)$ invece che $x_{0} = (x_{0,1}, x_{0,2}, ...)$, ad esempio} di $\phi^{\Delta t}$, posso approssimare il flusso escludendo i termini infinitesimi di ordini superiori al primo e scrivere che:
	$$
	\dfrac{\partial \phi^{\Delta t}}{\partial x_{0}} = I + \dfrac{\partial a}{\partial x_{0}}\Delta t
	$$
	ossia lo jacobiano di $\phi^{\Delta t }$ è l'identità più lo jacobiano del campo $a$ (entrambi valutati in $x_{0}$). Riscrivo l'equazione di sopra esplicitando i termini:
	\begin{equation}
		\dfrac{\partial \phi^{\Delta t}}{\partial x_{0}} = 
		\begin{pmatrix}
			1+ o(\Delta t) & o(\Delta t) & \cdots & o(\Delta t) \\
			o(\Delta t) & 1+ o(\Delta t) & \cdots &o(\Delta t) \\
			\vdots & \vdots &\ddots \\
			&&&\\
			o(\Delta t)  & o(\Delta t) & &1+o(\Delta t) \\
		\end{pmatrix}
	\end{equation}
	Nel valutare il determinante di questa matrice, dovrò considerare solo i termini di ordine non superiore al secondo, perciò non posso prendere gli elementi fuori dalla diagonale. Si può verificare che tale determinante è numericamente pari a:
	\begin{equation}
		\Bigl|\dfrac{\partial \phi^{\Delta t}}{\partial x_{0}}\Bigl| = 1+ \Bigl(\dfrac{\partial a_{1}}{\partial x_{1}} + \dfrac{\partial a_{2}}{\partial x_{2}}+ \cdots + \dfrac{\partial a_{n}}{\partial x_{n}}\Bigl)\Delta t + o(\Delta t) = 1 + \mbox{div}(a) \Delta t + o(\Delta t)
		\label{EqDiv}
	\end{equation}
	Derivando rispetto al tempo e valutando in $t=0$,
	$$
	\dfrac{d}{dt}\Bigl|_{t=0}	\Bigl|\dfrac{\partial \phi^{\Delta t}}{\partial x_{0}}\Bigl| = \mbox{div}(a)
	$$
	Ma poiché abbiamo imposto il determinante dello jacobiano pari a $1$ in tutti i tempi, deve seguire che la divergenza del campo $a$ è nulla:
	\begin{equation}
		\mbox{div}(a) = 0
	\end{equation}
	Viceversa, se mi ritrovo in una situazione in cui div$(a) = 0$, allora posso affermare che il determinante dello jacobiano rimane costantemente pari a 1 (a patto che valesse $1$ anche inizialmente. Questo, però, è banale perché a $t=0$ $\phi^{0} = I$, l'identità)
	\subsection{Singolarità}
	Ipotiziammo di dover risolvere un sistema per cui:
	\begin{equation}
		\dot{x} = a(x) = Ax
		\label{eq34}
	\end{equation}
	
	dove $A$ è una matrice a componenti costanti. Questi sistemi sono detti \textit{lineari} e li approfondiremo nella prossima sezione. Per ora osserviamo cosa capita se parto dallo stato $x_{0} = 0$. Si tratta di un caso molto particolare perché, sostituendo questa condizione iniziale in (\ref{eq34}), otteniamo che:
	$$
	\dot{x}(t=0) = Ax_{0} = 0
	$$
	La derivata calcolata in $t=0$ è pari a 0, dunque per piccoli intorni dello $0$ la soluzione si mantiene costante. Posso ripetere il ragionamento iterativo e concludere che la soluzione è costante per $\forall t$, cioè il sistema non evolve e rimane nello stato $x_{0}$:
	$$
	x(t) = x_{0} = 0
	$$
	La traiettoria descritta da questo sistema nello spazio delle fasi non è una curva ma un semplice punto, che può essere interpretato come una \textit{curva degenere 1-dimensionale}. 
	Questo è un esempio di punto dello spazio delle fasi detto di \textit{singolarità}, la cui definizione è però più generale. I punti di singolarità sono i punti in cui non è definito uno spazio tangente alla traiettoria e, in maniera più operativa, dove il campo $a(x)$ si annulla.\footnote{Se il sistema è lineare, $x=0$ è sempre singolare}:
	$$
	a(x_{s}) = 0 \>\>\> \Longrightarrow \mbox{ $x_{s}$ è punto di singolarità}
	$$
	Tali punti, detti anche \textit{fissi} (sinonimo di singolarità, poiché la soluzione rimane costante $x(t) = x_{s}$) fanno perdere le regolarità della trattazione ma sono molto importanti perché caratterizzano meglio dei campi vettoriali il sistema stesso e costituiscono punti di equilibrio, in quanto il sistema non evolve se si trova in un tale stato.
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[step = 0.5, very thin,color= gray] (-0.1,-0.1) grid (3.9,3.9);
			\draw[->] (0,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,4) node[above] {$p$};
			\draw[thick,->] (1,1.5) .. controls (2,2.5) .. (3,3);
			\draw[thick,->] (1,0.5) .. controls (1.5,1.25) and (2,1.7) .. (3,2.5);
			\draw[thick,->] (1.8,0.5) .. controls (2.1,1) and (2.5,1.4) .. (3,1.75);
		}
		\tikz{
			\draw[step = 0.5, very thin,color= gray] (-0.1,-0.1) grid (3.9,3.9);
			\draw[->] (0,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,4) node[above] {$p$};
			\draw[fill=black] (2,2) circle (1 pt);
			\draw[->, thick] (2,2) -- (3,2);
			\draw[->, thick] (2,2) -- (1,2);
			\draw[->, thick] (2,2) -- (2,3);
			\draw[->, thick] (2,2) -- (2,1);
			\draw[->, thick] (2,2) -- (2.71,2.71);
			\draw[->, thick] (2,2) -- (1.29,1.29);
			\draw[->, thick] (2,2) -- (1.29,2.71);
			\draw[->, thick] (2,2) -- (2.71,1.29);
		}
		\caption{\textit{A sinistra, esempio di traiettorie regolari senza singolarità per le quali esiste sempre uno spazio tangente. A destra, invece, c'è una singolarità.}}
		\label{FigSingolarità}
	\end{figure}
	Attenzione: la presenza di punti fissi non viola direttamente il teorema di esistenza ed unicità. Infatti, considerando la Fig.\ref{FigSingolarità} e riversando il tempo, potrebbe sembrare che esistano diverse traiettorie che divergono verso il medesimo punto (che è proprio quello di singolarità). Questo però non è assicurato: potrebbe infatti accadere che i sistemi che si muovano su tali curve impiegano un tempo infinito per raggiungere il punto fisso. Ed è proprio quello che capita. Per evitare dunque che le soluzioni violino i teoremi di unicità, deve necessariamente essere che le traiettorie nello spazio delle fasi che convergono/divergono ad un punto fisso lo facciano in tempi infiniti.
	\begin{figure}[H]
		\centering
		\tikz[scale = 1.2]{
			\draw[->] (0,0) -- (2.5,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,2.5) node[above] {$p$};
			\draw[fill=black] (1,1) circle (1 pt) node[above]{$x_{s}$};
			\draw[->, thick] (2,1) -- (1.06,1);
			\draw[->, thick] (0.28,0.28) -- (0.94,0.94) node[anchor = north west]{$t\to\infty$};
		}
		\caption{\textit{Le due traiettorie considerate convergono entrambe verso la singolarità $x_{s}$, violando apparentemente il teorema di unicità. Infatti, sembrerebbe che date due condizioni iniziali diverse, il sistema si porti verso uno stesso stato. Questo, tuttavia, non è un problema se il tempo di percorrenza su queste curve tende all'infinito}}
	\end{figure}
	Applichiamo quando detto per sistemi governati dalle equazioni di Newton, in cui il campo $a(x,p)$ ha la forma 
	\begin{equation}
		\vec{a} =
		\begin{cases}
			a_{1}(x,p) = \dot{x} = \dfrac{p}{m} \\
			a_{2}(x,p) = \dot{p} = -\dfrac{\partial V}{\partial x}(x)
		\end{cases}
		\label{NewtonField}
	\end{equation}
	In altre parole studio ora i sistemi dinamici propri della meccanica classica e non più sistemi generici. Le coordinate di stato sono dunque la posizione $x$ e l'impuslo $p$. Annullare la prima componente di $a$ richiede che:
	$$
	a_{1}(x,p) = \dot{x} = \dfrac{p}{m} = 0 
	$$
	cioè $p=0$. Quindi i punti fissi per un sistema meccanico devono soddisfare la nullità di $p$
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-0.5,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,-0.5) -- (0,2) node[above] {$p$};
			\draw[fill= black] (1,1) circle (1.5pt) node[anchor = south east]{$x_{0}$};
			\draw[fill= black] (1.8,0) circle (1.5pt) node[anchor = south east]{$x_{2}$};
			\draw[fill= black] (3.3,0) circle (1.5pt) node[anchor = south east]{$x_{3}$};
		}
		\caption{\textit{Il punto $x_{0}$ non può essere un punto fisso poiché non sta sull'asse $x$. Al contrario, i punti $x_{2}$ e $x_{3}$ sono ottimi candidati per il ruolo di punto fisso.}}
		
	\end{figure}
	L'altra condizione è che:
	$$
	a_{2}(x,p) = \dot{p} = -\dfrac{\partial V}{\partial x} = 0
	$$
	cioè si tratta dei punti critici del potenziale $V$, ossia dei punti in cui la forza è nulla. Abbiamo verificato che, in effetti, i punti fissi per sistemi dinamici newtoniani coincidono con i punti di equilibrio meccanico già noti.
	\newpage 
	\section{Risoluzione di sistemi lineari}
	\subsection{Equazioni differenziali lineari}
	Proponiamo una breve digressione matematica sulle equazioni differenziali lineari e sui relativi metodi di risoluzione analitica. Chiamiamo \textit{lineare} un sistema in cui il campo $a$ è una trasformazione lineare ($a$ nasce come campo vettoriale, ma è anche una trasformazione perché associa ad ogni vettore nello spazio delle fasi un altro vettore sempre nello spazio delle fasi). Dall'algebra lineare, sappiamo che ogni trasformazione lineare ammette una rappresentazione matriciale, perciò noi scriveremo:
	\begin{equation}
		a(x) = Ax
	\end{equation}
	Dunque vogliamo imparare a risolvere delle equazione differenziale nella forma:
	\begin{equation}
		\dot{x} = Ax
		\label{EqDiffLin}
	\end{equation}
	dove $x(t) = (x_{1}(t), x_{2}(t), ..., x_{n}(t)) \in \mathbb{R}^{n}$ e $A$ è una matrice $n\times n$ a valori costanti. Il sistema di equazioni è lineare e quindi, se $x_{A}$ e $x_{B}$ sono soluzioni dell'equazione, allora anche una loro qualsiasi combinazione lineare $c_{1}x_{A}(t) + c_{2}x_{B}(t)$ lo è. Dalla teoria matematica, sappiamo che lo spazio delle soluzioni di tale sistema ha dimensione $n$: basta dunque trovare $n$ soluzioni linearmente indipendenti per caratterizzare interamente lo spazio delle soluzioni tramite combinazioni lineari. Cerco dunque soluzioni delle forma:
	$$
	x(t) = v_{\lambda}e^{\lambda t}
	$$
	con $\lambda \in \mathbb{R}$. Sostituendo nella (\ref{EqDiffLin}), si ottiene che:
	$$
	Av_{\lambda} = \lambda v_{\lambda}
	$$
	cioè ho eliminato la dipendenza temporale riconducendomi al problema degli autovalori. Non dovrò fare altro, perciò, che trovare gli autovalori della matrice $A$ e relativi autovettori. Se sono linearmente indipendenti, sommo linearmente le varie soluzioni e ottenga quella generale:
	$$
	\vec{x}(t) = \sum_{\lambda}A_{\lambda}v_{\lambda}e^{\lambda t}
	$$
	Le condizioni iniziali permettono di stabilire i coefficienti $A_{\lambda}$ della combinazione, risolvendo il sistema:
	$$
	\vec{x}_{0} = \sum_{\lambda} A_{\lambda}v_{\lambda}
	$$
	\subsubsection{Esponenziale di matrice}
	Esiste un altro metodo per risolvere problemi come quelli di (\ref{EqDiffLin}). Osservando tale equazione, siamo tentati di scrivere:
	\begin{equation}
		x(t) = x_{0}e^{At} = x_{0}\exp(At)
		\label{ExpMatr}
	\end{equation}
	Il problema è che questa equazione è formulata per vettori e $A$ è una matrice, non un numero reale. Tuttavia, a patto di ridefinire ad hoc:
	$$
	\exp(At) := \sum_{k=0}^{\infty}\dfrac{A^{k
	}}{k!}t^{k}
	$$
	Definito così l'esponenziale di matrice, allora possiamo effettivamente scrivere la soluzione della (\ref{EqDiffLin}) in una forma simbolica più coincisa. Infatti:
	$$
	\dfrac{d}{dt} \exp(At) = \dfrac{d}{dt}\sum_{k=0}^{\infty}\dfrac{A^{k
	}}{k!}t^{k} = \sum_{k=0}^{\infty}\dfrac{A^{k
	}}{k!}\dfrac{d}{dt}t^{k} = \sum_{k=1}^{\infty}\dfrac{A^{k
	}}{(k-1)!}t^{k-1} = A \exp(At)
	$$
	Questo metodo, per quanto molto elegante, in realtà è poco utile. Si tratta infatti di calcolare una somma di infiniti termini (per altro matriciali) e, quindi, possiamo solo avere una rappresentazione approssimata del risultato. Inoltre spesso la convergenza è lenta, dunque richiede un alto ordine di approssimazione. Esistono alcuni casi in cui la serie può essere risolta senza approssimazioni in modo analitico, ad esempio se la matrice $A$ è diagonalizzabile. In tal caso, con un opportuno cambio di base lineare dalle coordinate iniziali dello spazio delle fasi $(x,p)$ a delle coordinate $(X,P)$ in cui $A$ è in forma diagonale, l'esponenziale di matrice è facile da calcolare (è una matrice diagonale in cui ogni termine è l'esponenziale scalare degli autovalori della matrice $A$).
	
	\subsection{Autovalori e divergenza}
	Se il metodo dell'esponenziale fallisce, perché troppo lungo e laborioso, possiamo pur sempre ricorrere al calcolo degli autovalori di $A$. Ancora prima di calcolare esplicitamente questi numeri, possiamo trarre alcune conclusioni sull'andamento asintotico delle soluzione. In particolare, se $\lambda \in \mathbb{C}$ è un autovalore di $A$, si distinguono i 3 seguenti casi:
	\begin{itemize}
		\item $Re(\lambda) > 0$: In tal caso la soluzione corrispondente, $x(t) = v_{\lambda}e^{\lambda t}$, diverge all'infinito per $t\to\infty$. Infatti, se $\lambda = a+ib$ con $a>0$, allora $x(t) = e^{at} (v_{\lambda} e^{ibt})$ che diverge esponenzialmente all'infinito. Chiaramente basta una sola soluzione divergente all'infinito perché la soluzione generale diverga.
		\item $Re(\lambda) < 0$: In tal caso la soluzione corrispondente, $x(t) = v_{\lambda}e^{\lambda t}$, converge a $x(\infty) = 0$, qualsiasi sia la condizione iniziale.
		\item $Re(\lambda) = 0$: La matrice $A$ ha autovalori puramente immaginari e la soluzione è di carattere oscillante (cioè non converge o diverge per tempi grandi).
	\end{itemize}
	Tutto ciò è molto comodo. Possiamo infatti studiare la stabilità di un sistema lineare senza andare a risolverlo direttamente, ma osservando semplicemente lo spettro della sua matrice $A$.
	\subsection{Esempi di sistemi lineari}
	\subsubsection{Rotatore}
	Abbiamo già incontrato un esempio di sistema lineare: il rotatore. In quel caso, eravamo riusciti a calcolare il campo $a$ notando che si trattava di una trasformazione lineare $A$:
	\begin{equation}
		a(x(t)) = Ax(t) =
		\begin{pmatrix}
			0 & \omega \\
			-\omega & 0
		\end{pmatrix}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
	\end{equation}
	che corrisponde al sistema di equazioni differenziali:
	\begin{equation}
		\begin{cases}
			\dot{x} = \omega p \\
			\dot{p} = -\omega x \\
		\end{cases}
		\label{DiffRotat}
	\end{equation}
	Come già detto, in genere noi conosciamo la forma delle equazioni differenziali e non il flusso di fase. Proviamo quindi a ricavarcelo da queste equazioni verificando che esso è formalmente uguale a quello calcolato in precedenza. Calcoliamo gli autovalori di $A$ ottenendo:
	$$
	\lambda_{1,2} = \pm i \omega
	$$
	Entrambi gli autovalori sono puramente immaginari, perciò ci aspettiamo una soluzione nè divergente nè convergente. La soluzione perciò è nella forma:
	\begin{equation}
		x(t) = Re(Ae^{i\omega t} + Be^{-i\omega t}) = C cos(\omega t) + D sin(\omega t)
	\end{equation}
	Imponendo le condizioni iniziali, $x(0) = x_{0} = (x_{0},p_{0})$:
	\begin{equation}
		x(t) =  x_{0}cos(\omega t) + p_{0}sin(\omega t)
	\end{equation}
	e il momento $p(t)$ vale (usando la prima equazione differenziale)\footnote{Attenzione: per ora, il momento $p$ non è necessariamente la quantità di moto $m\dot{x}$ (si può verificare dimensionalmente). Si tratta del momento coniugato alla posizione, lo vedremo meglio in seguito, per ora basta pensarlo come qualcosa di affine al momento, che veicola l'informazione della velocità, ma che non è esattamente tale. In fondo, se $p$ fosse la quantità di moto, una delle due equazioni differenziali dovrebbe essere scritta nella forma $\dot{x} = p/m$, con $m$ la massa.}:
	$$
	p(t) = -x_{0}sin(\omega t) + p_{0} cos(\omega t)
	$$
	cioè:
	\begin{equation}
		\begin{pmatrix}
			x(t) \\
			p(t)
		\end{pmatrix}
		=
		\begin{pmatrix}
			cos(\omega t) & sin(\omega t) \\
			-sin(\omega t) & cos(\omega t)
		\end{pmatrix}
		\begin{pmatrix}
			x_{0} \\ p_{0}
		\end{pmatrix}
	\end{equation}
	che è esattamente quanto visto nella (\ref{ExampleRotation}). 
	
	Potevamo arrivare allo stesso risultato applicando il metodo dell'esponenziale di matrice. Notiamo infatti che la matrice $A$ ha la particolare proprietà:
	\begin{equation}
		A^{2} = -\omega I
	\end{equation}
	intendendo con $I$ la matrice identità. In altre parole, il quadrato della matrice A restituisce l'opposto della matrice identità (a meno di un fattore $\omega$). Questo accadeva anche per l'unità immaginaria nel caso del piano complesso, in cui $(i\omega)^{2} = -(1)\omega$. Posso dunque realizzare un isomorfismo fra lo spazio dei numeri complessi e un sottospazio delle matrici $2\times2$ in cui:
	\begin{equation}
		1 \rightarrow 
		\begin{pmatrix}
			1 & 0 \\
			0 &1
		\end{pmatrix}
		\>\>\>\>\>\>\>\>\>\>\>\>
		i \rightarrow 
		\begin{pmatrix}
			0 & 1 \\
			-1 & 0
		\end{pmatrix}
		\label{Iso}
	\end{equation}
	Tale isomorfismo conserva la struttura algebrica dei numeri complessi e, perciò, invece di scrivere $e^{At}$, posso scrivere:
	$$
	e^{At} \rightarrow e^{i\omega t}
	$$
	essendo:
	$$
	A = 
	\begin{pmatrix}
		0 & \omega \\
		-\omega & 0
	\end{pmatrix}
	= \omega 
	\begin{pmatrix}
		0 & 1 \\
		-1 & 0
	\end{pmatrix}
	$$
	Dunque la soluzione della (\ref{DiffRotat}) si scrive come:
	\begin{equation}
		x(t) = x_{0}e^{At} \rightarrow x_{0}e^{i\omega t}
	\end{equation}
	Usando la formula di Eulero,
	$$
	x(t) = x_{0}e^{i \omega t} = x_{0} (1) cos(\omega t) + x_{0}isin(\omega t)
	$$
	Tornando allo spazio delle matrici con le relazioni (\ref{Iso}), ottengo:
	$$
	x(t) = x_{0}cos(\omega t)
	\begin{pmatrix}
		1 & 0 \\
		0 & 1
	\end{pmatrix} + x_{0}sin(\omega t)
	\begin{pmatrix}
		0 & 1 \\
		-1 & 0
	\end{pmatrix} = 
	\begin{pmatrix}
		cos(\omega t) & sin(\omega t) \\
		-sin(\omega t) & cos(\omega t)
	\end{pmatrix}
	\begin{pmatrix}
		x_{0} \\
		p_{0}
	\end{pmatrix}
	$$ 
	che è esattamente la forma del flusso di fase che avevamo già identificato.
	\subsubsection{Oscillatore armonico}
	Consideriamo un sistema dinamico lineare che evolve secondo:
	\begin{equation}
		\begin{cases}
			\dot{x} = p \\
			\dot{p} = -\omega^{2}x
		\end{cases}
	\end{equation}
	Si può dimostrare che il flusso di fase associato a tale sistema è della forma:
	\begin{equation}
		\begin{pmatrix}
			x(t) \\
			p(t)
		\end{pmatrix} =
		\begin{pmatrix}
			cos(\omega t) & \dfrac{1}{\omega} sin(\omega t) \\
			-\omega sin(\omega t) & cos(\omega t)
		\end{pmatrix}
		\begin{pmatrix}
			x_{0} \\
			p_{0}
		\end{pmatrix}
	\end{equation}
	Vediamo velocemente come provarlo. La matrice dell'equazione differenziale è:
	\begin{equation}
		A =
		\begin{pmatrix}
			0 & 1 \\
			- \omega^2 & 0
		\end{pmatrix}
	\end{equation}
	I suoi autovalori sono facili da calcolare e sono $\lambda = \pm i \omega $. Notiamo che questi autovalori sono gli stessi della matrice tipica del rotatore. Dall'algebra lineare ricordiamo che questo implica che le due matrici sono simili, cioà esiste una trasformazione lineare che porti l'una all'altra. Vedremo meglio dopo cosa ciò significhi. Calcoliamo i due autovettori, che otteniamo risolvendo l'equazione agli autovalori:
	\begin{equation}\label{key}
		\begin{pmatrix}
			0 & 1 \\
			- \omega^2 & 0
		\end{pmatrix}
		\begin{pmatrix}
			x \\ p
		\end{pmatrix}
		= \begin{pmatrix}
			\pm i\omega x \\ \pm i\omega p
		\end{pmatrix}
	\end{equation}
	Allora una base per i due autospazi è data dai due vettori non normalizzati:
	\begin{equation}\label{key}
		v_{i\omega} =
		\begin{pmatrix}
			1 \\ i\omega
		\end{pmatrix},
		\quad \quad
		v_{-i\omega} =
		\begin{pmatrix}
			1 \\ -i\omega
		\end{pmatrix}
	\end{equation}
	e quindi la soluzione generale è:
	\begin{equation}\label{key}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
		= A \begin{pmatrix}
			1\\i\omega
		\end{pmatrix}e^{i\omega t} +  B \begin{pmatrix}
			1\\-i\omega
		\end{pmatrix}e^{-i\omega t} = 
		\begin{pmatrix}
			Ae^{i\omega t} + B e^{-i\omega t} \\
			iA\omega e^{i\omega t} - iB\omega e^{-i\omega t}
		\end{pmatrix}
	\end{equation}
	Imponendo le condizioni iniziali,
	\begin{equation}\label{key}
		\begin{pmatrix}
			x_0 \\ p_0
		\end{pmatrix}
		= 
		\begin{pmatrix}
			A + B\\
			i\omega (A-B)
		\end{pmatrix}
	\end{equation}
	E risolvendo per $A,B$ otteniamo facilmente che
	\begin{equation}\label{key}
		\begin{aligned}
			A &= \dfrac{1}{2}(x_0 - i \dfrac{p_0}{\omega}) \\
			B &= \dfrac{1}{2}(x_0 + i \dfrac{p_0}{\omega}) 
		\end{aligned}
	\end{equation}
	Allora
	\begin{equation}\label{key}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
		= 
		\begin{pmatrix}
			\dfrac{x_0}{2}(e^{i\omega t} + e^{-i\omega t}) - i\dfrac{p_0}{2\omega}(e^{i\omega t} - e^{-i\omega t}) \\
			-\dfrac{1}{2i}x_0 \omega(e^{i\omega t} - e^{-i\omega t}) + \dfrac{1}{2}p_0(e^{i\omega t}+e^{-i\omega t})
		\end{pmatrix} = 
		\begin{pmatrix}
			x_0 cos(\omega t)+\dfrac{p_0}{\omega}sin(\omega t) \\
			- x_0 \omega sin(\omega t) + p_0 cos(\omega t)
		\end{pmatrix}
	\end{equation}
	che corrisponde al flusso di fase menzionato all'inizio
	
	
	Interpretando $x$ come posizione e $p$ come velocità, allora si tratta di un \textit{oscillatore armonico}, ossia di un generico sistema fisico governato dall'equazione di Newton:
	$$
	\ddot{x} = -\omega^{2}x
	$$
	come ad esempio una molla (la legge di Hooke ha questo tipo di proporzionalità)
	\subsubsection{Oscillatore iperbolico}
	\subsubsection{Significato fisico del rotatore e cambio di variabili}
	Ricapitoliamo brevemente quanto visto.
	Fino ad ora abbiamo incontrato due sistemi fisici caratteristici della meccanica classica, in particolare l'oscillatore armonico e l'oscillatore iperbolico. I due oscillatori, armonico ed iperbolico, rappresentano nello spazio delle fasi tutti quei sistemi dinamici governati dall'equazione differenziale:
	$$
	\ddot{x} = \pm \omega^{2} x
	$$
	e il segno del secondo membro identifica il tipo di oscillatore che modellizza il sistema. Le due equazioni del primo ordine nello spazio delle fasi possono essere scritte così:
	\begin{equation}
		\begin{cases}
			\dot{x} = p \\
			\dot{p} = \pm \omega^{2} x
		\end{cases}
	\end{equation}
	dove chiaramente $x$ rappresenta la coordinata spaziale (la posizione) e $p$ è la comune velocità istantanea\footnote{Lo so, $p$ in genere è riservato alla quantità di moto. Ad ogni modo, fra le due grandezze, velocità e quantità di moto, non intercorre molta differenza ed è indifferente in questi casi quale consideriamo. O comunque, lavorando nell'ipotesi $m=1$, allora $v = p$}. Per completezza scriviamo anche la matrice $A$:
	\begin{equation}
		A =
		\begin{pmatrix}
			0 & 1 \\
			\pm \omega^{2} & 0
		\end{pmatrix}
	\end{equation}
	Abbiamo poi parlato del caso del rotatore, in cui le equazioni differenziali si presentano nella forma:
	\begin{equation}
		\begin{cases}
			\dot{x} = \omega p \\
			\dot{p} = -\omega x
		\end{cases}
		\label{EqRotat}
	\end{equation}
	I due oscillatori rappresentano situazioni fisiche ben conosciute, come ad esempio una molla (armonico) o un pendolo rovesciato per piccoli angoli (iperbolico). Ed invece il rotatore? Cosa rappresenta a livello fisico? Ha qualche impiego in meccanica?
	
	È facile verificare che le quantità $(x,p)$ presenti nelle eq. (\ref{EqRotat}) non possono essere la posizione e la quantità di moto o la velocità perché violerebbero la dimensionalità delle equazioni. A dirla tutta, il rotatore scritto in questa forma non rappresenta alcun tipo di sistema fisico ma è tuttavia strettamente imparentato con gli oscillatori. Basta infatti, partendo ad esempio dall'oscillatore armonico, operare attraverso il seguente cambio di variabile: 
	\begin{equation}
		\begin{cases}
			X = \sqrt{\omega}x \\
			P = \dfrac{p}{\sqrt{\omega}}
		\end{cases}
		\label{TrasfRot}
	\end{equation}
	e si ottiene il set di equazioni differenziali tipiche del rotatore scritto nelle variabili non fisiche ma omogenee $X,P$:
	\begin{equation}
		\begin{cases}
			\dot{X} = \omega P \\
			\dot{P} = -\omega X
		\end{cases}
	\end{equation}
	La ragione per questo cambio di variabile è di natura simmetrica e avremo modo di ritornarci più avanti. Le equazioni (\ref{EqRotat}) scritte tramite le variabili astratte $(X,P)$ sono più simmetriche rispetto a quelle dell'oscillatore nelle variabili fisiche $(x,p)$. In generale, perciò, il rotatore è un sistema fisico a patto di interpretare le variabili $(X,P)$ come non fisiche ma legate ad esse tramite le trasformazioni lineari di (\ref{TrasfRot}).
	
	Questo semplice cambio di variabili ci ha permesso di mettere in luce una simmetria del problema che all'inizio ci sembrava nascosta. Dal punto di vista della meccanica, infatti, la distinzione fra coordinata spaziale e quantità di moto correlata è abbastanza fittizia ed arbitraria. Approfondendo lo studio della meccanica analitica, scopriremo che spesso esistono coordinate dello spazio delle fasi alternative a quelle "fisiche" che permettono di semplificare notevolmente il problema da affrontare e persino sottolineare aspetti di simmetria latenti, altrimenti ignorati
	\newpage
	\section{Integrali primi del moto}
	Quanto discusso in precedenza è un approccio molto matematico alla meccanica (appunto, \textit{meccanica analitica}) che permette una più potente e rigorosa formalizzazione del problema fondamentale della meccanica, cioè ricavare l'evoluzione temporale dei sistemi. La variabili $x,p$ avevano un significato molto generale e, infatti, il concetto di spazio delle fasi e flusso di fase possono essere impiegate per una vasta gamma di problematiche anche non strettamente meccaniche. Se vogliamo rendere questa descrizione utile alla risoluzione di problemi meccanici, usiamo come variabili di stato $x$ posizione e $p$ quantità di moto e, introducendo l'equazione di Newton applicata allo spazio delle fasi, otteniamo le due equazioni differenziali del primo ordine 
	\begin{equation}
		\begin{cases}
			\dot{x} = \dfrac{p}{m} \\
			\dot{p} = - \dfrac{\partial V}{\partial x}
		\end{cases}
		\label{NewtonPhase}
	\end{equation}
	Avendo formalmente diviso $x$ da $p$, dobbiamo in qualche modo ricordarci che, da ora in poi, queste due quantità sono indipendenti, nel senso che descrivono in maniera indipendente lo stato dinamico di un sistema.
	Allora, per i sistemi dinamici, cioè per sistemi in cui vale la caratterizzazione (\ref{NewtonPhase}), il campo $a$ sarebbe:
	\begin{equation}
		\vec{a} =
		\begin{cases}
			a_{1}(x,p) = \dfrac{p}{m} \\
			a_{2}(x,p) =  -\dfrac{\partial V}{\partial x}(x)
		\end{cases}
		\label{NewtonField}
	\end{equation}
	Per cui è facile verificare che:
	$$
	\mbox{div}(a) = \dfrac{\partial}{\partial x}\dfrac{p}{m} - \dfrac{\partial }{\partial p} \dfrac{\partial V}{\partial x} = 0
	$$
	questo è vero perché il potenziale $V$ è solamente funzione di $x$ (e non di $p$) e $\partial p/\partial x = 0$. Per capire bene quest'ultima relazione, va ricordato che $p$ e $x$ sono da considerarsi due variabili indipendenti!\footnote{Perché? In fondo non è $p = m\dot{x}$? Sì e no. La variabile $p$ è legata alla derivata della variabili $x$. La derivata ha senso solo quando io conosco l'evoluzione di $x$ nel tempo, cioè una volta che ho isolato compiutamente la legge oraria $x(t)$. Devo cioè conoscere il comportamente globale di $x$. Se mi viene fornito un generico punto $x$, non posso sapere anche a che velocità la particella si muove quando sta a $x$ (almeno finché non ho tutta la legge oraria). A priori, non c'è legame fra $x$ e $p$, che sono coordinate indipendenti descriventi lo stato dinamico del sistema. Il processo logico alla base di questo ragionamento è il seguente: dappriam consideriamo svincolate $x,p$ lavorando con due equazioni differenziali del primo ordine e, solo dopo aver risolto per $x(t)$, le due variabili saranno collegate} Essendo indipendenti, la derivata parziale dell'una rispetto all'altra è chiaramente nulla.
	
	Dalla nullità della divergenza di $a$ concludiamo che tutti i sistemi dinamici sono effettivamente \textbf{conservativi}, ossia preservano la misura nello spazio delle fasi\footnote{Questo è legato al fatto che se una forza può essere scritta come un potenziale, allora è conservativa. Le interazioni fondamentali sono assunte conservative}
	
	
	Possiamo ora introdurre il concetto di \textit{integrale primo del moto}, definito come una funzione di stato $H(x,p)$ che si mantiene costante nel tempo per un generico sistema che si evolve nello spazio delle fasi:
	\begin{equation}
		\dfrac{d}{dt}H(x,p) = 0
		\label{DefH}
	\end{equation}
	Queste funzioni sono molto utili perché permettono di individuare alcuni vincoli geometrici cui il sistema è soggetto nella sua evoluzione. Se questo, infatti, si trova inizialmente allo stato $x_{0}$, allora al tempo $t$ è vincolato ad assumere unicamente configurazioni in cui $H(x(t))=H(x_{0})$, come in Fig.\ref{FigIntPrimi}.
	\begin{figure}
		\centering
		\tikz{
			\draw (1,1) to[out = 90, in =135] (3,3);
			\draw (3,3) to[out = -45, in = 0] (3,0.3);
			\draw (3,0.3) to[out = 180, in = -90] (1,1);
			\node[anchor=south west, scale = 0.9] (A) at (3,3) {$H(x,p) = const$};
			\draw[->] (0,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,4) node[above] {$p$};
			\draw[fill= black] (1,1) circle (1.5pt) node[anchor = south east]{$x_{0}$};
		}
		\caption{\textit{Spazio delle fasi e integrale primo del moto $H(x,p)$. La linea continua rappresenta il luogo geometrico dei punti in cui $H$ si mantiene costante. Da ciò segue che il punto iniziale $x_{0}$ è vincolato a muoversi su tale curva e non può assumere altre configurazioni (è soggetta ad un vincolo geometrico).}}
		\label{FigIntPrimi}
	\end{figure}
	Possiamo riscrivere la (\ref{DefH}) esplicitando le dipendenze temporali:
	$$
	\dfrac{dH}{dt} = \dfrac{\partial H}{\partial x}\dfrac{\partial x}{\partial t}  + \dfrac{\partial H}{\partial p}\dfrac{\partial p}{\partial t} = \dfrac{\partial H}{\partial x} \dot{x} + \dfrac{\partial H}{\partial p}\dot{p}    = 0
	$$
	ossia:
	\begin{equation}
		\vec{\nabla}H \cdot \vec{a} = 0
	\end{equation}
	Questa condizione traduce il fatto che il gradiente di $H$ è sempre ortogonale al campo vettoriale, ossia il campo $a$ è tangente alle curve di livello per $H$. Quindi sono sempre in grado di costruire localmente le curve di livello per un generico sistema dinamico (infatti basta \textit{rincorrere} le linee di campo), il problema però rimane quello di caratterizzare a livello globale la soluzione (legata al flusso di fase). Tradotto in termini matematici, $a$ mi permette solo di caratterizzare una forma locale per $H$, non la sua forma globale $H(x,p)$. La costruzione di un integrale primo del moto, infatti, richiede di estendere a tutto lo spazio delle fasi la condizione di ortogonalità, il che non è banale. Come avevamo già visto in precedenza, estendere globalmente delle proprietà locali non è così semplice.
	
	
	Gli integrali primi del moto appartengono allo specifico sistema che stiamo studiando e non per forza sono caratteristiche universali di ogni sistema meccanico (ma qualcuno di uguale per tutti ne esiste). In generale, vale il seguente risultato: un sistema dinamico a $n$ gradi di libertà può avere al massimo $n$ integrali primi del moto.
	\subsection{Energia meccanica}
	Abbiamo già capito dove vogliamo andare a parare. Sospettiamo infatti che, da qualche parte nel nostro discorso sugli integrali primi, balzi fuori l'energia meccanica. Anche lei, infatti, condivide la proprietà di mantenersi invariata nel tempo. Ed in effetti, esiste un integrale primo del moto valido per tutti i sistemi dinamici che si scrive nella forma:
	\begin{equation}
		H(x,p) = \dfrac{p^{2}}{2m} + V(x)
	\end{equation}
	che è esattamente l'\textit{energia meccanica} nota da studi precedenti. L'energia è uno dei pochi integrali primi che sono tali per tutti i sistemi dinamici e la sua invarianza temporale è diretta conseguenza delle leggi di Newton di (\ref{NewtonPhase}), infatti:
	$$
	\dfrac{d}{dt}H(x,p) = \dfrac{\partial H}{\partial x} \dfrac{\partial x}{\partial t} + \dfrac{\partial H}{\partial p}\dfrac{\partial p}{\partial t} = \dot{x}\dfrac{\partial V}{\partial x}+\dfrac{p}{m}\dot{p}
	$$
	e sostituendo da (\ref{NewtonPhase}) le espressioni per $\dot{p}$ e $\dot{x}$:
	$$
	\dfrac{d}{dt}H(x,p) = \dfrac{p}{m}\dfrac{\partial V}{\partial x} - \dfrac{p}{m}\dfrac{\partial V}{\partial x} = 0
	$$
	\subsection{Condizioni sufficienti e necessarie per integrali primi del moto}
	L'esistenza di integrali primi del moto necessita della condizione di conservatività del sistema (deve conservare i volumi o comunque godere di alcuni invarianti geometrici). Ad esempio, nel caso $1$D, la conservazione dell'energia è (anche) dovuta alla conservazione dell'area nel piano delle fasi. 
	
	Potrebbe però sorgere un dubbio. Poiché il generico integrale $H(x,p)$ deve rispettare la condizione:
	$$
	\dfrac{\partial H}{\partial x}\dot{x} + \dfrac{\partial H}{\partial p}\dot{p} = 0 = \dfrac{\partial H}{\partial x}a_{1}(x,p) + \dfrac{\partial H}{\partial p}a_{2}(x,p)
	$$
	Allora proviamo a costruire una funzione $H(x,p)$ tale che:
	\begin{equation}\begin{split}
			\dfrac{\partial H}{\partial x} = -a_{2}(x,p) \\
			\dfrac{\partial H}{\partial y} = a_{1}(x,p)
			\label{eq1}
	\end{split}\end{equation}
	Non avrei automaticamente trovato un integrale primo del moto? In realtà no. Così facendo, ho solo descritto alcune sue proprietà scritte in termini di derivate parziali. Se voglio trovare una forma analitica per $H(x,p)$, sempre ammesso che esista, dovrei integrare le equazioni di cui sopra. E niente mi garantisce che possa effetuare questa operazione con successo (solo nel caso 1D il teorema fondamentale del calcolo integrale mi assicura l'esistenza di primitive, ma per le derivate parziali )
	
	Tuttavia questi due vincoli ci permettono di riflettere su alcune proprietà di $H$. Infatti dovrà verificarsi che:
	\begin{equation}
		\dfrac{\partial^{2}H}{\partial x \partial y} = \dfrac{\partial^{2}H}{\partial y \partial x}
		\label{CondizChius}
	\end{equation}
	Questa condizione è detta \textit{di chiusura} e rappresenta una condizione necessaria ma non sufficiente per l'esistenza di $H$ (al contrario di una ipotetica condizione di \textit{esattezza}, da cui potrei integrare e trovare $H(x,p)$). Combinando la (\ref{CondizChius}) alla (\ref{eq1}), si ricava che:
	$$
	\dfrac{\partial a_{1}}{\partial x} + \dfrac{\partial a_{2}}{\partial p} = 0 = \mbox{div}(a)
	$$
	Cioè perché $H$ possa esistere, allora div$(a) = 0$, ossia, come già dimostrato, il sistema deve essere conservativo. Deduciamo allora che la conservatività di un sistema rappresenta una condizione necessaria ma non sufficiente all'esistenza di un qualche integrale primo del moto. Nello specifico caso di sistemi dinamici newtoniani, la particolare forma delle equazioni di Newton (insieme chiaramente alla conservatività dei sistemi) permette di isolare sempre almeno un integrale primo del moto, l'energia meccanica.
	
	
	\subsection{Energia per un oscillatore}
	Torniamo al caso dell'oscillatore armonico uni-dimensionale e proviamo a disegnare nel piano le curve di livello per l'energia meccanica $H(x,p)$:
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-4,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,-3) -- (0,3) node[above] {$p$};
			\draw(0,0) ellipse (2cm and 1.5cm);
			\draw(0,0) ellipse (3cm and 2.25cm);
			\draw(0,0) ellipse (1cm and 0.75cm);
			\node[] at (3,1.9) (A) {$H(x,p) = E$};
			\draw[->] (3,0) -- (3,1);
			\draw[->] (0,2.25) -- (-1,2.25);
			\draw[->] (-3,0) -- (-3, -1);
			\draw[->](0,-2.25) -- (1,-2.25)node[anchor = north west]{$\vec{a}$};
			\draw[->] (1.49,1) -- (0.718,1.667);
		}
		\caption{\textit{Curve di livello per l'energia meccanica in un oscillatore armonico uni-dimensionale parametrizzate a $E_0$, energia dell'orbita. Il campo $a$ è tangente alle linee di livello.}}
		\label{FigOscill}
	\end{figure}
	Infatti, imponendo $H(x,p) = E_{0}$ e $V(x) = 1/2kx^{2}$:
	$$
	E_{0} = \dfrac{p^{2}}{2m} + \dfrac{1}{2}kx^{2}
	$$
	cioè:
	\begin{equation}
		\dfrac{p^{2}}{2mE_{0}} + \dfrac{x^{2}}{2\dfrac{E_{0}}{k}} = 1
	\end{equation}
	che è proprio l'equazione di un ellisse nel piano delle fasi, come mostrato in Fig.\ref{FigOscill}.
	Il periodo di oscillazione $\omega$ è pari a:
	$$
	\omega = \sqrt{\dfrac{k}{m}} 
	$$ 
	ed è indipendente dal valore di $E_{0}$. Questa proprietà può essere riassunta dicendo che l'oscillatore non conosce scala intrinseca.
	
	
	Una volta note le varie curve di livello, possiamo suddividere l'intero piano delle fasi in diversi \textit{sottospazi} di forma ellittica che costituiscono le orbite del sistema. Notiamo che tali orbite si dispiegano attorno al punto fisso $x=0$, sempre presente nei sistemi lineari. Il punto di singolarità centrale sembra dunque suggerire la forma delle soluzioni attorno ad esso (ed infatti viene chiamato punto ellittico ed è una caratteristica degli oscillatori armonici).
	
	Come avevamo già detto, la struttura dello spazio delle fasi, intesa come la struttura delle orbite che risolvono il mio sistema meccanico, è determinata dai punti fissi: sono proprio loro che definiscono la geometria delle orbite perché, al di là di questi, le orbite sono tutte simili (sono rettificabili, le posso trasformare come voglio operando con cambiamenti di variabile). Da ellissi, infatti, possono diventare circonferenze o altre curve piane. Le singolarità, invece, rimangono. La conclusione che ci viene suggerita è che \textit{i punti fissi determinano in maniera univoca la struttura delle orbite nello spazio delle fasi}. Questo spiega perché, in genere, siamo molto interessati alla loro individuazione.
	\newpage
	\section{Sistemi unidimensionali}
	Concentriamoci sui sistemi dinamici caratterizzati dall'avere un solo grado di libertà. Per tali problemi, purché si conservi, possiamo usare l'equazione di conservazione dell'energia meccanica per trovare la soluzione del sistema (in fondo basta una sola equazione avendo un solo grado di libertà). In tal caso, posso interpretare l'equazione della conservazione dell'energia come un'equazione differenziale a tutti gli effetti:
	\begin{equation}
		\dfrac{m}{2}\Bigl(\dfrac{dx}{dt}\Bigl)^{2} + V(x) = E(x_{0},p_{0}) = E_{0}
	\end{equation}
	separando le variabili:
	\begin{equation}
		dt = \dfrac{dx}{\sqrt{\dfrac{2}{m}(E_{0}-V(x))}}
		\>\>\>\> \longrightarrow \>\>\>\>
		t = \int_{x_{0}}^{x(t)}\dfrac{dx'}{\sqrt{\dfrac{2}{m}(E_{0}-V(x'))}}
		\label{Solution1D}
	\end{equation}
	Per trovare la soluzione analitica mi basta integrare e invertire\footnote{Potremmo avere difficoltà ad integrare una funzione il cui denominatore può essere nullo (basta infatti che $E = V(x)$ ad un certo punto dell'evoluzione del sistema). In realtà non ce ne dobbiamo preoccupare perché in quel caso l'integrale converge nonostante l'integrando diverge all'infinito. A titolo d'esempio, l'integrale $\int_{0}^{t}\dfrac{1}{\sqrt{x}}dx$ ha valore finito nonostante la radice vada all'infinito}.
	
	La (\ref{Solution1D}) rappresenta, dunque, la soluzione più generale possibile per sistemi dinamici uni-dimensionali. Per il teorema fondamentale del calcolo integrale, tale formula ha sempre senso e, dunque, concludiamo che un sistema dinamico unidimensionale è sempre \textit{integrabile}. Questo non vuol dire necessariamente che la soluzione $x(t)$ possa essere scritta in termini di funzioni analitiche elementari (anzi, a volte dobbiamo impiegare funzioni ellittiche). Però esiste sempre una soluzione esprimibile con metodi numerici. In generale, dunque, diremo che un sistema è \textit{integrabile} se è almeno possibile arrivare ad una forma tipo la (\ref{Solution1D}). 
	
	
	
	A volte possiamo ricavare delle informazioni molto importanti sul comportamento di un sistema uni-dimensionale senza risolvere l'integrale di (\ref{Solution1D}), che può essere particolarmente complicato, semplicemente disegnando lo spazio delle fasi. Vediamo come.
	\subsection{Sistema unidimensionale con potenziale cubico}
	Immaginiamo di dover analizzare un sistema unidimensionale descritto dalla coordinata spaziale $x$ per cui il grafico del potenziale è di tipo polinomiale cubico, come quello di Fig.\ref{Fig1}.
	\begin{figure}
		\centering
		\tikz{
			\draw[->] (0,-3) -- (0,3)node[above]{$V(x)$};
			\draw[->] (-3,0) -- (3,0)node[right]{$x$};
			\draw[domain=-1.7:1.7] plot (\x, {-\x*\x*\x + \x - 0.3849});
			\node[anchor = north] (A) at (-0.5,-0.9) {$V_{B}$};
			\node[anchor = south] (B) at (0.7,0.1) {$V_{A}$};
			\draw[dotted] (-0.577,-0.7770) -- (3.277,-0.777) node[below]{$E<V_{B}$};
		}
		\tikz{
			\draw[->] (0,-3) -- (0,3)node[above]{$V(x)$};
			\draw[->] (-3,0) -- (3,0)node[right]{$x$};
			\draw[domain=-1.7:1.7] plot (\x, {-\x*\x*\x + \x - 0.3849});
			\node[anchor = north] (A) at (-0.5,-0.9) {$V_{B}$};
			\node[anchor = south] (B) at (0.7,0.1) {$V_{A}$};
			\draw[dotted] (1.2,-0.977) -- (3.277,-0.977) node[below]{$E<V_{B}$};
			\draw[dotted] (1.2,-0.977) -- (1.2,0)node[anchor = south west]{$x_{0}$};
			
		}
		\caption{\textit{Grafico del potenziale, di forma cubica. Se $E<V_B$, il moto è confinato per $x>x_0$.}}
		\label{Fig1}
	\end{figure}
	Proviamo a costruire la geometria dello spazio delle fasi, cioè tracciare le curve di livello, semplicemente osservando il grafico del potenziale e evitando per il momento di risolvere le equazioni del moto usando la (\ref{Solution1D}).
	
	Poiché l'energia può assumere, a priori, qualsiasi valore, scegliamo in primis valori di $E< V_{B}$. Siccome $E = \dfrac{1}{2m}p^{2} + V(x)$, solo le posizioni $x$ in cui $V(x) < E$ sono fisiche e possono essere assunte dal sistema in esame. Inoltre, tanto maggiore è la differenza $E-V(x)$, tanto maggiore l'energia cinetica e, quindi, la variabile $p$. Di conseguenza, allontanandosi da $x=x_{0}$ (soluzione di $E = V(x_0)$) e tendendo verso $\infty$, anche $p\to\infty$. Per $x=x_{0}$, si ha un \textit{punto di inversione}, ossia un punto in cui il momento (e quindi la velocità) si annulla e cambia direzione. Questo punto si trova alla minima distanza raggiungibile dall'origine, in quanto il moto è confinato a $x>x_0$. Mettendo insieme quanto appena detto sul piano delle fasi, otterremo una curva di livello avente la forma rappresentata in Fig.\ref{Fig10}
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-3,0) -- (3,0)node[right]{$x$};	
			\draw[->] (0,-3) -- (0,3)node[above]{$p$};
			\draw[domain=-3:3, samples=50]   plot ({sqrt(3+1.3*\x*\x)}, \x)node[anchor = north west]{$E<V_{B}$};
			\node[anchor = south east] (A) at (1.7,0) {$x_{0}$};
		}
		
		\caption{\textit{Traiettoria nello spazio delle fasi per un'energia $E<V_B$. Il moto è confinato a valori $x>x_0$ dove $x_0$ è il punto di inversione, soluzione di $E=V(x_0)$}}
		\label{Fig10}
	\end{figure}
	La curva di livello con energia minore di $V_B$ nello spazio delle fasi assomiglia ad un iperbole (ma in generale non lo è) e rispetta tutte le caratteristiche sopra esposte. Inoltre l'angolo che tale curva individua attraversando l'asse $x$ nel punto di inversione deve essere obbligatoriamente retto. Le curve di livello (almeno finché non prendo valori critici dell'energia) sono regolari e perciò possiedono sempre un gradiente e una direzione tangente univoca. Le curve di livello dell'energia, poi, sono simmetriche rispetto alla variabile $p$ in ragione del termine $p^{2}$ e perciò l'unico angolo per cui la curva appare regolare se riflessa è proprio l'angolo retto. Diminuendo ulteriormente l'energia si ottengono pseudo-iperboli sempre più lontane dall'origine (perché il punto di inversione si allontana).
	
	Adesso mi occupo delle curve di livello ad energia più grande, $V_{B} < E < V_{A}$, come in Fig.\ref{Fig3}
	\begin{figure}[H]
		\centering
		\tikz[scale = 0.9]{
			\draw[->] (0,-3) -- (0,3)node[above]{$V(x)$};
			\draw[->] (-3,0) -- (3,0)node[right]{$x$};
			\draw[domain=-1.7:1.7] plot (\x, {-\x*\x*\x + \x - 0.3849});
			\node[anchor = north] (A) at (-0.5,-0.9) {$V_{B}$};
			\node[anchor = south] (B) at (0.7,0.1) {$V_{A}$};
			\draw[dotted] (-1,-0.377) -- (2.577,-0.377) node[below]{$E$};
			\node[left] (A) at (-1,-0.377) {$x_{1}$};
			\node[below right] (A) at (0,-0.377) {$x_{2}$};
			\node[below right] (A) at (1.1,-0.377) {$x_{0}$};
		}
		\tikz[scale = 0.9]{
			\draw[->] (-3,0) -- (3,0)node[right]{$x$};	
			\draw[->] (0,-3) -- (0,3)node[above]{$p$};
			\draw[domain=-3:3, samples=50]   plot ({sqrt(1.8+1.3*\x*\x)}, \x)node[anchor = north west]{$V_{B}<E<V_{A}$};
			\node[anchor = south east] (A) at (1.3,0) {$x_{0}$};
			\draw[rotate=0] (-1.25,0) ellipse (35pt and 20pt);
			\node[anchor = south east] (A) at (-1.75,0) {$x_{1}$};
			\node[anchor = south west] (A) at (0,0) {$x_{2}$};
			
		}
		\label{Fig3}
	\end{figure}
	
	Per tali livelli energetici, solo le regioni spaziali $x_{1} < x < x_{2}$ e $x>x_{0}$ sono permesse. In questo caso, la curva di livello si comporrà di due componenti connesse che rappresentano fisicamente soluzioni diverse. La prima, per $x>x_{0}$ è simile alla pseudo-iperbole individuata in precedenza mentre la seconda è necessariamente "intrappolata" fra gli estremi $x_{1}, x_{2}$. In corrispondenza di questi punti, $E=V$ e perciò si tratta di punti di inversione, in cui la curva di livello intersecherà perpendicolarmente l'asse $x$. Il valore massimo di $p$ nell'intervallo $ [x_{1},x_{2}]$ verrà raggiunto quando $x=x_{B}$, cioè il minimo del potenziale. In generale, dunque, la curva di livello per $V_B < E < V_A$ è composta da una componente connessa pseudo-ellittica di carattere periodico (la soluzione oscilla in quel buco di potenziale) e una componente connessa pseudo-iperbolica analoga a quella vista in precedenza ma un po' più vicina all'origine.
	
	Vediamo cosa accade, in particolare, nel caso critico $E=V_{A}$. La soluzione nello spazio delle fasi ci apparirà:
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-2.5,0) -- (2.5,0)node[right]{$x$};	
			\draw[->] (0,-2.5) -- (0,2.5)node[above]{$p$};
			\draw (1,0) to[out =60, in = 220] (3,2.2);
			\draw (1,0) to[out =-60, in = -220] (3,-2.2);
			\draw (1,0) to[out =120, in = 90] (-1.5,0);
			\draw (1,0) to[out =-120, in = -90] (-1.5,0);
			\node[anchor = south west] (A) at (1.2,0) {$x_{A}$};
			
		}
	\end{figure}
	La curva presenta un punto angoloso per $x = x_{A}$ poiché, in effetti, in quel punto non è ben definita una direzione tangente (è un punto singolare, di massimo). Ci potrebbe sembrare che questa curva di livello sia un'unica componente connessa rappresentante un'unica soluzione, ma ciò è falso. Infatti, il punto singolare $x=x_{A}$ rappresenta una soluzione puntuale del sistema dinamico e, perciò, le curve a destra e a sinistra non possono includerlo. Ne segue che la curva di livello critica ha ben $4$ soluzioni fisiche diverse: la soluzione limitata pseudo-ellittica a sinistra del punto singolare, il punto singolare stesso e i due rami pseudo-iperbolici che divergono o convergono verso il punto singolare. Per le soluzioni non banali (cioè tutte tranne quella $x(t) = x_{A}$), il tempo di percorrenza per convergere a $x_{A}$ deve essere $\infty$ per non violare il teorema di unicità ed esistenza. Questa curva molto particolare è detta \textit{curva separatrice} e determina le sotto-regioni dello spazio delle fasi in cui i comportamenti sono simili. A questo punto, è facile intuire la struttura geometrica globale dello spazio delle fasi:
	\begin{figure}[H]
		\centering
		\tikz[scale =1.2]{
			\draw[->] (-2.5,0) -- (2.5,0)node[right]{$x$};	
			\draw[->] (0,-2.5) -- (0,2.5)node[above]{$p$};
			\draw[thick] (1,0) to[out =60, in = 220] (3,2.2);
			\draw[thick] (1,0) to[out =-60, in = -220] (3,-2.2);
			\draw[thick] (1,0) to[out =120, in = 90] (-1.5,0);
			\draw[thick] (1,0) to[out =-120, in = -90] (-1.5,0);
			\draw[fill=black] (1,0) circle (2pt);
			\draw[fill = black] (-0.3,0) circle (2pt);
			\draw (-0.3,0) ellipse (1 and .5);
			\draw (-0.3,0) ellipse (.75 and .375);
			\draw (-0.3,0) ellipse (.5 and .25);
			\draw[domain=-1.8:1.8, samples=50]   plot ({sqrt(3+1.7*\x*\x)}, \x);
			
			\draw (2.5,2.1) to[out=210, in=0] (0,.8);
			\draw (0,.8) to[out = 180, in = 2] (-1,.9);
			\draw (-1,.9) to[out=180, in = 90] (-1.8,0);
			\draw (2.5,-2.1) to[out=-210, in=0] (0,-.8);
			\draw (0,-.8) to[out = -180, in = -2] (-1,-0.9);
			\draw (-1,-.9) to[out=-180, in = -90] (-1.8,0);
			
			\draw (2,2.1) to[out=210, in=0] (0,1.2);
			\draw (0,1.2) to[out = 180, in = 2] (-1.2,1.3);
			\draw (-1.2,1.3) to[out=180, in = 90] (-2.2,0);
			\draw (2,-2.1) to[out=-210, in=0] (0,-1.2);
			\draw (0,-1.2) to[out = -180, in =- 2] (-1.2,-1.3);
			\draw (-1.2,-1.3) to[out=-180, in = -90] (-2.2,0);
		}
		\label{SpazioFasiPotenzialeMinimoMassimo}
	\end{figure}
	La curva separatrice è calcata in nero e divide lo spazio delle fasi in 3 regioni (la zona delle orbite chiude pseudoellittiche che si avvolgono attorno al punto critico di minimo, la zona delle pseudoiperboli a destra del punto critico di massimo e la regione delle curve ibride a sinistra del massimo). I due punti critici, di minimo e di massimo, stabiliscono una particolare geometria dello spazio delle fasi. In intorni del punto di minimo, infatti, le orbite sembrano ellittiche mentre in intorni del punto di massimo le orbite sembrano iperboliche. Questo è vero generalmente: un punto di minimo è localmente un punto ellittico e, analogamente, un punto di massimo è localmente iperbolico.
	La forma specifica delle orbite attorno a questi punti, poi, dipende dalla struttura analitica del potenziale, ma finché tale punto critico è di minimo è sempre possibile zoomare in intorni di tale punto e ritrovare orbite che approssimano la forma dell'ellisse o dell'iperbole arbitrariamente bene.\footnote{Se il potenziale è di tipo $U\propto \pm x^{2}$, allora le orbite sono ellissi/iperboli perfette, come già dimostrato per l'oscillatore armonico/iperbolico. Per altri tipi di potenziale non è detto.}
	
	
	
	\subsection{Linearizzazioni in intorni di punti di equilibrio}
	Prendiamo in esame un sistema unidimensionale che in $x=x_0$ abbia un punto critico del potenziale. Sappiamo che questa condizione equivale ad un equilibrio del sistema meccanico 1D, stabile o o instabile a seconda che il punto sia di minimo o di massimo. Tali punti critici del potenziale sono anche punti di singolarità nello spazio delle fasi e, nella sezione precedente, abbiamo visto che i minimi sembrano essere avvolti da orbite simil ellittiche mentre i massimi attraggono attorno a sè curve quasi iperboliche\footnote{Di nuovo ricordiamo che la perfetta ellitticità/iperbolicità è riservati ai due oscillatori fisici (armonico e iperbolico)} Cerchiamo di approfondire questa osservazione.
	
	Sia $x=x_0$ un punto fisso di un sistema 1D, minimo e massimo che sia.  Immaginando di poter rimanere abbastanza vicini a tale punto singolare, cerchiamo di studiare la dinamica del sistema in intorni del punto $x_0$.
	
	Per farlo, espando con Taylor il potenziale attorno a $x_0$:
	$$
	V(x) = V_{0} + \dfrac{\partial V}{\partial x}(x_0) (x-x_0) + \dfrac{1}{2}\dfrac{\partial^2 V}{\partial x^2 }(x_0)(x-x_0)^2 = V_{0} + \dfrac{1}{2}\dfrac{\partial^2 V}{\partial x^2 }(x_0)(x-x_0)^2 + O((x-x_0)^3)
	$$
	in quanto nel punto critico la derivata prima del potenziale è nulla. Allora l'energia del sistema, in prima approssimazione è:
	$$
	E = \dfrac{1}{2}m\dot{x}^2 + V_{0} + \dfrac{1}{2}\dfrac{\partial^2 V}{\partial x^2 }(x_0)(x-x_0)^2 
	$$
	La costante $V_0$ è ininfluente ai fini dinamici e quindi posso inglobarla in $E$ definendo $\Delta E$ e ridefinendo una nuova coordinata $x = x-x_0$:
	$$
	\Delta E = \dfrac{1}{2}m\dot{x}^2 + \dfrac{1}{2}kx^2
	$$
	Avendo definito $k$ la derivata seconda calcolata nel punto di criticità. Questa forma dell'energia è equivalente all'energia di un oscillatore armonico o iperbolico a seconda del segno di $k$:
	$$
	k = \dfrac{d^2 V}{dx^2}(x_0)
	$$
	Se $x_0$ è un punto di minimo, allora la derivata seconda $k$ è necessariamente maggiore di $0$ e l'equazione dell'energia linearizzata rappresenta l'energia di un oscillatore armonico (invece per $x_0$ massimo $k<0$ e il punto è iperbolico). La frequenza delle piccole oscillazioni per punti di minimo è allora:
	$$
	\omega^2 = \dfrac{1}{m}\dfrac{d^2 V}{dx^2}(x_0)
	$$
	Per quanto riguarda il caso di punto di massimo, il sistema si comporta in prima approssimazione come un oscillatore iperbolico. Quest'ultimo tende a divergere iperbolicamente dal massimo e, dunque, fa decadere in breve l'approssimazine di Taylor fatta (valida solo in intorni del punto critico). In un certo senso, è possibile definire anche per l'oscillatore iperbolico una "pulsazione immaginaria", nonostante il moto non sia chiaramente di tipo periodico.
	
	Attorno a punti di minimo, invece, la soluzione rimane confinata in una buca di potenziale (arbitrariamente piccola) e quindi, scegliendo intorni abbastanza piccoli, si ha la certezza che l'orbita rimanga abbastanza vicina al minimo, dunque giustificando l'utilizzo dell'approssimazione con Taylor.
	\subsection{Il pendolo semplice}
	Un esempio molto famoso di linearizzazione è quello del pendolo semplice fisico. Si tratta di un sistema abbastanza universale che permette di applicare i concetti che abbiamo appreso sui sistemi unidimensionali. L'equazione differenziale che governa il comportamento del pendolo è\footnote{Come l'abbiamo ricavata? Basta usare l'equazione di Newton. In questa prima parte del documento, ci occupiamo di comprendere come studiare/analizzare le equazioni del moto quando sono già state ricavate. Più avanti vedremo invece come ottenere le equazioni differenziali che governano i sistemi dinamici con metodi diversi da quelle di Newton} \begin{equation}
		\ddot{\theta} =- \dfrac{g}{l}\sin\theta = -\omega_{0}^2 \sin\theta
	\end{equation}
	dove $\theta$ è l'angolo dalla verticale. Per lo spazio delle fasi, usiamo l'angolo $\theta$ stesso e l'impulso $p=mv = ml\dot{\theta}$ del pendolo. L'angolo $\theta$ può chiaramente variare da $-\pi$ a $\pi$ mentre l'impulso $p$ può assumere valori arbitrari, dunque lo spazio delle fasi è più propriamente un cilindro. Infatti la variabile angolo vive su di una circonferenza mentre la variabili impulso vive su di una retta reale e il loro prodotto restituisce un cilindro.\footnote{Perché non un rettangolo? In fondo $(\theta,p)\in[-\pi,\pi]\times\mathbb{R}$ e quindi sembra che lo spazio delle fasi debba essere una striscia rettangolare di spessore infinito e altezza finita. Questo però non è sufficiente, perché il pendolo può passare da $-\pi$ a $\pi$ con continuità nella realtà fisica, mentre nel rettangolo che abbiamo identificato fra questi due punti non c'è continuità. L'unica è di unire i due lembi del rettangolo, cioè farne un cilindro. Dopodiché posso identificare il cilindro col rettangolo, perché in questo caso le due superfici sono topologicamente simili, ma questa cosa non è così scontata}. L'energia del sistema si scrive allora come:
	$$
	H(\theta,p) = \dfrac{1}{2m}p^2- mgl\cos\theta 
	$$
	Lo spazio delle fasi assume dunque una geometria del tipo:
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\draw[dotted] (-4,3.2) -- (-4,-3.2);
			\draw[dotted] (4,3.2) -- (4,-3.2);
			\draw[->] (-4.2,0) -- (4.2,0);
			\draw[->] (0,-3.2) -- (0,3.2);
			\draw[fill = black] (-4,0) circle (2pt);
			\draw[fill = black] (0,0) circle (2pt);
			\draw[fill = black] (4,0) circle (2pt);
			\draw (4,0) to[out=125,in=55] (-4,0);
			\draw (4,0) to[out=-125,in=-55] (-4,0);
			\draw (0,0) ellipse (2 and 1);
			\draw (0,0) ellipse (1 and 0.5);
			\draw (0,0) ellipse (3 and 1.5);
			
			
			\draw (-3.8,1.5) to[out=0,in=-180] (0,2.5);
			
			\draw (3.8,1.5) to[out=180,in=0] (0,2.5); 
			
			\draw (-3.8,-1.5) to[out=0,in=-180] (0,-2.5);
			
			\draw (3.8,-1.5) to[out=180,in=0] (0,-2.5);
			
			
			\draw (-3.8,2.1) to[out=0,in=-180] (0,3);
			
			\draw (3.8,2.1) to[out=180,in=0] (0,3); 
			
			\draw (-3.8,-2.1) to[out=0,in=-180] (0,-3);
			
			\draw (3.8,-2.1) to[out=180,in=0] (0,-3);
		\end{tikzpicture}
	\end{figure}
	Dove immaginiamo di prendere il cilindro e svolgerlo su di un piano. I due lati tratteggiati, dunque, coincidono perfettamente e i due punti iperbolici sono in realtà lo stesso punto di equilibrio instabile (la posizione a 180 gradi). La curva separatrice separa il cilindro delle fasi in due regioni, quella interna in cui le orbite sono periodiche e centrate nel punto di equilibrio $\theta = 0$, mentre le curve di livello esterne (che si ricongiungono "teletrasportandosi" quando il punto valica la linea tratteggiata) rappresentano un pendolo abbastanza energetico da compiere una totale rotazione di 360 gradi all'infinito. Sulla curva separatrice, invece, i tempi devono divergere all'infinito. Questo vuol dire che se impartisco al pendolo un'energia pari a quella della curva separatrice, allora il pendolo tende asintoticamente alla posizione di equilibrio instabile senza tuttavia mai arrivarci.
	
	È noto da precedenti studi di meccanica che l'equazione del pendolo fisico è estremamente difficile da risolvere a causa del termine $\sin\theta$. L'integrale da risolvere sarebbe:
	\begin{equation}
		t = \int_{\theta_0}^{\theta}\dfrac{d\theta}{\sqrt{2E'+2\dfrac{g}{l}\cos\theta}} =  \int_{\theta}^{\theta_0}\dfrac{d\theta}{\sqrt{2E'+2\omega_0^2\cos\theta}}
		\label{Pendolo}
	\end{equation}
	con:
	$$
	E' = \dfrac{E}{ml^2}
	$$
	
	Proviamo allora a studiare il moto del pendolo attorno alla posizione di equilibrio stabile $\theta = 0$ con la tecnica della linearizzazione. In particolare, espandiamo il potenziale gravitazionale fino al secondo ordine ottenendo:
	$$
	\Delta E \approx \dfrac{1}{2m}p^2 + \dfrac{1}{2}\dfrac{g}{l}\theta^2
	$$
	Questa è l'energia di un oscillatore armonico con pulsazione caratteristica delle piccole oscillazioni:
	$$
	\omega = \sqrt{\dfrac{g}{l}}
	$$
	ed è la celebre approssimazione in uso per le piccole oscillazioni. Notiamo che questa espressione per il periodo delle orbite:
	$$
	T = \dfrac{2\pi}{\omega} = 2\pi \sqrt{\dfrac{l}{g}}
	$$
	non dipende dall'energia dell'orbita stessa. Questo non ci stupisce poiché è una proprietà notevole dell'oscillatore armonico. Nel caso del pendolo fisico, tale formula per il periodo vale solo in intorni della posizione di equilibrio e, in generale, il periodo di un'orbita è funzione dell'energia, $T = T(E)$. D'altronde, il periodo associato all'energia della curva separatrice deve tendere all'infinito, dunque la funzione $T(E)$ è monotona crescente da $0 <E < E_{sep}$.
	
	Ritorniamo momentaneamente alla (\ref{Pendolo}). Possiamo trasformare un po' questo integrale. Infatti, il denominatore può essere reso:
	\begin{equation}
		\begin{aligned}
			\sqrt{2E'+2\omega_0^2 \cos\theta} &= \sqrt{2(E'+\omega_0^2)}\sqrt{\dfrac{E'+\omega_0^2 \cos\theta}{E'+\omega_0^2}} = \\
			&=   \sqrt{2(E'+\omega_0^2)}\sqrt{\dfrac{E'-\omega_0^2 (1-\cos\theta)+\omega_0^2}{E'+\omega_0^2}} = \\
			&= \sqrt{2(E'+\omega_0^2)}\sqrt{\dfrac{E'-\omega_0^2 (1-\cos\theta)+\omega_0^2}{E'+\omega_0^2}} = \\
			&= \sqrt{2(E'+\omega_0^2)}\sqrt{1-\dfrac{\omega_0^2}{E'+\omega_0^2}(1-\cos\theta)} =
		\end{aligned} 
	\end{equation} 
	Ma $\-cos\theta =2 \sin^{2}\dfrac{\theta}{2}$, perciò
	\begin{equation}\label{key}
		\sqrt{2(E'+\omega_0^2)}\sqrt{1-\dfrac{\omega_0^2}{E'+\omega_0^2}(1-\cos\theta)} =  \sqrt{2(E'+\omega_0^2)}\sqrt{1-\dfrac{\omega_0^2}{E'+2\omega_0^2} \sin^{2}\dfrac{\theta}{2}} =
	\end{equation}
	detti
	\begin{equation}\label{key}
		A = \dfrac{1}{\sqrt{2(E+\omega_0^2)}}  \quad \quad \quad m = \dfrac{2\omega_0^2}{E+\omega_0^2}
	\end{equation}
	allora il denominatore si riscrive come:
	\begin{equation}\label{key}
		\dfrac{1}{A}\sqrt{1-m\sin^{2}\dfrac{\theta}{2}}
	\end{equation}
	E quindi la forma integrale per $t$ diventa:
	\begin{equation}\label{key}
		t = A\int_{\theta_0}^{\theta}\dfrac{d\theta}{\sqrt{1-m\sin^{2}\dfrac{\theta}{2}}}
	\end{equation}
	
	Questa forma integrale è abbastanza famosa e passa sotto il nome di \textit{funzione ellittica di Jacobi}. Non esistono primitive per queste forme integrali facilmente esprimibili con l'analisi standard.
	
	L'aspetto interessante è che, operando un altro cambio di variabili:
	$$
	u = \sin\dfrac{\theta}{2}
	$$
	allora 
	$$
	d\theta = 2 \dfrac{du}{\sqrt{1-u^2}}
	$$
	e l'integrale di Jacobi diventa esprimibile in forma polinomiale come:
	\begin{equation}\label{key}
		t = 2A\int_{u_0}^{u}\dfrac{du}{\sqrt{1-(1+m)u^2+mu^4}}
	\end{equation}
	Notiamo ora una vaga somiglianza con un problema unidimensionale caratterizzato da potenziale quartico. Infatti, per un generico sistema 1D in cui la coordinata è $u$, abbiamo che:
	\begin{equation}\label{key}
		t = \int_{u_0}^{u}\dfrac{du}{\sqrt{E-V(u)}}
	\end{equation}
	che ricorda molto la formula per il pendolo, a patto che il potenziale sia di potenza quarta. Proviamo, allora, a studiare come si composta un tale sistema fisico.
	\subsection{Sistema a potenziale quartico}
	\subsection{Divergenza delle soluzioni per punti iperbolici}
	Prendiamo un sistema unidimensionale che abbia un punto di massimo (cioè iperbolico). Negli intorni del punto, posso scrivere l'energia del sistema come:
	$$
	H = \dfrac{1}{2}m\dot{x}^2 - \dfrac{1}{2}kx^2
	$$
	Con un cambio di variabili (locali), posso sempre ricondurmi alla forma:
	$$
	H = \dfrac{\omega}{2}(P^2-X^2)
	$$
	con le variabili $X,P$ tipiche del rotatore iperbolico definite di modo che:
	\begin{equation}\label{key}
		\begin{cases}
			\dot{X} = \omega P \\
			\dot{P} = \omega X
		\end{cases}
	\end{equation}
	La domanda che ci poniamo è allora la seguente: dato un intorno in cui sia ragionevole usare l'approssimazione lineare per il punto iperbolico, quanto tempo ci mette una soluzione arbitrariamente vicina al punto critico ad allontanarsi (o avvicinarsi) sulla curva di livello da esso?
	
	Detto $x^{*}$ il raggio dell'interno massimo entro cui è valida l'approssimazione lineare, prendiamo un punto $x_0$ sull'asse $x$ e chiediamoci quanto il punto materiale impieghi per abbandonare l'intorno lineare partendo da $x^*$. Avremo che:
	$$
	x^* = x_0 \cosh\Bigl(\dfrac{\omega T}{2}\Bigl)
	$$
	cioè:
	$$
	2x^* = x_0 e^{\omega T} + x_0 e^{-\omega T}
	$$
	detto $\lambda = e^{\omega t}$, allora
	$$
	2x^* = x_0 \lambda + x_0 \dfrac{1}{\lambda}
	$$
	$$
	x_0 \lambda^{2} - 2x^{*}\lambda + x_0 = 0
	$$
	$$
	\lambda^{2} - 2\dfrac{x^{*}}{x_0}\lambda + 1 = 0
	$$
	Risolvendo, ottengo che:
	$$
	\lambda = \dfrac{x^{*}}{x_0} \pm \sqrt{\Bigl(\dfrac{x^{*}}{x_0}\Bigl)^2 -1} = \dfrac{x^{*}}{x_0} \pm \dfrac{x^{*}}{x_0} \sqrt{1-\Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2} 
	$$
	Quale segno devo scegliere? Facendo tendere $x_0$ a $0$ (il punto di massimo), otterrei l'approssimazione:
	$$
	\sqrt{1-\Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2} \approx 1- \Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2
	$$
	e se scegliessi la soluzione col meno avrei.
	$$
	\lambda =  \dfrac{x^{*}}{x_0} - \dfrac{x^{*}}{x_0} + \dfrac{x_0}{x^{*}} =  \dfrac{x_0}{x^{*}} \rightarrow 0
	$$
	e quindi avrei che $\lambda = e^{\omega T}\rightarrow 0$, cioè che $T \rightarrow -\infty$. Questo è chiaramente impossibile, io mi aspetto che $T\rightarrow\infty$ man mano che mi avvicino alle separatrici iperboliche. Allora devo scegliere il segno più:
	$$
	e^{\omega T} = \lambda =\dfrac{x^{*}}{x_0} + \dfrac{x^{*}}{x_0} \sqrt{1-\Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2}
	$$
	e quindi, risolvendo per $T$:
	$$
	T = \dfrac{2}{\omega} \ln\dfrac{x^{*}}{x_0}\Bigl(1+\sqrt{1-\Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2}\Bigl)
	$$
	Se effettivamente $x_0 \rightarrow 0$ allora $T\rightarrow\infty$, che è quello che ci aspettiamo. A che velocità $T$ tende all'infinito? Di che natura è la singolarità? Cerco di isolarla nell'espressione di $T$.
	Per la proprietà dei logaritmi,
	$$
	T = \dfrac{2}{\omega} \ln\dfrac{x^{*}}{x_0} + \dfrac{2}{\omega}\Bigl(1+\sqrt{1-\Bigl(\dfrac{x_0}{x^{*}}\Bigl)^2}\Bigl)
	$$
	Il secondo termine è abbastanza ininfluente perché fornisce correzioni di ordine successivi. L'andamento è dunque del tipo:
	$$
	T = \dfrac{2}{\omega} \ln\dfrac{x^{*}}{x_0} 
	$$
	cioè di natura logaritmica. Tuttavia $x$ non è una variabili fisica (è quella del rotatore), dunque vorrei un'espressione che leghi $T$ all'energia (che ha un significato universale). Poiché:
	$$
	|E| = \dfrac{\omega}{2}x_0^2
	$$
	Se consideriamo $x^{*}$ una costante, allora
	$$
	T \propto -\dfrac{1}{\omega} \ln|E|
	$$
	Siamo dunque di fronte ad una singolarità di tipo logaritmico, abbastanza debole (ma alla base della caoticità)
	
	
	
	
	
	\newpage
	
	\section{Sistemi con forzanti}
	Consideriamo un'equazione differenziale della forma:
	\begin{equation}
		m\ddot{x} = -\dfrac{\partial V}{\partial x}(x) + f(t)
		\label{EqForz1}
	\end{equation}
	che corrisponde ad un sistema meccanico governato dalle forze $\dfrac{\partial V}{\partial x}$ in cui aggiungo dall'esterno una \textit{forzante} funzione del tempo di cui conosco l'espressione analitica, $f(t)$. Traducendo questa equazione differenziale del secondo ordine in due equazioni del primo ordine, otteniamo:
	\begin{equation}
		\dot{x} = a(x) +
		\begin{pmatrix}
			0 \\ f(t)
		\end{pmatrix}
	\end{equation}
	dove il campo di Newton $a(x)$ sarebbe sostanzialmente:
	\begin{equation}\label{key}
		a(x,p) =
		\begin{pmatrix}
			\dfrac{p}{m} \\[6pt]
			\dfrac{\partial V}{\partial x}
		\end{pmatrix}
	\end{equation}
	Tuttavia noi vogliamo studiare questo tipo di equazioni differenziali da una prospettiva più ampia e non necessariamente fisica, dunque lasceremo la notazione col campo $a(x)$ (che poi, se si tratta di un sistema fisico, può essere sostituita col campo di Newton).
	
	Nel caso ci si trovi a studiare sistemi lineari, tale equazione differenziale diventa:
	\begin{equation}
		\dot{x} = Ax +
		\begin{pmatrix}
			0 \\ f(t)
		\end{pmatrix}
		\label{EqForz2}
	\end{equation}
	Questa aggiunta rende l'equazione non omogenea e non rispetta i requisiti per l'applicazione del teorema di unicità, ma non complica particolarmente la risoluzione del problema (almeno finché $A$ non dipende dal tempo).
	
	L'equazione di (\ref{EqForz2}) è particolarmente utile in diversi ambiti, fra cui annoveriamo:
	\begin{itemize}
		\item Nella teoria dei signali, $f(t)$ è il segnale in ricezione mentre $x(t)$ è il segnale filtrato
		\item Nella teoria del controllo, $f(t)$ è una perturbazione che il mio sistema può ricevere in maniera casuale dall'esterno o che posso impartire io per \textit{controllare} il mio sistema.
	\end{itemize}
	
	Come possiamo risolvere un'equazione del tipo di (\ref{EqForz2})? Dalla teoria dell'analisi, sappiamo che una simile equazione differenziale si risolve calcolando dapprima la soluzione omogenea in cui $f(t)=0$ (cosa che già sappiamo fare) e sommando una soluzione particolare:
	$$
	x(t) = x_{omo}(t) + x_p(t)
	$$ 
	Ci costruiamo una funzione $y(t)$ definita di modo che:
	$$
	x(t) = e^{At}y(t)
	$$
	derivando rispetto al tempo questa relazione ottengo che
	$$
	\dot{x} = Ae^{At}y(t) + e^{At}\dot{y}(t)
	$$
	eguagliando all'equazione iniziale l'espressione di $\dot{x}(t)$,
	$$
	Ae^{At}y(t) + e^{At}\dot{y}(t) = Ae^{At}y(t) + f(t)
	$$
	cioè:
	$$
	\dot{y} = e^{-At}f(t)
	$$
	Questa non è praticamente più una equazione differenziale perché mi basta integrare ambo i membri per ottenere l'espressione analitica $y(t)$
	\begin{equation}
		y(t) = y_{0} + \int_{0}^{t}e^{-As}f(s)ds = x_{0} + \int_{0}^{t}e^{-As}f(s)ds
	\end{equation}
	dove chiaramente $y_{0} = y(0) = x_{0}$. Voglio però trovare $x(t)$, e quindi mi basta moltiplicare per la matrice $A$ e ottenere:
	\begin{equation}
		x(t) = x_{0}e^{At} + \int_{0}^{t}e^{A(t-s)}f(s)ds
		\label{SoluzForz}
	\end{equation}
	La soluzione (\ref{SoluzForz}) si compone di due addendi separati. Il primo termine è la soluzione dell'omogenea associata con condizione iniziale uguale a $x_{0}$ mentre il secondo termine è una soluzione particolare che si annulla a $t=0$\footnote{Questo particolare \textit{operatore}, l'integrazione con esponenziale di matrice scalato di $s$, ricorre molto spesso in fisica e si chiama \textit{convoluzione} o \textit{integrale di convoluzione}}.
	
	\subsubsection{Metodo alternativo per oscillazioni forzate}
	Un modo alternativo per ricordarsi la formula di convoluzione ce lo suggerisce Landau. Questo metodo è molto più comodo (a parer mio) quando il problema di forzante da considerare è di natura fisica e quindi l'equazione differenziale da studiare ha la specifica forma
	$$
	\ddot{x} + \omega_0^2 x = \dfrac{1}{m}f(t)
	$$
	Senza andare a aggiungere un'altra dimensionalità considerando vettori nello spazio delle fasi, definiamo una nuova variabile complessa 
	\begin{equation}\label{key}
		z = \dot{x} + i\omega_0 x
	\end{equation}
	Allora l'equazione differenziale di partenza può essere espressa in termini di $z$ come:
	\begin{equation}\label{key}
		\dot{z} - i\omega_0 z = \dfrac{1}{m}f(t)
	\end{equation}
	Supponiamo una soluzione del tipo:
	$$
	z(t) = A(t)e^{i\omega_0 t}
	$$
	e sostituendo direttamente nell'equazione differenziale avremo che:
	\begin{equation}\label{key}
		\dot{A}(t) = \dfrac{1}{m}f(t)e^{-i\omega_0 t}
	\end{equation}
	\begin{equation}\label{key}
		A(t) = A_0 + \dfrac{1}{m}\int_{0}^{t}f(s)e^{-i\omega_0 s}ds
	\end{equation}
	e quindi:
	\begin{equation}\label{key}
		z(t) = A_0e^{i\omega_0 t} + \dfrac{1}{m}\int_{0}^{t}f(s)e^{i\omega_0 (t-s)}ds
	\end{equation}
	Isolando la parte reale e la parte immaginaria di $z$, posso trovare sia $\dot{x}(t)$ sia $x(t)$.
	\subsection{Esempio: rotatore con forzante}
	Studiamo l'esempio del rotatore con l'aggiunta di una forzatura $f(t)$:
	\begin{equation}
		\begin{pmatrix}
			\dot{x} \\ \dot{p}
		\end{pmatrix} =
		\begin{pmatrix}
			0 &\omega \\
			-\omega & 0 
		\end{pmatrix}
		\begin{pmatrix}
			x \\ p
		\end{pmatrix} +
		\begin{pmatrix}
			0 \\ f(t)
		\end{pmatrix}
	\end{equation}
	Applichiamo il metodo appena esposto per trovare una soluzione al problema. Calcoliamo in primis $e^{At}$:
	\begin{equation}
		e^{At} =
		\begin{pmatrix}
			cos(\omega t) & sin(\omega t) \\
			-sin(\omega t) & cos(\omega t)
		\end{pmatrix}
	\end{equation}
	e quindi:
	\begin{equation}
		e^{A(t-s)} =
		\begin{pmatrix}
			cos(\omega (t-s)) & sin(\omega (t-s)) \\
			-sin(\omega (t-s)) & cos(\omega (t-s))
		\end{pmatrix}
	\end{equation}
	Moltiplicando per il vettore $(0,f(s))$ otteniamo l'integrando della (\ref{SoluzForz}):
	\begin{equation}
		e^{A(t-s)}f(s) =
		\begin{pmatrix}
			cos(\omega (t-s)) & sin(\omega (t-s)) \\
			-sin(\omega (t-s)) & cos(\omega (t-s))
		\end{pmatrix}
		\begin{pmatrix}
			0 \\ f(s)
		\end{pmatrix} =
		\begin{pmatrix}
			f(s)sin(\omega (t-s)) \\
			f(s)cos(\omega (t-s))
		\end{pmatrix}
	\end{equation}
	Supponiamo che la forzante abbia la seguente espressione:
	\begin{equation}
		f(t) = a sin(\Omega t)
	\end{equation}
	Si tratta ora di valutare le due soluzioni particolari come da (\ref{SoluzForz}):
	\begin{equation}
		\begin{cases}
			x^{*}(t) = a\int_{0}^{t}sin(\Omega s)sin(\omega (t-s))ds \\
			p^{*}(t) = a\int_{0}^{t}sin(\Omega s)cos(\omega (t-s))ds
		\end{cases}
	\end{equation}
	Consideriamo solo la prima equazione, cioè:
	$$
	x^{*}(t) = a\int_{0}^{t}sin(\Omega s)sin(\omega (t-s))ds
	$$
	Utilizziamo le formule di Werner per scrivere:
	$$
	x^{*}(t) = \dfrac{1}{2}a\Bigl(\int_{0}^{t}cos((\Omega+\omega) s-\omega t)ds-\int_{0}^{t}cos((\Omega -\omega)s + \omega t)ds\Bigl)
	$$
	Ora posso calcolare i due integrali:
	\begin{equation}\begin{split}
			x^{*}(t) &= \dfrac{a}{2} \dfrac{sin(\omega t)+sin(\Omega t)}{\Omega + \omega} - \dfrac{a}{2} \dfrac{sin(\omega t)-sin(\Omega t)}{\omega - \Omega} \\ &= -\dfrac{a\Omega}{\omega^{2}-\Omega^{2}}sin(\omega t) + \dfrac{a\omega}{\omega^{2}-\Omega^{2}}sin(\Omega t)
			\label{eq3}
	\end{split}\end{equation}
	dunque la soluzione generale rimane la somma di due seni, perciò limitata. Calcoliamola, per completezza. Abbiamo già la soluzione dell'omogenea associata, che scrivo come:
	$$
	x_{omo}(t) = e^{At}x_{0} 
	$$
	e isolando la sola componente delle coordinata $x$, ottengo (ma potevo anche arrivarci dal flusso di fase):
	$$
	x_{omo}(t) = x_{0}cos(\omega t) + p_{0}sin(\omega t) 
	$$
	e la soluzione completa sarà perciò\footnote{Notiamo inoltre che le \textit{soluzioni particolari} sono diverse se calcolate col metodo formale o col metodo operativo. Non c'è nulla di problematico, essendo esse una particolare soluzione fra le tanti, ne va bene una qualunque}:
	\begin{equation}\begin{split}
			x(t) &=  x_{0}cos(\omega t) + p_{0}sin(\omega t) -\dfrac{a\Omega}{\omega^{2}-\Omega^{2}}sin(\omega t) + \dfrac{a\omega}{\omega^{2}-\Omega^{2}}sin(\Omega t)
			\\ 
			&= x_{0}cos(\omega t) + \Bigl(p_{0}-\dfrac{a\Omega}{\omega^{2}-\Omega^{2}}\Bigl)sin(\omega t) + \dfrac{a\omega}{\omega^{2}-\Omega^{2}}sin(\Omega t)
	\end{split}\end{equation}
	È interessante notare, però, che se $\Omega = \pm \omega$, i due termini della (\ref{eq3}) diventano una forma di indecisione del tipo $0/0$. Valutiamo cosa accade per $\Omega\to-\omega$ al primo addendo:
	$$
	\lim_{\Omega \to -\omega} \dfrac{a}{2} \dfrac{sin(\omega t)+sin(\Omega t)}{\omega + \Omega} = \lim_{\Omega \to \omega} \dfrac{a}{2} \dfrac{sin(\omega t)-sin(\Omega t)}{\omega - \Omega} = \dfrac{d}{d\omega}sin(\omega t) = t\>cos(\omega t)
	$$
	In tal caso, la soluzione diventa:
	\begin{equation}
		x^{*}(t) = \dfrac{a}{2} \dfrac{sin(\omega t)}{\omega} + \dfrac{a}{2}t\> cos(\omega t)
		\label{Rison}
	\end{equation}
	Analogo ragionamento col secondo termine laddove $\Omega = \omega$. La soluzione (\ref{Rison}) è molto particolare perchè il secondo termine non è limitato nel tempo (la sua ampiezza è funzione monotona del tempo $t$). Questo vuol dire che il sistema comincierà a ruotare nel piano delle fasi ed aumenterà la ampiezza di tali rotazioni senza limite superiore, tendendo all'infinito.
	\subsection{Esempio: oscillazioni forzate}
	A volte possiamo risolvere sistemi con forzanti in maniera molto più rapida, soprattutto se si tratta di situazioni fisiche. È il caso dell'oscillatore armonico forzato. Se, infatti, l'equazione differenziale compare nella forma: 
	\begin{equation}
		m\ddot{x} + kx = f(t) = Acos(\Omega t)
		\label{eq2}
	\end{equation}
	dove la forzante $f(t)$ varia armonicamente nel tempo, allora posso provare a creare una soluzione senza applicare integrali di convoluzione. Dobbiamo in primisi distinguere il problema secondo due condizioni differenti dette di \textit{risonanza} o \textit{non risonanza}. Se $\Omega \neq \omega$, la frequenza di oscillazione senza forzante, si dice che il sistema non è in risonanza e azzardo una forma per la soluzione particolare:
	$$
	x(t) = Bcos(\Omega t)
	$$
	in cui devo determinare la costante $B$. Per farlo, sostituisco questa forma di $x(t)$ nella (\ref{eq2}):
	$$
	-mB \Omega^{2}cos(\Omega t) + kBcos(\Omega t) = Acos(\Omega t)
	$$
	dovendo valere $\forall t$, posso semplificare il termine $cos(\Omega t)$ e ottenere:
	$$
	-mB \Omega^{2} + kB = A \>\>\> \Longrightarrow \>\>\> B = \dfrac{A}{m(\omega^{2}-\Omega^{2})}
	$$
	che in effetti dà problemi per $\Omega = \pm \omega$ (ma noi lo abbiamo escluso). La soluzione particolare, perciò, recita:
	$$
	x^{*}(t) = \dfrac{A}{m(\omega^{2}-\Omega^{2})}cos(\Omega t)
	$$
	Ora mi basta aggiungere la soluzione omogenea e sono a posto, scritta nella forma:
	$$
	x_{omo}(t) = C_{1}cos(\omega t) + C_{2}\sin(\omega t) 
	$$
	con $C_{1}, C_{2}$ costanti da determinare per matchare le condizioni iniziali. La soluzione completa è perciò:
	$$
	x(t) =  C_{1}cos(\omega t) + C_{2}sin(\omega t) + \dfrac{A}{m(\omega^{2}-\Omega^{2})}cos(\Omega t)
	$$
	E se fossi in condizione di risonanza? Il caso precedente è singolare per $\Omega = \omega$ poiché la loro differenza è a denominatore. Non potrei azzardare la stessa soluzione particolare. Ne cerco una nella forma (e lo faccio perché già so che in tali condizioni sono in risonanza):
	$$
	x(t) = Bt\>sin(\Omega t)
	$$
	È importante notare che, in questo caso, la soluzione particolare è sfalsata di $\pi/2$ rispetto alla forzante. Procedo a determinare il fattore $B$ ottenendo:
	$$
	B = -\dfrac{A}{2m\Omega }
	$$
	e quindi la soluzione completa, somma delle omogenea e della particolare, diventa:
	$$
	x(t) = C_{1}cos(\omega t) + C_{2}sin(\omega t) -\dfrac{A}{2m\Omega }t\>sin(\Omega t)
	$$
	Nel caso di risonanza, l'ampiezza della soluzione particolare tende all'infinito per $t\to\infty$. È importante osservare che, in casi di risonanza, la soluzione diverge asintoticamente in maniera lineare. Vedremo che esistono situazioni in cui tale dipendenza diventa esponenziale.
	
	Un ultimissimo breve appunto. Se l'equazione differenziale del moto ammette anche termini dissipativi, ad esempio:
	\begin{equation}\label{key}
		m\ddot{x} + \beta \dot{x} + kx = f(t) = f_0 \sin(\Omega t)
	\end{equation}
	Allora, anche in condizioni di risonanza, la soluzione non tende all'infinito. Semplicemente per $\Omega = \Omega_{ris}$ l'ampiezza di oscillazione è la massima. Questa ampiezza massima dipende in relazione inversamente proporzionale dal fattore $\beta$, $A_{max} \propto \beta^{-1}$, così che se $\beta\to0$, allora ritroviamo la crescita infinita $A_{max}\to \infty$. È anche importante sottolineare che, in presenza di attrito, la condizione di risonanza non è semplicemente:
	\begin{equation}\label{key}
		\Omega_{ris} = \omega_0
	\end{equation}
	intendendo con $\omega_0$ la pulsazione naturale del sistema imperturbato. Infatti, vale che:
	\begin{equation}\label{key}
		\Omega_{ris}^{2} = \omega_{0}^2 - \dfrac{\beta^{2}}{4m^{2}}
	\end{equation}
	Se il termine di differenza è piccolo (rispetto a $\omega_0$), allora la differenza fra $\Omega_{ris}$ e $\omega_{0}$ è un infinitesimo del secondo ordine.
	\newpage
	\subsection{Teoria del controllo}
	La teoria del controllo fa uso di forzanti applicate a sistemi fisici per modificare a proprio vantaggio alcune proprietà di interesse. Facciamo un esempio: immaginiamo un sistema dinamico che si trovi in uno stato di equilibrio (dunque in un punto fisso) $x_{s}$. Se questo viene perturbato, la normale dinamica del sistema procederà a farlo evolvere in una determinata maniera (ad esempio, spostandoci di poco da un punto di equilibrio instabile ce ne allontiamo indefinitamente). Noi vogliamo però limitare l'entità di queste evoluzioni cercando di interagire col sistema attraverso dei \textit{controlli}. In altre parole, applico al sistema delle forzanti $f(t)$ per controllare la sua evoluzione in seguito ad una perturbazione, di modo che sia sempre \textbf{sotto controllo}. L'entità e la forma analitica della forzante da applicare $f(t)$ viene stabilita in ragione della perturbazione applicata.
	
	
	Un esempio pratico di tale teoria risiede nella bicicletta. Quando pedaliamo, stiamo controllando un sistema dinamico molto instabile, passibile di caduta alla minima perturbazione. Eppure, il nostro cervello riesce a mettere in atto, istante per istante, una serie di micro-azioni (lievi sterzi del manubrio, spostamenti del peso, ...) calibrate in funzione dell'entità della perturbazione di modo che l'equilibrio venga sempre mantenuto in maniera quasi-stabile. E noi non cadiamo.
	
	\subsection{Stabilizzare un oscillatore iperbolico}
	Consideriamo una situazione in cui si abbia a che fare con un oscillatore iperbolico (come ad esempio il caso di un pendolo rovesciato per piccoli angoli dalla verticale). Il flusso di fase per questi sistemi non è limitato nello spazio delle fasi e la soluzione può tendere all'infinito (o, nel caso del pendolo rovesciato, allontanarsi definitivamente dal punto di equilibrio instabile. L'equilibrio instabile del pendolo rovesciato è iperbolico solo in intorni del punto critico stesso). L'energia meccanica dell'oscillatore iperbolico è:
	$$
	E = \dfrac{p^{2}}{2m} - \dfrac{1}{2}kx^{2}
	$$
	Disegno le curve di livello per questo sistema, una famiglia di iperboli con energia positiva o negativa:
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-3.5,0) -- (3.5,0) node[right] {$x$};
			\draw[->] (0,-3) -- (0,3) node[above] {$p$};
			\draw[domain=-2.6:2.6, samples=50] plot (\x,{sqrt(1+\x*\x)});
			\draw[domain=-2.6:2.6, samples=50] plot (\x,{sqrt(3+\x*\x)});
			\draw[domain=-2.6:2.6, samples=50]   plot (\x,-{sqrt(1+\x*\x)});
			\draw[domain=-2.6:2.6, samples=50] plot (\x,-{sqrt(3+\x*\x)});
			\draw[domain=-2.6:2.6, samples=50]   plot ({sqrt(1+\x*\x)}, \x);
			\draw[domain=-2.6:2.6, samples=50]   plot ({sqrt(3+\x*\x)}, \x);
			\draw[domain=-2.6:2.6, samples=50]   plot (-{sqrt(1+\x*\x)}, \x);
			\draw[domain=-2.6:2.6, samples=50]   plot (-{sqrt(3+\x*\x)}, \x);
			\draw[dotted, domain=-3:3] plot (\x,{\x})node[anchor = west]{$p=x\sqrt{mk}$};
			\draw[dotted, domain=-3:3] plot (\x,{-\x})node[anchor = west]{$p=-x\sqrt{mk}$};
		}
	\end{figure}
	Abbiamo anche lo zero dell'energia, che corrisponde ai due asintoti (che sono rette date dall'equazione $p=\pm\sqrt{mk}x$) ma corrisponde anche al valore di energia del punto critico (l'origine). Quindi la curva di livello ad energia nulla è singolare e contiene il punto critico.
	Poiché è un punto fisso, l'origine è una soluzione stabile e nessun altra soluzione dovrebbe poter passare dallo zero. Ne deduco che, muovendomi sugli asintoti, posso tendere verso il punto critico nell'origine, ma devo farlo in tempo infiniti. Quindi in realtà, per la curva di livello a $E=0$ ho 5 soluzioni diverse: una del punto fisso stabile, due rami degli asintoti che tendono verso il punto fisso in tempi infiniti e due soluzioni che tendono all'infinito partendo in prossimità dell'origine. I due asintoti sono singolari (d'altronde non posso definire una tangente a questi nell'origine poiché è un punto angoloso).
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-3.5,0) -- (3.5,0) node[right] {$x$};
			\draw[->] (0,-3) -- (0,3) node[above] {$p$};
			\draw[->] (0,0) -- (3,3);
			\draw[->] (0,0) -- (1,1);
			\draw[->] (0,0) -- (2,2);
			\draw[] (3,-3) -- (0,0);
			\draw[->] (3,-3) -- (1,-1);
			\draw[->] (3,-3) -- (2,-2);
			\draw[domain=-3:3] plot (\x,{-\x})node[anchor = west]{$p=-x\sqrt{mk}$};
			\draw[domain=-3:3] plot (\x,{\x})node[anchor = west]{$p=x\sqrt{mk}$};
			\draw[->] (-3,3) -- (0,0);
			\draw[->] (-3,3)--(-1,1);
			\draw[->] (-3,3)--(-2,2);
			\draw[->] (0,0) -- (-3,-3);
			\draw[->] (0,0)--(-1,-1);
			\draw[->] (0,0)--(-2,-2);
			\node[rotate=-45] (A) at (-1.23,1.7) {$t\to\infty$};
			\draw[fill = black] (0,0) circle (1pt);
			\draw[fill = black] (1.6,-1.6) circle (1.5pt)node[anchor = south west]{$x_{0}$};
		}
		\caption{\textit{La curva di livello ad energia nulla è singolare (infatti in $(0,0)$ è nullo il gradiente e, di conseguenza, non è definita una tangente). In questo caso, tale curva ingloba 5 soluzioni differenti, i $4$ rami dell'asintoti e il punto fisso all'origine. Partendo ad esempio dallo stato iniziale $x_{0}$, il sistema si avvicinerà al punto fisso seguendo la retta $p = -\sqrt{mk}x$. Per non violare il teorema di unicità ed esistenza, tale sistema non potrà mai portarsi in tempi finiti nello stato $x_{s}=0$ e, al massimo, vi tenderà asintoticamente.}}
	\end{figure}
	
	Questo punto fisso è detto punto iperbolico ed è instabile: nei suoi intorni, le soluzioni tendono ad allontanarsi indefinitamente dall'origine.
	\subsubsection{Meglio iperbolico o ellittico?}
	Abbiamo per ora incontrato due tipi di punti fissi nello spazio delle fasi di sistemi unidimensionali, i punti ellittici (tipici degli oscillatori armonici) ed i punti iperbolici (propri degli oscillatore iperbolici). 
	
	Tornando alla teoria del controllo, saremmo tentati di affermare che è meglio lavorare con sistemi configurati in intorni di punti ellittici (laddove ne esistano) perché, una volta perturbati dall'equilibrio, questi non se ne allontano ma gli orbitano attorno stabilmente.
	Eppure non è così: la stazione spaziale o gli aerei che volano tendono sempre a stare in punti di tipo iperbolico, non ellittico. Perché? 
	
	In intorni del punto iperbolico, per quanto appena detto, divergo, ma lo faccio abbastanza lentamente (la velocità è vicina allo zero). Il tempo che ci metto a percorrere queste curve è abbastanza alto. Questo mi dà tempo per "riflettere" sulla forzante che voglio applicare per tornare in una condizione stabile.
	Non solo: le curve iperboliche hanno la particolare proprietà che, partendo da un certo $(x,-p)$, allora passerò di sicuro per $(x,p)$ grazie alla normale evoluzione del sistema. Una volta giunto in questo nuovo stato \textit{ribaltato}, mi basta dare un impulso istantaneo per ritornare in $(x,-p)$ e ricominciare daccapo. In altre parole, spendo poca energia ma riesco ugualmente a mantenere stabile il sistema (come in Fig. \ref{TeoriaContr})
	
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-.5,0) -- (3.5,0) node[right] {$x$};
			\draw[->] (0,-2.2) -- (0,2.2) node[above] {$p$};
			\draw[domain=-2:2, samples=50,->]   plot ({sqrt(1+\x*\x)}, \x);
			\draw[domain=-1:1, samples=50,->]   plot ({sqrt(1+\x*\x)}, \x);
			\node[anchor= north west, scale = 0.8]  (A) at (1.8,1.5) {$(p,x)$};
			\draw[] (1.8,1.5) -- (1.8,-1.5);
			\draw[->] (1.8,1.5) -- (1.8,0.5);
			\draw[->] (1.8,1.5) -- (1.8,-0.5);
			
			\draw[dotted, domain=0:2] plot (\x,{\x});
			\draw[dotted, domain=0:2] plot (\x,{-\x});
			
		}
		\label{TeoriaContr}
		\caption{\textit{Stabilizzare un oscillatore iperbolico. Basta operare con un impulso istanteaneo di entità $2p$.}}
	\end{figure}
	
	
	
	
	Perché tutto ciò non vale per sistemi in intorni di punti ellittici? L'idea è che in tali casi, l'unico controllo che mi stabilizzerebbe l'orbita sarebbe una dissipazione (ad esempio c'è l'attrito che riporta nella posizione di minimo). Però non sempre c'è attrito o, magari, esso è trascurabile. Detto in breve, non possiamo sfruttare la dinamica stessa del sistema per rimanere in intorni del punto con poca spesa di energia (nel caso iperbolico, c'è una tratta in cui mi avvicino al punto iperbolico). In un certo senso, è più semplice controllare sistemi instabili che sistemi stabili.
	\subsection{Un problema di controllo}
	Proviamo ad essere più quantitativi e risolvere un problema classico della teoria del controllo. Ci mettiamo nelle situazioni di un sistema ad oscillatore iperbolico\footnote{Questo, a dirla tutta, è un rotatore iperbolico. La descrizione però è simile perché, attraverso un cambio di coordinate lineare, posso tornare alla situazione fisica in cui $x,p$ rappresentano le variabili di stato fisiche (posizione-impulso).} caratterizzato dalla matrice $A$:
	\begin{equation}
		A = 
		\begin{pmatrix}
			0 & \omega \\
			\omega & 0
		\end{pmatrix}
	\end{equation}
	
	Supponiamo di partire da una condizione iniziale $(0,p_{0})$ che non è chiaramente di equilibrio. Il destino naturale del sistema sarebbe quello di divergere verso l'infinito, seguendo un'iperbole nello spazio delle fasi.
	
	Ci poniamo ora la domanda fondamentale della teoria del controllo: se io ho modo di inserire un controllo, una forzante $f(t)$ che influenza il sistema, posso sceglierla in modo che il destino del mio sistema sia di mantenere un orbita periodica nelle vicinanze del punto iperbolico, perché non diverga all'infinito? Ad esempio, prendiamo il pendolo rovesciato\footnote{Il pendolo rovesciato segue un'equazione differenziale del tipo $\ddot{\theta} = \omega^{2}\theta$ per piccole oscillazioni, dove $\theta$ è l'angolo dalla verticale ("rovesciata"). Per piccoli angoli attorno alla posizione di verticalità, il pendolo si comporta come un oscillatore iperbolico (e infatti diverge dal punto di equilibrio)}: se parte con una piccola velocità, riesco a mantenerlo rovesciato perturbando il sistema con una forzante $f(t)$?
	\begin{figure}
		\centering 
		\tikz{
			\draw[fill=gray] (0,0) rectangle (4,.25);
			\draw (2,.25) -- (1,2);
			\draw[dotted] (2,.25) -- (2,2);
			\draw[fill = black] (1,2) circle (5 pt);
			\filldraw[fill=gray!20!white, draw=gray!60!black] (2,.25) -- (2,.75) arc (90:95.3:3) -- (2,.25);
			\node[anchor = east] (A) at (1.75,.55) {$\theta$};
			\draw[->] (2.5,.55) -- (3.5,.55) node[anchor = south]{$f(t)$};
		}
		\caption{\textit{Pendolo rovesciato come esempio di un sistema che, a patto di avere piccole oscillazione, è un oscillatore iperbolico. Posso applicare una forzante $f(t)$ (ad esempio applicando una forza al sostegno di base) nella speranza di stabilizzare il sistema una volta perturbato}}
	\end{figure}
	
	Ipotizziamo di poter applicare un controllo periodico sul sistema del tipo:
	\begin{equation}
		f(t) = A \sin(\Omega t)
		\label{ControlloSeno}
	\end{equation}
	e vogliamo calibrare i parametri di $f$ di modo che, usando questo controllo e imponendo la condizione iniziale ($(x_{0}, p_{0}) = (0,p_{0})$), io arrivi ad una soluzione periodica. Chiaramente non è garantito che un tale controllo possa esistere e, anche esista, non è detto abbia la forma di (\ref{ControlloSeno}). Per ora è un azzardo, vedremo a posteriori se esistono dei parametri $\Omega$ e $A$ che soddisfino le nostre richieste.
	
	Per trovare la soluzione generale del moto, procedo come abbiamo già mostrato nel caso dell'oscillatore armonico forzato (solo che in questo caso l'oscillatore è iperbolico). Dovrò risolvere la:
	\begin{equation}
		\begin{pmatrix}
			\dot{x} \\ \dot{p}
		\end{pmatrix}
		= 
		\begin{pmatrix}
			0 & \omega \\
			\omega & 0
		\end{pmatrix}
		\begin{pmatrix}
			x \\ p
		\end{pmatrix}
		+ \begin{pmatrix}
			0 \\ f(t)
		\end{pmatrix}
	\end{equation} 
	La matrice $A$ è allora:
	\begin{equation}\label{key}
		A = \begin{pmatrix}
			0 & \omega \\
			\omega & 0
		\end{pmatrix} =
		\omega \begin{pmatrix}
			0 & 1 \\
			1 &0
		\end{pmatrix}
	\end{equation}
	Questa purtroppo non è una matrice antisimmetrica e quindi non riconosciamo un isomorfismo con i numeri complessi. Però notiamo che:
	\begin{equation}\label{key}
		A^2 = \omega^{2} \begin{pmatrix}
			1 & 0 \\
			0 & 1
		\end{pmatrix} = \omega^2 I
	\end{equation}
	In generale, allora, varrà che:
	\begin{equation}
		A^{2m} = \omega^{2m} \begin{pmatrix}
			1 & 0 \\
			0 & 1
		\end{pmatrix}
		= \omega^{2m} I
	\end{equation}
	\begin{equation}
		A^{2m+1} = \omega^{2m+1} \begin{pmatrix}
			0 & 1 \\
			1 &0
		\end{pmatrix}
		= \omega^{2m+1} I'
	\end{equation}
	Allora dalla definizione di esponenziale di matrice:
	\begin{equation}
		\begin{aligned}
			e^{At} &= \sum_{n=0}^{\infty} \dfrac{A^{n}}{n!}t^{n} = \sum_{m=0}^{\infty}\dfrac{A^{2m}}{(2m)!}t^{2m} + \sum_{m=0}^{\infty}\dfrac{A^{2m+1}}{(2m+1)!}t^{2m+1} =  I \sum_{m=0}^{\infty}\dfrac{\omega^{2m}}{(2m)!}t^{2m} + I' \sum_{m=0}^{\infty}\dfrac{\omega^{2m+1}}{(2m+1)!}t^{2m+1} \\
			&= I \sum_{m=0}^{\infty}\dfrac{(\omega t)^{2m}}{(2m)!} + I' \sum_{m=0}^{\infty}\dfrac{(\omega t)^{2m+1}}{(2m+1)!} = I \cosh(\omega t) + I'\sinh(\omega t)
		\end{aligned}
	\end{equation}
	e quindi:
	\begin{equation}\label{key}
		e^{At} = \begin{pmatrix}
			\cosh(\omega t) & \sinh(\omega t) \\
			\sinh(\omega t) & \cosh(\omega t)
		\end{pmatrix}
	\end{equation}
	e quindi, usando il solito metodo per le forzanti, dovremo risolvere per la soluzione particolare:
	\begin{equation}\label{key}
		x^{*}(t) = A \int_{0}^{t}\sinh(\omega (t-s))\sin(\Omega s) ds
	\end{equation}
	a cui aggiungeremo la soluzione omogenea. Svolgiamo l'integrale per parti:
	\begin{equation}\label{key}
		\begin{aligned}
			x^{*}(t) &= A \int_{0}^{t}\sinh(\omega (t-s))\sin(\Omega s) ds = A\Bigl[\Bigl(\sinh(\omega(t-s)) \dfrac{-\cos(\Omega s)}{\Omega}\Bigl)\Bigl|_{0}^{t} - \int_{0}^{t}\omega\cosh(\omega(t-s)) \dfrac{\cos(\Omega s)}{\Omega}ds\Bigl] =
			\\ 
			&= A\Bigl[\dfrac{1}{\Omega}\sinh(\omega t)- \dfrac{\omega}{\Omega}\int_{0}^{t}\cosh(\omega(t-s))\cos(\Omega s)ds\Bigl] = 
			\\
			&= A \Bigl[\dfrac{1}{\Omega}\sinh(\omega t) - \dfrac{\omega}{\Omega}\Bigl(\dfrac{1}{\Omega}\cosh(\omega(t-s))\sin(\Omega s)\Bigl)\Bigl|_{0}^{t}-\dfrac{\omega^2}{\Omega^2}\int_{0}^{t}\sinh(\omega(t-s))\sin(\Omega s)ds\Bigl] =\\
			&= A\Bigl(\dfrac{1}{\Omega}\sinh(\omega t)
			- \dfrac{\omega}{\Omega^2}\sin(\Omega t) - \dfrac{\omega^2}{\Omega^2}\dfrac{x^{*}(t)}{A}\Bigl) = \\
			&= A \dfrac{\omega}{\Omega}\Bigl(\dfrac{1}{\omega}\sinh(\omega t)-\dfrac{1}{\Omega}\sin(\Omega t)- \dfrac{\omega}{\Omega}\dfrac{x^{*}(t)}{A}  \Bigl) 
		\end{aligned}
	\end{equation}
	e quindi, volendo isolare la soluzione $x^{*}(t)$, otteniamo che:
	\begin{equation}\label{key}
		\dfrac{\Omega}{\omega} \dfrac{x^{*}(t)}{A} = \dfrac{1}{\omega}\sinh(\omega t) - \dfrac{1}{\Omega}\sin(\Omega t) - \dfrac{\omega}{\Omega} \dfrac{x^{*}(t)}{A}
	\end{equation}
	\begin{equation}\label{key}
		\dfrac{x^{*}(t)}{A} \Bigl(\dfrac{\Omega}{\omega} + \dfrac{\omega}{\Omega}\Bigl)=\dfrac{\Omega\sinh(\omega t)-\omega\sin(\Omega t)}{\omega\Omega}
	\end{equation}
	\begin{equation}\label{key}
		\dfrac{x^{*}(t)}{A} \Bigl(\dfrac{\Omega^2+\omega^2}{\omega \Omega}\Bigl)=\dfrac{\Omega\sinh(\omega t)-\omega\sin(\Omega t)}{\omega\Omega}
	\end{equation}
	\begin{equation}\label{key}
		x^{*}(t)= A \dfrac{1 }{\Omega^2+\omega^2}\Bigl(\Omega\sinh(\omega t) - \omega\sin(\Omega t)\Bigl)
	\end{equation}
	Infine valutiamo la soluzione omogenea che è quella di un oscillatore iperbolico con le giuste condizioni iniziali, cioè $x(0)= 0, p(0) = p_0$:
	\begin{equation}\label{key}
		x_{omo}(t) = p_0 \sinh(\omega t)
	\end{equation}
	La soluzione finale del sistema, sommando l'omogenea e la particolare recita allora
	\begin{equation}
		x(t) = p_{0}\sinh(\omega t) + A \dfrac{1 }{\Omega^2+\omega^2}\Bigl(\Omega\sinh(\omega t) - \omega\sin(\Omega t)\Bigl)
	\end{equation}
	
	Come ci aspettavamo, nella soluzione compaiono dei termini proporzionali a seni e coseni iperbolici. Sono loro la componente problematica di cui vorremmo sbarazzarci, poiché fanno divergere all'infinito la soluzione per $t\to\infty$. Per annullarli, basterà raccogliere i termini in $\sinh$:
	\begin{equation}\label{key}
		x(t) = \sinh(\omega t)\Bigl(p_0+ A \dfrac{\Omega}{\omega^2+\Omega^2}\Bigl) - A\dfrac{\omega}{\omega^2+\Omega^2}\sin(\Omega t)
	\end{equation}
	e annullarli, dunque porre:
	$$
	A = -\dfrac{\omega^{2} + \Omega^{2}}{\Omega}p_{0}
	$$
	cioè agire con una forzante del tipo:
	\begin{equation}
		f(t) = -p_{0}\dfrac{\omega^{2} + \Omega^{2}}{\Omega} \cos(\Omega t)
		\label{ForzanteControllo}
	\end{equation}
	In tal caso, la soluzione si riduce a:
	\begin{equation}
		x(t) = p_0\dfrac{\omega}{\Omega}\cos(\Omega t)
	\end{equation}
	che è limitata e periodica di pulsazione $\Omega$, quella della forzante (che dunque non ha vincoli, posso agire con la frequenza che preferisco). Ho risolto il problema: per stabilizzare un sistema iperbolico che è stato perturbato nello stato $(0,p_{0})$, basterà agire con una forzante (\ref{ForzanteControllo}) ed il sistema si manterrà in orbite periodiche!
	
	
	\subsection{Come funziona l'altalena: risonanza parametrica}
	Un altro esempio di teoria del controllo applicata nella vita quotidiana consiste nell'altalena. Vediamo come funziona.
	
	Formuliamo dapprima il modello fisico.
	Il filo dell'altalena è un vincolo ed è di lunghezza costante. Le forze in gioco sono quella peso e la reazione vincolare della fune. Scompongo la forza peso in una componente normale al vincolo e una componente tangente al vincolo: è proprio quest'ultima che mi riporta verso la condizione di equilibrio e, essendo questo un sistema conservativo, dovrebbe conservare l'energia. Eppure, nell'altalena, è possibile aumentare nel tempo l'ampiezza dell'oscillazione e, perciò, aumentare la propria energia. Ma allora chi fa lavoro? Quale forza fa lavoro?
	
	Una cosa però cambia, e cioè che chi sta sull'altalena alza e abbassa continuamente le gambe mentre oscilla. Questo gesto istintivo si traduce in un innalzamento/abbassamento del baricentro e, poiché la lunghezza della corda è legata proprio alla posizione del baricentro, quest'ultima non si mantiene invariata. Perciò possiamo modificare la lunghezza della corda a piacere. Spostando il baricentro, la traiettoria non è più esattamente circolare, ed è ora la reazione vincolare che può fare lavoro (e lo fa)\footnote{L'energia viene comunque fornita dal bambino che sta sull'altalena. Alzare le gambe (alzare il suo centro di massa) non gli è indolore e gli costa fatica. D'altronde nel suo sistema di riferimento il bambino è \textit{schiacciato} sul sellino dalla forza fittizia centrifuga e, per alzare le gambe, deve compiere lavoro. Nel sistema di riferimento inerziale, la reazione vincolare agisce in direzione normale, ma è proprio questa direzione che si allunga/accorcia in seguito ai movimenti del bambino. C'è una spostamento in seguito ad una forza a lui parallelo, e dunque diremo che la reazione vincolare fa lavoro. L'energia è però fornita dal bambino, a spese della sua energia interna.}.
	
	
	Il controllo che stiamo facendo sull'altalena è qualcosa di diverso rispetto a quelli già visti in precedenza. La forzatura non è infatti una funzione distribuita nel tempo (come se fosse una sinusoide, per intendersi) ma è piuttosto qualcosa di istantaneo (arrivati all'ampiezza massima, allungo le gambe subito). Ed inoltre è improprio parlare di forzatura, poiché nel caso dell'altalena sto semplicemente variando un parametro del modello, la lunghezza della corda. La risonanza innescata dalla variazione di un parametro è detta \textit{risonanza parametrica} ed è un po' diversa da quella indotta da una forzante esterna: ha un'evoluzione temporale di tipo esponenziale invece di essere lineare.
	
	Resta comunque da dimostrare che il cambiare lunghezza della fune possa generare effetti di risonanza (parametrica). Andiamo dunque a considerare il problema in forma lineare e scriviamo il moto delle piccole oscillazioni definito dall'equazione differenziale usuale:
	$$
	\ddot{\theta} = -\omega^{2} \theta
	$$
	con 
	$$
	\omega = \dfrac{g}{l} \>\>\> (=\omega_{0})
	$$
	e trascuriamo gli attriti. Siano poi $l_{d} > l_{u}$ le lunghezze a gambe abbassate e alzate della fune e siano $\omega_{-}, \omega_{+}$ le due frequenze dell'oscillatore a seconda della posizione delle gambe. Supponiamo che la loro differenza $2\varepsilon$ sia abbastanza piccola rispetto al valore centrale $\omega$:
	$$
	\omega_{+/-} = \omega \pm \varepsilon
	$$
	La dinamica è di tipo impulsivo, nel senso che l'atto di abbassare/alzare le gambe viene effettuato in un tempo pari a $0$, perciò avremo:
	$$
	\ddot{\theta} = -\omega^{2}(t)\theta
	$$
	essendo:
	\begin{equation}
		\omega(t) =
		\begin{cases}
			\omega_{-} \mbox{ se } t \in [2n\tau, (2n+1)\tau] \\
			\omega_{+} \mbox{ se } t \in[(2n+1)\tau, (2n+2)\tau]
		\end{cases}
	\end{equation}
	Avendo introdotto un tempo $\tau$. Il grafico di $\omega(t)$ è un'onda quadra\footnote{Per ora $\tau$ è un intervallo temporale a caso, che dovremo determinare una volta imposta la condizione di risonanza. È però già chiaro che l'effetto di "altalena crescente" si ottiene se il cambio di gamba viene fatto con lo stesso periodo dell'oscillazione dell'altalena, perciò probabilmente $2\tau = T = 2\pi/\omega$} di periodo $2\tau$.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[domain=0:4] 
			\draw[->] (-0.2,0) -- (4.2,0) node[right ] {$t$}; 
			\draw[->] (0,-.2) -- (0,4.2) node[above] {$\omega(t)$};
			\draw (0,1.8) -- (1.8,1.8)node[anchor = south east]{$\omega_{-}$};
			\draw (1.8,2.2) -- (3.6,2.2)node[above]{$\omega_{+}$};
			\draw[dotted] (1.8,2.2) -- (1.8,0) node[below]{$\tau$};
			\draw[dotted] (3.6,2.2) -- (3.6,0) node[below]{$2\tau$};
		\end{tikzpicture}
		\caption{\textit{Grafico della pulsazione in funzione del tempo. Si tratta sostanzialmente di un'onda quadra.}}
	\end{figure}
	
	In ogni intervallo di tempo $\Delta t = \tau$, il il sistema si comporta come un oscillatore armonico di una certa pulsazione di cui conosco bene la matrice di flusso di fase\footnote{D'ora in poi, sia $x$ la coordinata angolare, $x = \theta$ e $p$ il suo momento}:
	\begin{equation}
		\begin{pmatrix}
			x(t) \\ p(t)
		\end{pmatrix}
		= 
		\begin{pmatrix}
			cos(\omega t) & \dfrac{1}{\omega}sin(\omega t)\\
			-\omega sin(\omega t) & cos(\omega t)
		\end{pmatrix}
		\begin{pmatrix}
			x_{0} \\ p_{0}
		\end{pmatrix}
		=
		\phi_{\omega}^{t}(x_{0})
	\end{equation}
	dove $\omega$ assume il valore di $\omega_{+}$ o $\omega_{-}$ a seconda della posizione delle gambe. Ne segue che per calcolare cosa succede dopo un $\Delta t = 2\tau$, mi basta combinare le due matrici di flusso di fase $\phi_{\omega_{-}} \mbox{ e }\phi_{\omega_{+}}$:
	$$
	M^{2\tau} = \phi^{2\tau}_{\omega(t)} = \phi_{\omega_{-}} \circ \phi_{\omega_{+}}
	$$
	Così facendo, mi concentro solo sullo stato dell'altalena negli istanti temporali $t=2n\tau $.
	Questo tipo di approccio alla risoluzione di certi sistemi dinamici si chiama \textit{mappa di Poincaré} e consente di descrivere l'evoluzione del sistema in maniera stroboscopica, cioè andandolo a studiare dopo ogni periodo e ignorarne l'evoluzione interna. 
	
	Svolgiamo ora i calcoli:
	\begin{equation}
		M^{2\tau} = 
		\begin{pmatrix}
			cos(\omega_{-} t) & \dfrac{1}{\omega_-} sin(\omega_{-} t)\\
			-\omega_{-} sin(\omega_{-} t) & cos(\omega_{-} t)
		\end{pmatrix}
		\begin{pmatrix}
			cos(\omega_{+} t) & \dfrac{1}{\omega_+}sin(\omega_{+} t)\\
			-\omega_+ sin(\omega_{+} t) & cos(\omega_{+} t)
		\end{pmatrix}
		\label{MatriceAltalena}
	\end{equation}
	
	
	La matrice di (\ref{MatriceAltalena}) permette dunque di valutare l'evoluzione discreta del sistema. Per vedere cosa succede dopo $n$ periodi, dovremo studiare le varie potenze di $M^{2\tau}$,
	$$
	(M^{2\tau})^{n}
	$$
	e questa cosa non è molto comoda, essendo la matrice particolarmente complicata. Possiamo però servirci di un trucchetto. Essendo la matrice $M^{2\tau}$ simmetrica, allora deve esistere una trasformazione lineare dello spazio delle fasi $(x,p)\to(x',p')$, dove $x$ è una combinazione lineare di $x',p'$ e idem per $p$, per la quale la matrice $M^{2\tau}$ assume una forma diagonale. Questa cosa è comoda perché l'elevamento a potenza di una matrice in forma diagonale è particolarmente facile:
	\begin{equation}\label{key}
		\begin{pmatrix}
			a & 0 \\
			0 & b
		\end{pmatrix}^{n} = 
		\begin{pmatrix}
			a^n & 0 \\
			0 & b^n
		\end{pmatrix}
	\end{equation}
	Nelle nuova base dei $x',p'$ la matrice $M^{2\tau}$ assume allora la forma diagonale:
	\begin{equation}\label{key}
		M^{2\tau} =
		\begin{pmatrix}
			\lambda_1 & 0 \\
			0 & \lambda_2
		\end{pmatrix}
	\end{equation}
	\begin{equation}\label{key}
		(M^{2\tau})^{n} =
		\begin{pmatrix}
			\lambda_1^n & 0 \\
			0 & \lambda_2^n
		\end{pmatrix}
	\end{equation}
	dove $\lambda_{1},\lambda_{2}$ sono i due autovalori della matrice. Dunque, per valutare l'evoluzione dinamica discreta delle coordinate $(x',p')$ ci basterà studiare come si comportano gli autovalori della matrice (che, ricordiamo, sono invarianti per trasformazioni lineari). Se il sistema è stabile nelle coordinate $x',p'$, allora lo sarà anche nelle coordinate iniziali $x,p$ (poiché la trasformazione è lineare e, dunque, limitata).
	
	Studiamo allora gli autovalori di (\ref{MatriceAltalena}). So già a priori che questa matrice segue certe proprietà. In particolare, $detM^{2\tau} = 1$, poiché prodotto di due matrici a determinante unitario (formula di Binet). Poiché il determinante è il prodotto degli autovalori, allora
	$$
	\lambda_{1} \lambda_{2} = 1
	$$
	Quindi gli autovalori sono $\lambda \mbox{ e } \dfrac{1}{\lambda}$. Se $\lambda$ è puramente reale, allora uno è maggiore di 1, l'altro autovalore minore. Questo però significa che l'autovalore maggiore di $1$ tende a crescere iterando la mappa di Poincaré, cioè nel tempo. Concludiamo che allora se $\lambda$ è reale, sicuramente la soluzione tende a divergere all'infinito (cioè l'altalena funzione per come ce la aspettiamo).
	
	Se invece $\lambda$ fosse complesso, allora l'altro autovalore è il suo complesso coniugato. Questo perché il loro prodotto è reale (e pari a 1).
	$$
	\lambda_1 = Ae^{i\omega t}, \lambda_2 = \dfrac{1}{A}e^{-i\omega t}
	$$ 
	Se $A = 1$, allora i due autovalori hanno entrambi modulo unitario e l'elevamento a potenza ha solo l'effetto di ruotare nel piano complesso, senza amplificare il modulo, compiendo oscillazioni attorno alla posizione di equilibrio. L'altalena non funzionerebbe.  
	Devo dunque cercare di capire quale sia il modulo di questi due autovalori per valutare la stabilità o l'instabilità dell'altalena.
	
	
	Dall'algebra lineare, ricordo che:
	$$
	\lambda + \dfrac{1}{\lambda} = Tr(M^{2\tau})
	$$
	
	Calcolo la traccia della matrice, che diventa:
	\begin{equation}\label{key}
		\lambda + \dfrac{1}{\lambda} = \cos(\omega_- t)\cos(\omega_+ t)-\dfrac{\omega_+}{\omega_-}\sin(\omega_- t)\sin(\omega_+ t) - \dfrac{\omega_-}{\omega_+} \sin(\omega_- t)\sin(\omega_+ t) + \cos(\omega_- t)\cos(\omega_+ t)
	\end{equation}
	\begin{equation}\label{key}
		= 2\cos(\omega_- t)\cos(\omega_+ t) - \Bigl(\dfrac{\omega_+}{\omega_-}+\dfrac{\omega_-}{\omega_+}\Bigl)\sin(\omega_- t)\sin(\omega_+ t)
	\end{equation}
	Ora cerco di approsimare il termine con gli $\omega$, perché essi sono distanti da $\omega_0$ per un infinitesimo del primo ordine, cioè $\omega_{+/-} = \omega_{0} \pm \varepsilon$:
	\begin{equation}\label{key}
		\begin{aligned}
			\dfrac{\omega_+}{\omega_-}+\dfrac{\omega_-}{\omega_+} &= \dfrac{\omega_+^2 + \omega_-^2}{\omega_- \omega_+} = 2 \dfrac{\omega_0^2+\varepsilon^2}{\omega_0^2 - \varepsilon^2} = 2 \dfrac{1+\Bigl(\dfrac{\varepsilon}{\omega_0}\Bigl)^2}{1-\Bigl(\dfrac{\varepsilon}{\omega_0}\Bigl)^2} \approx \\
			&\approx 2\Bigl(1+2\Bigl(\dfrac{\varepsilon}{\omega_0}\Bigl)^2+2\Bigl(\dfrac{\varepsilon}{\omega_0}\Bigl)^4\Bigl)
		\end{aligned}
	\end{equation}
	Avendo all'ultimo passaggio espanso con Taylor. La traccia allora diventa:
	\begin{equation}\label{key}
		\begin{aligned}
			Tr(M) &=2\Bigl[\cos(\omega_- t)\cos(\omega_+ t) - \sin(\omega_- t)\sin(\omega_+ t) - \dfrac{2\varepsilon^2}{\omega_0^2}\Bigl(1+\dfrac{2\varepsilon^2}{\omega_0^2}\Bigl)\sin(\omega_- t)\sin(\omega_+ t) \Bigl] = \\
			&= 2\Bigl[cos(2\omega_0 t) - \dfrac{2\varepsilon^2}{\omega_0^2}\sin(\omega_- t)\sin(\omega_+ t) \Bigl]
		\end{aligned}
	\end{equation}
	777777777
	Se $\lambda = e^{i\omega t}$, la somma col suo complessa coniugato mi darebbe due volte la sua parte reale, $2cos(\omega t) < 2$. Al contrario, se $\lambda$ fosse reale, avremmo una quantità maggiore di 2. Calcolo la traccia (vedi slide). Vediamo se è maggiore di $2$. Se $\omega_{+} = \omega_{-}$, avremmo $cos(2...)$ che non può essere maggiore di 2, quindi in effetti senza questo cambiamento non c'è fenomeno di risonanza. Segui i calcoli da sua slide. Importanza di mettere la condizione $2\omega_{0}\tau = 2\pi$. Copia da slide sue (risonanze parametriche sono le più frequenti in natura, un po' più difficili da studiare)
	
	?linearizzo ogni volta adattando il periodo?
	
	
	E se considerassi la:
	$$
	m\ddot{\theta} = \varepsilon sin(\omega_{0} t)\theta
	$$
	non la saprei risolvere (equazione di Flake)
	
	
	Inoltre se avessi un rotatore invece di un oscillatore non riuscirei (non potrei modificare il vincolo, il raggio è fissato). Non tutti i sistemi hanno risonanze parametriche
	Conclusioni: esponenziale/lineare !!
	
	
	\newpage
	\section{Variabili azione angolo}
	Quando le traiettorie di un sistema fisico sono sempre chiuse, allora ha senso definire due nuove coordinate, dette di \textit{azione} e di \textit{angolo}, di grande utilità. Questo posso anche farlo in intorni di punti ellittici, dove ho la certezza che la buca di potenziale limiti le orbite del sistema ad essere chiuse (e quindi definisco delle variabili locali, definibili fino alla separatrice). 
	La variabile d'azione $I$ è definita:
	\begin{equation}\label{key}
		I = \dfrac{1}{2\pi} \oint_{H=E} p dx = \dfrac{A(E)}{2\pi}
	\end{equation}
	cioè rappresenta l'area di un'orbita nello spazio delle fasi (divisa per $2\pi$). Esplicitando $p$ a partire dalla legge di conservazione di energia,
	\begin{equation}\label{key}
		I = \dfrac{1}{2\pi} \oint_{H=E} \sqrt{2m(E-V(x))} dx 
	\end{equation}
	L'altra variabile è la variabile d'angolo $\theta$, che rappresenta l'angolo di un punto dell'orbita calcolato rispetto all'asse $x$. In altre parole, l'azione determina l'orbita su cui si muove, l'angolo determina il punto attuale dell'orbita stessa\footnote{Avrei potuto usare anche energia e tempo, come variabili al posto dell'azione/angolo. In fondo l'energia è una misura dell'area, dell'ampiezza dell'orbita. Il problema è che non tutte le orbite hanno lo stesso periodo temporale, mentre tutte le orbite hanno lo stesso periodo angolare (l'angolo $2\pi$ corrisponde per tutte le orbite al punto di ritorno alla condizione iniziale)}. La definizione formale dell'angolo $\theta$ è:
	\begin{equation}\label{key}
		\theta = \dfrac{\partial}{\partial I}\int_{H=E}^{x} \sqrt{2m(E-V(x))}
	\end{equation}
	ed è dunque funzione di $E$ ma anche di $x$:
	$$
	\theta = F(E,x)
	$$
	Oppure, essendo $E$ e $I$ legate fra di loro, posso pensarla come:
	$$
	\theta = F(I,x)
	$$
	Allora derivare rispetto a $I$ equivale a:
	$$
	\theta = \dfrac{dE}{dI}\dfrac{\partial}{\partial E} \int_{H=E}^{x} \sqrt{2m(E-V(x))} = \omega(E)\dfrac{\partial}{\partial E} \int_{H=E}^{x} \sqrt{2m(E-V(x))}
	$$
	Avendo definito:
	$$
	\omega(E) = \dfrac{dE}{dI}
	$$
	Faccio entrare la derivata rispetto all'energia e ottengo:
	$$
	\theta = \omega(E)\int_{H=E}^{x} \dfrac{mdx}{\sqrt{2m(E-V(x))}} = \omega(E) \int_{H=E}^{x}dt
	$$
	cioè, appunto, la variabile $\theta$ sembra descrivere l'avanzamento sull'orbita chiusa in funzione del tempo con una velocità angolare pari a $\omega$. In effetti, tale quantità:
	$$
	\omega(E) = \dfrac{dE}{dI} 
	$$
	è proprio la pulsazione di un'orbita, cioè legata al periodo dell'orbita stessa. D'altronde, se l'area vale:
	$$
	A(E) = \oint_{H=E} p dx = \oint_{H=E} \sqrt{2m(E-V(x))}dx = 2m\int_{x_1}^{x_2} \sqrt{\dfrac{2}{m}(E-V(x))}dx
	$$
	dove $x_1, x_2$ sono i due punti di inversione. Provo a derivare rispetto a $E$:
	\begin{equation}\label{key}
		\dfrac{dA}{dE} = 2m\dfrac{d}{dE} \int_{x_1}^{x_2} \sqrt{\dfrac{2}{m}(E-V(x))}dx = \int_{x_1}^{x_2} \frac{dx}{\sqrt{\dfrac{2}{m}(E-V(x))}} = T(E)
	\end{equation}
	E quindi, invertendo,
	\begin{equation}\label{key}
		\dfrac{dE}{dA} = \dfrac{1}{T(E)}
	\end{equation}
	Ma abbiamo visto che l'azione è definita come $I = \dfrac{A}{2\pi}$, quindi effettivamente:
	\begin{equation}\label{key}
		\dfrac{dE}{dI} = \omega
	\end{equation}
	Con l'introduzione delle variabili azione-angolo, le equazioni del moto assumono una forma molto semplice:
	\begin{equation}\label{key}
		\begin{cases}
			\dot{I} = 0 \\
			\dot{\theta} = \omega(I)
		\end{cases}
	\end{equation}
	\subsection{Azione-angolo nell'oscillatore}
	Introduco altre variabili (che non sarebbero immediatamente suggerite dalla fisica). Questo cambio di variabile però non è proprio indolore: se $\omega$ dipende dal tempo, quella sostituzione non è così facile (?). Faccio appunto un altro cambio di variabile:
	$$
	I = \dfrac{P^{2}+X^{2}}{2}
	$$
	$$
	\theta = arctan\Bigl(\dfrac{X}{P}\Bigl)
	$$
	l'energia dell'oscillatore diventa perciò:
	$$
	E = \omega I
	$$
	L'azione è l'area del cerchio definito dalla curva di livello in cui sta un orbita (divida per 2$\pi$). Ma sarà anche l'area delle ellissi iniziali? Si, quel cambio di variabili ha uno jacobiano pari a $1$ (l'area sottesa dall'orbita del rotatore = area sottesa dall'orbita dell'oscillatore = 2$\pi I$). Abbiamo cioe fatto un cambio di variabile che conserva la aree. Noi faremo sempre di queste cambi di variabile.
	
	La variabile $I$ è molto importante. Associato a $I$ c'è l'angolo $\theta$. Cioè praticamente:
	\begin{equation}
		\begin{cases}
			X = \sqrt{2I}sin(\theta) \\
			P = \sqrt{2I}cos(\theta)
		\end{cases}
	\end{equation}
	(N.B. seno e coseno sono invertiti ma ok così, in questo modo l'area è conservata, calcola nuovamento lo jacobiano e il suo determinante). Tutto ciò ha la proprietà di trasformare le equazioni principali, infatti l'energia del sistema oscillatore armonico diventa:
	$$
	E = I \omega
	$$
	e le equazioni del moto diventano:
	\begin{equation}
		\begin{cases}
			\dot{I} = 0 \\
			\dot{\theta} = \omega
		\end{cases}
	\end{equation}
	\begin{equation}
		\begin{cases}
			I = I_{0} \\
			\theta = \theta_{0} +\omega t
		\end{cases}
	\end{equation}
	che corrisponde in pratica a questa coppia di equazioni
	\begin{equation}
		\begin{cases}
			\dot{x} = p \\
			\dot{p} = -\omega^{2}x
		\end{cases}
	\end{equation}
	questo è lo scopo di tutto il corso. Uno parte da equazioni diff molto complicate da integrare e non integrarle ma utilizzare dei cambi di variabili per portare il sistema in delle forme in cui l'integrazione è banale (come qua con $I$ e $\theta$).
	
	In realtà, si puo dimostrare (lo fece Poincaré) che non sempre esiste un tale cambio di variabili. Se esiste, anche il set di equazioni diff originali era integrabile con certi metodi (tipo doppio pendolo, non c'è modo). STORIA INVARIANTE ADIABATICO
	
	
	
	\newpage
	\section{Introduzione alla meccanica lagrangiana}
	\subsection{Coordinate generalizzate}
	L'ambiente di lavoro della meccanica classica è lo spazio tridimensionale euclideo: in esso avvengono i fenomeni dinamici che siamo interessati a studiare.
	
	I punti $P$ dello spazio sono oggetti geometrici intrinseci e possono essere individuati facilmente una volta che attrezzo il mio spazio di un sistema di coordinate che mi permettano di mappare biunivocamente tutti i punti dello spazio tramite una rappresentazione univoca. La scelta a cui siamo spesso abituati è quella cartesiana, per cui è necessario individuare un punto $O$ di origine e 3 versori perpendicolari linearmente indipendenti (una base ortonormale, insomma). Dotato di questo sistema di coordinate, posso rappresentare il generico punto $P$ come una n-upla di numeri:
	\begin{equation}
		\vec{x}(P) = (x_{1}, x_{2}, ..., x_{n})
		\label{RapprP}
	\end{equation}
	che, almeno nella scelta cartesiana, sono uguali alla proiezione perpendicolare del raggio vettore $OP$ sui versori di base. Attenzione alla notazione: $P$ è un punto dello spazio mentre $\vec{x}(P)$ è il vettore $OP$. Anche il vettore è un oggetto geometrico, ma a differenza dell'oggetto punto $P$ ha bisogno di un origine, di un altro punto privilegiato nello spazio per poter esser definito. Posso poi rappresentare tale vettore mediante una serie di numeri, basta avere bene in mente che un vettore non è una lista di numeri. Un vettore è un vettore.
	\begin{tcolorbox}
		
		Una breve digressione matematica su spazi vettoriali e spazi euclidei. Indicheremo con $\mathbb{R}^{n}$ lo spazio lineare n-dimensionale delle n-uple di numeri reale, che è a tutti gli effetti uno spazio vettoriale.
		
		Chiamiamo $A^{n}$ lo \textbf{spazio affine} che differisce dallo spazio $\mathbb{R}^{n}$ per il fatto di non avere un origine fissata, un punto privilegiato. Tale spazio non è uno spazio vettoriale (non posso definire una somma, al massimo una differenza). Questo spazio è quello che utilizziamo matematicamente per modellizzare lo spazio fisico che ci circonda. Gli elementi di questo spazio affine sono più propriamente punti, non vettori. In generale, dato uno spazio affine, è possibile ricondursi ad uno spazio lineare scegliendo un punto $O$ da origine (al punto $P$ è associato il vettore di $\mathbb{R}^{n}$ che collega $O$ con $P$. La somma di questi vettori è chiaramente definita).
		
		Lo spazio affine tridimensionale è lo strumento naturale per modellizzare lo spazio della fisica classica, le cui leggi sono infatti indipendenti dalla scelta di un sistema di riferimento. Il punto $P$ di cui si parla, dunque, vive nello spazio affine della fisica. Quando fissiamo un origine e un set di coordinate cartesiane, allora ha senso parlare di raggio vettore $\vec{x}(P)$ per poterlo identificare.
		
		
		Uno \textbf{spazio euclideo} è uno spazio affine sul cui spazio vettoriale associato è stata introdotta una nozione di prodotto scalare (o equivalentemente di distanza) che corrisponde alla usuale definizione quando viene impiegata la base canonica standard.
		
	\end{tcolorbox}
	
	Ad ogni modo, la scelta della rappresentazione è decisamente arbitraria. Il punto $P$ dello spazio è un'entità geometrica che è indipendente dal set di coordinate di cui mi armo. Per fare un esempio, posso utilizzare (una volta fissata un origine comune) coordinate polari al posto delle coordinate cartesiane usuali e impiegare tre diversi numeri per rappresentare il medesimo punto nello spazio. Immaginiamo, perciò, di dotarci di un generico sistema di \textit{coordinate generalizzate }$q$ in cui ogni punto dello spazio può essere rappresentato tramite la n-upla di numeri:
	\begin{equation}
		\vec{x}(P) = (q_{1}, q_{2}, ..., q_{n})
	\end{equation}
	Così, ad esempio, impiegando delle coordinate polari nello spazio 2D, ogni punto del piano potrà essere individuato dalla coppia di numeri $(r, \theta)$ invece che dalla coppia di numeri $(x,y)$.
	\subsubsection{Il problema della scelta delle coordinate}
	L'equazione fondamentale della meccanica recita:
	\begin{equation}
		\vec{F} = m\vec{a}
	\end{equation}
	Le due quantità coinvolte, $\vec{F}$ e $\vec{a}$ sono vettori. I vettori, ricordiamolo, sono oggetti geometrici, astratti, propri della matematica. Noi non misuriamo mai vettori nella vita reale, così dobbiamo trovare un modo per "rappresentarli" attraverso cose che possiamo misurare, e cioè i numeri scalari\footnote{I vettori sono entità molto astratte, a ben pensarci. Nessuno fa esperienza di vettori. La loro comodità nasce dal fatto che essi sono oggetti geometrici indipendente da come li descriviamo e covarianti per cambi di sistemi di riferimento. Queste due proprietà sono le stesse proprietà che ci aspettiamo dalle leggi fondamentali della fisica, e quindi viene comodo impiegare il formalismo vettoriale in meccanica analitica. Il contro è che se vogliamo ritornare sul piano empirico, i vettori vanno "interpretati", descritti con qualcosa che io sia in grado di misurare. Un angolo, una lunghezza, un'area...}. Ed è proprio quello che facciamo quando si parla di coordinate. Se traduciamo l'equazione di Newton in coordinate cartesiane, essendo $\vec{a} = \ddot{x}\hat{x}+\ddot{y}\hat{y}$, otterremmo il semplice sistema:
	\begin{equation}
		\begin{cases}
			F_{x} = m\ddot{x} \\
			F_{y} = m\ddot{y} 
		\end{cases}
	\end{equation}
	Ora proviamo ad espandere la stessa equazione con la "rappresentazione" polare. Sarebbe molto carino avere una situazione del tipo:
	\begin{equation}
		\begin{cases}
			F_{r} = m\ddot{r} \\
			F_{\theta} = m\ddot{\theta} 
		\end{cases}
	\end{equation}
	Ma sfortunatamente le equazioni corrette sono:
	\begin{equation}
		\begin{cases}
			F_{r} = m\ddot{r} - r\dot{\theta}^{2} \\
			F_{\theta} = mr\ddot{\theta} + 2\dot{r}\dot{\theta}
		\end{cases}
		\label{EQNewtonrt}
	\end{equation}
	Dunque l'equazione di Newton non è invariante per scelta di coordinate. Questo è il motivo per cui ci serviamo dei vettori: loro sì che sono invarianti per variazioni di coordinate (in quanto sono definiti a priori). Sai che sbatti a scrivere un nuovo principio di Newton per ogni set di coordinate esistenti.
	
	Tutta questa trattazione sembra sottolineare un fatto molto importante: l'equazione fondamentale della meccanica trova una forma semplice e naturale nel set di coordinate cartesiane, che sembra essere il migliore. Scopriremo, tuttavia, che le cose non stanno così: la scelta cartesiana è la migliore solo quando riscriviamo l'assioma della meccanica nella forma $\vec{F}=m\vec{a}$ (ma neanche sempre, comunque). Avremo modo di vedere che esistono altre formulazione dello stesso principio che rendono la scelta cartesiana la peggiore possibile.
	
	
	Ancora meglio, vedremo che esiste una formulazione della meccanica (detta \textit{lagrangiana}, dal nome dell'inventore) che non ha coordinate preferite (e infatti utilizza coordinate generiche, dette \textit{coordinate generalizzate}). Il primato delle coordinate cartesiane è solo apparente.
	\subsection{Geometria degli spazi}
	\subsubsection{Lo spazio delle configurazioni}
	Prima di addentrarci nella meccanica lagrangiana, un altro po' di geometria. Partiamo del definire lo \textit{spazio delle configurazioni} di un sistema dinamico. Avevamo già parlato di spazio delle fasi di un sistema meccanico, inteso come il luogo geometrico di tutti i punti biunivocamente in relazione con i possibili stati del sistema stesso. Lo spazio delle configurazioni, in un certo senso, è qualcosa di più semplice. Si tratta dello spazio fisico di tutte le possibili posizioni che il sistema può occupare. Facciamo qualche esempio:
	\begin{itemize}
		\item Lo spazio delle configurazioni $\mathcal{M}$ di una particella libera è chiaramente lo spazio euclideo $\mathbb{R}^{3}$, in quanto la particella può occupare qualsiasi punto dello spazio tridimensionale.
		\item Lo spazio delle configurazioni $\mathcal{M}$ di un pendolo piano è la circonferenza. Il pendolo sferico, invece, ammette come spazio delle configurazioni la sfera $S^{2}$
		\item Lo spazio delle configurazioni $\mathcal{M}$ di un doppio pendolo piano è il prodotto diretto di due circonferenze, che topologicamente coincide con un toro $\mathcal{M} = T^2 = S^{1} \times S^1$
	\end{itemize}
	Quello che è possibile dimostrare è che lo spazio delle configurazioni di un sistema è una varietà differenziabile. Teoremi matematici ci assicurano che ogni varietà differenziabile può essere immersa nello spazio euclideo $\mathbb{R}^3$ e questo ci torna anche dal punto di vista fisico: ogni spazio delle configurazioni, essendo lo spazio delle possibili posizioni del sistema, deve essere contenuto nello spazio fisico tridimensionale, essendo questo lo spazio fondamentale della fisica classica.
	
	Come facciamo ad individuare i punti delle varietà spazio delle configurazioni $\mathcal{M}$? Il problema è lo stesso di quello affrontato nel paragrafo precedente. Devo rappresentare i punti dello spazio $\mathcal{M}$ tramite \textit{coordinate}, cioè sostanzialmente numeri. Se $\mathcal{M} = \mathbb{R}^3$, possiamo usare le coordinate cartesiane ad esempio e mappiamo ogni punto della varietà spazio euclideo. E se fossimo su una sfera? Consideriamo ad esempio un sistema dinamico di un punto materiale che sia vincolato a muoversi su di una sfera di raggio $1$. Lo spazio delle sue configurazioni è ovviamente la sfera unitaria, $\mathcal{M} = S^2$. Come rappresento i punti della sfera? Certo, potrei immergere la sfera nello spazio euclideo e impiegare le coordinate cartesiane per rappresentare i suoi punti (tanto abbiamo visto che le cartesiane funzionano molto bene nello spazio euclideo). Questa scelta però è un po' infelice: la sfera è qualcosa di piano, è una superficie che ha dimensionalità 2, perché usare tre coordinate, $x,y,z$? Usando le coordinate cartesiane ho un certo livello di ridondanza (d'altronde, una volte definite $x,y$ ho automaticamente anche la $z$).
	\subsubsection{Le carte e le coordinate}
	Per la sfera, potrei usare le due coordinate angolari $(\theta,\varphi)$, l'angolo azimuthale e quello polare. Questa è una scelta ragionevole, essendo la dimensione pari a $2$. L'insieme $(\theta,\varphi)\in[0,\pi]\times[0,2\pi]\subset \mathbb{R}^2$ è un esempio di quello che in geometria viene chiamata \textit{carta}, la cui definizione formale è\footnote{Dall'Arnold}:
	\begin{tcolorbox}
		Una carta $U$ è un sottoinsieme dello spazio euclideo $\mathbb{R}^n$ munito di coordinate cartesiane sono $q_1,q_2, ..., q_n$\footnote{È lo spazio euclideo che è munito di coordinate cartesiane.} tale che esista una trasformazione iniettiva $\varphi : U \to \mathcal{M}$ che associa ogni elemento di $U$ a elementi della varietà $\mathcal{M}$,
		$$
		\varphi(U)\subset \mathcal{M}
		$$
	\end{tcolorbox}
	La definizione sembra complicata ma il significato è immediato. Come una carta geografica permette di capire dove sono sulla sfera terrestre, l'insieme $U$ (che è sottoinsieme dello spazio euclideo) mi permette di identificare i punti della varietà che sto studiando. Il concetto di carta rappresenta il concetto di coordinata fisica, un insieme di numeri (che ho chiamato $q_1, q_2, ..., q_n$) il cui compito è quello di mappare i punti della varietà. 
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			% Cartesian axes
			\draw[->] (-0.1,0) -- (5.2,0) node[right] {$\varphi$};
			\draw[->] (0,-0.1) -- (0,2.7) node[above] {$\theta$};
			
			
			\filldraw[fill=black!20!white, draw=black!40!black] (0,0) rectangle (5,2.5);
			
			
			% Labels
			\node at (4.6,-0.5) {$2\pi$};
			\node at (-0.5,2.84) {$\pi$};
			
			% Caption
		\end{tikzpicture}
		\begin{tikzpicture}
			\draw (0,0) -- (0,0);
			\draw[->] (0,3) -- (1,3);
		\end{tikzpicture}
		\begin{tikzpicture}
			% Sphere
			\shade[ball color=gray!20] (0,0) circle (2);
			
			% Axes
			\draw[->] (0,0) -- (3,0) node[right] {$x$};
			\draw[->] (0,0) -- (0,3) node[above] {$y$};
			\draw[->] (0,0) -- (-2.5,-2.5) node[below left] {$z$};
			
			% Latitude and Longitude lines
			
			
			% Arcs for angles
			
			
		\end{tikzpicture}
		\caption{\textit{Ogni punto del rettangolo (la carta) permette di mappare un punto della sfera. Non tutti, in realtà.}}
	\end{figure}
	Le coordinate cartesiane $(x,y) \in \mathbb{R}^{2} = U_1$ sono una carta per lo spazio $\mathbb{R}^2$. Le coordinate polari anche: la carta qua è però diversa, poiché $(r,\theta) \in\mathbb{R}^+ \times [0,2\pi] = U_2 \subset \mathbb{R}^2$. Le due carte sono diverse, $U_1 \neq U_2$ ma rappresentano la medesima varietà: si dicono carte equivalenti.
	\begin{tcolorbox}
		Due piccoli appunti matematici per i più puristi. Non è detto che una varietà $\mathcal{M}$ possa essere rappresentata da una sola carta sola. La sfera ne è un esempio: usando le coordinate $(\theta,\varphi)\in[0,\pi]\times[0,2\pi] = U\subset\mathbb{R}^2$, ho difficoltà a rappresentare i poli. Si può dimostrare che non c'è modo di rappresentare suriettivamente i punti della sfera con una sola carta $U\subset\mathbb{R}^2$. Servono almeno due carte (ad esempio, si può usare la proiezione stereografica che consta di due piano, cioè due carte di $\mathbb{R}^2$). L'unione di più carte è detta \textit{atlante}. Questo fatto si traduce nella constatazione che, per certe varietà, \textbf{non è possibile individuare coordinate globali}, in grado cioè di coprire tutta la varietà. Al massimo posso ambire a coordinate locali, che spazzano regioni della varietà. Lo spazio euclideo $\mathbb{R}^n$ possiede delle coordinate globale (le cartesiane, mappano tutto) ma, come abbiamo appena visto, la sfera no.
		
		Secondo appunto. Possiamo definire la varietà in un modo alternativo, cioè come classe di equivalenza di tutti gli atlanti compatibili.
	\end{tcolorbox}
	
	\subsubsection{Il senso della meccanica lagrangiana}
	Perché tutta questa pippa sulle varietà e su come rappresentarle con coordinate/carte? Lo dimostriamo tornando all'esempio fecondo della sfera (di un punto vincolato su di essa). Nessuno ci impedisce di immergere la sfera nello spazio euclideo $\mathbb{R}^3$ e descrivere i punti della sfera con le coordinate cartesiane. A questo punto uso le equazioni di Newton e il gioco è fatto, risolvo qualsiasi moto.
	
	Certo, ma questo metodo è lungo e difficile. Il punto è sempre lo stesso: perché complicarmi la vita analizzando il problema della sfera in uno spazio che ha una dimensione in più ($\mathbb{R}^3$) quando la dimensionalità naturale del problema è più bassa ($dim(S^2)=2$)? Voglio sviluppare una teoria che mi permetta di lavorare direttamente sulla varietà stessa, senza doverla immergere in spazi euclidei a più dimensioni. Voglio equazioni del moto che non siano nelle coordinate cartesiane:
	\begin{equation}
		\begin{cases}
			x=x(t) \\
			y= y(t) \\
			z=z(t)
		\end{cases}
	\end{equation}
	ma che siano espresse direttamente nelle coordinate che io ho scelto per modellizzare la varietà $\mathcal{M}$:
	\begin{equation}
		\begin{cases}
			q_1=q_1(t) \\
			q_2= q_2(t) \\
			\dots \\
			q_n = q_n(t)
		\end{cases}
	\end{equation}
	D'altronde viene molto meglio capire il moto della particella sulla sfera se ricavo $\theta(t),\varphi(t)$ rispetto alle $x(t),y(t),z(t)$.
	
	Il primo approccio, di immersione in $\mathbb{R}^3$, è quello tipico di Newton. Il secondo è l'approccio della \textbf{meccanica lagrangiana}. Quest'ultimo è mille volte più efficace e veloce quando il problema che sto studiando è vincolato, e dunque lo spazio delle configurazioni non è più tutto $\mathbb{R}^3$, ma una sua varietà. 
	
	Il problema è che, per ora, l'equazione di Newton sembra cambiare a seconda delle coordinate che scelgo di usare (\ref{EQNewtonrt}). L'approccio newtoniano si riconduce sempre allo spazio euclideo perché qui è comodo usare le coordinate cartesiane e, come abbiamo visto, l'equazione di Newton in cartesiane è facile. Ma noi vogliamo superare le cartesiane: per farlo, però, dobbiamo trovare una forma del principio di Newton che si adatti bene a qualunque coordinata $\vec{q}$ di una generica varietà. 
	\subsubsection{Lo spazio tangente e la metrica}
	Ultimissimi cenni di geometria. Una volta individuato un modo per rappresentare i punti dello spazio, vogliamo definire gli spazi tangenti alla varietà $\mathcal{M}$. Prendiamo nuovamente un generico punto $P\in\mathcal{M}$ e proponiamoci di calcolare lo spazio tangente in quel punto, detto $T\mathcal{M}_{P}$. Vale la pena ricordare che l'unione di tutti gli spazi tangenti in tutti i punti della varietà è detta \textit{fibrato tangente}, indicato con $T\mathcal{M}$. Ricordiamo che, formalmente, lo spazio tangente $TM_{P}$ non è sempre la stessa cosa dello spazio di partenza $\mathcal{M}$ che stiamo considerando. Infatti, se ci immaginiamo uno varietà sferica $S^2$, i due concetti non coincidono, essendo lo spazio tangente ad un qualsiasi punto della sfera un piano $TS^2_P = \mathbb{R}^2$. La geometria ci assicura che \textbf{tutti gli spazi tangenti hanno struttura di spazi vettoriali euclidei} (e quindi lineari). Questo vuol dire che in tali spazi posso definire dei vettori\footnote{Posso definire dei vettori come punti di una generica varietà? No, perché uno spazio generico può non essere vettoriale. I punti della sfera non possono essere considerati come vettori (come sommo due punti sulla sfera? Non ha senso). La sfera non ha la struttura di spazio vettoriale. Invece in spazi euclidei, lineari per definizione, ogni punto è anche vettore, inteso proprio come "freccetta".}
	
	
	
	La domanda che ci poniamo è ora la seguente: dato uno spazio delle configurazioni $\mathcal{M}$ in cui introduco le coordinate $(q_{1}, q_{2}, .., q_{n})$, come posso definire una base per lo spazio tangente in un generico punto $P$? La domanda ha senso perché, per quanto detto, gli spazi tangenti sono vettoriale e quindi posso definire basi vettoriali.
	
	Per rispondere alla domanda, mi basta considerare una qualsiasi curva passante per $P$ e calcolarne la derivata rispetto al parametro che la genera, ad esempio $t$:
	\begin{equation}
		\dfrac{d}{dt}\vec{x}(q_{1}(t), ..., q_{n}(t))
		\label{Deriv}
	\end{equation}
	Questo vettore appartiene, per definizione, allo spazio tangente nel punto considerato (lo lascio in forma vettoriale perché, in quanto vettore, non è vincolato alla coordinate scelte. Non l'ho scritto in alcuna base). Esplicito l'eq (\ref{Deriv}) usando la convenzione di Einstein:
	\begin{equation}
		\dfrac{d}{dt}\vec{x}(q_{1}(t), ..., q_{n}(t)) = \dfrac{\partial \vec{x}}{\partial q_{k}}\dfrac{\partial q_{k}}{\partial t} = \dfrac{\partial \vec{x}}{\partial q_{k}}\dot{q_{k}}
	\end{equation}
	Il primo termine mi racconta come varia il vettore $\vec{x}$ variando le coordinate generalizzate. Notiamo che abbiamo riscritto il vettore tangente della (\ref{Deriv}) come una combinazione lineare di vettori, ossia i termini:
	$$
	\vec{e}_{k} = \dfrac{\partial \vec{x}}{\partial q_{k}}
	$$
	Questi rappresentano dunque una base di vettori per lo spazio tangente al punto $P$. Chiaramente tale base è da intendersi nello spazio euclideo in cui abbiamo immerso la varietà (cioè sono vettori di $\mathbb{R}^{N}$ che, se applicati al punto P, mi identificano la base dello spazio tangente. Questi vettori hanno dimensione $N$, in fondo, cioè la dimensione dello spazio in cui sta immersa la varietà, che invece ha dimensione $n$. Il numero di vettori-basi così individuati è invece pari a $n$, come ci aspettiamo). Notiamo che tale base potrebbe a rigore dipendere dal punto stesso in cui stiamo valutando lo spazio tangente, cioè più propriamente
	\begin{equation}
		\vec{e}_{k}(q_{1}, ..., q_{n}) = \dfrac{\partial \vec{x}}{\partial q_{k}}(q_{1}, ..., q_{n})
	\end{equation}
	Il fatto che la base determinata può non essere fissa produce alcuni effetti interessanti in dinamica: questa variazione continua di base introduce delle accelerazioni fittizie (ne parleremo a tempo debito). 
	
	Allora la velocità di un corpo in un dato punto $P = \vec{x}(q_{1}(t), ..., q_{n}(t))$ della varietà si scrive come:
	$$
	\vec{v} = \dot{q}_{k}\vec{e}_{k}
	$$
	Provo a calcolarne il modulo quadro. Per farlo, però, devo introdurre negli spazi tangenti una nozione di prodotto scalare:
	\begin{equation}
		||\vec{v}||^{2} = (\dot{q}_{k}\vec{e}_{k} )\cdot(\dot{q}_{k}\vec{e}_{k}) = \dot{q}_{k} \vec{e}_{k} \cdot \vec{e}_{h} \dot{q}_{h}
	\end{equation}
	Definendo la matrice metrica $G_{kh} = \vec{e}_{k} \cdot \vec{e}_{h}$ (potenzialmente funzione anche del punto), possiamo riscrivere il modulo quadro della velocità come:
	\begin{equation}
		||\vec{v}||^{2} = \dot{q}_{k}G_{kh}\dot{q}_{h}
		\label{Velocità}
	\end{equation}
	Il modulo di un vettore deve essere uno scalare, cioè non può dipendere dalla scelta di coordinate. Ne segue che il secondo membro della (\ref{Velocità}) deve essere una quantità complessivamente non dipendente dalla scelta di $q$, nonostante le singole parti ne dipendando.
	A questo punto è facile trovarsi l'energia cinetica $T$ di un punto materiale vincolato su di una varietà:
	\begin{equation}
		T = \dfrac{m}{2}\dot{q}_{k}G_{kh}\dot{q}_{h}
		\label{Cinetica}
	\end{equation}
	Perché fare tutta questa fatica? Perché siamo riusciti a scrivere l'energia cinetica in maniera indipendente dala scelta delle coordinate e, dunque, valida su qualsiasi varietà. Nella scelta cartesiana, l'energia cinetica per un punto materiale libero nel piano è banalmente (dunque lo spazio delle configurazioni è tutto $\mathbb{R}^2$):
	$$
	T = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2})
	$$
	Ma, ad esempio nella scelta polare in cui le coordinate sono $(r,\theta)$:
	$$
	T = \dfrac{1}{2}m(\dot{r}^{2}+(\dot{\theta}r)^{2})
	$$
	Le due forme dell'equazione per l'energia cinetica sono palesemente differenti. Con l'espressione (\ref{Cinetica}) possiamo trovare una forma per $T$ che prescinda dalla specifica scelta delle coordinate. Era proprio parte del nostro obiettivo, quello di trovare una forma più generale per le grandezze tipiche della meccanica, lavorando senza abbandonare lo spazio delle configurazioni. Infatti la (\ref{Cinetica}) non fa riferimento a nessuna immersione nello spazio euclideo $\mathbb{R}^n$. Ci sono solo le coordinate \textit{generalizzate} con cui descrivo la varietà stessa e la metrica \textbf{G} che è intrinseca della varietà.\footnote{I vettori di base $\vec{e}_k$ sono ancora oggetti che appartengono allo spazio euclideo di immersione (non hanno la stessa dimensione della varietà!). Quando ne faccio il prodotto scalare, ottengo la metrica. Una volta definita la metrica, non devo più tornare in $\mathbb{R}^{N}$. La metrica deve dunque essermi fornita insieme allo spazio delle configurazioni (oppure la posso calcolare immergendomi temporaneamente nello spazio euclideo, che è quello che spesso si fa nei problemi, avremo modo di vederlo bene con esempi).}
	
	Notiamo una particolarità interessante nella forma di $T$. Per fissare un esempio, facciamo finta di lavorare in uno spazio a 2 dimensioni. L'espressione $\dot{q}_{k}G_{kh}\dot{q}_{h}$ è la scrittura indiciale della relazione vettoriale:
	\begin{equation}
		\dot{\vec{q}}\>\textbf{G}\>\dot{\vec{q}} =
		(\dot{q}_{1}, \dot{q}_{2})
		\begin{pmatrix}
			G_{11} & G_{12} \\
			G_{21} & G_{22} \\
		\end{pmatrix}
		\begin{pmatrix}
			\dot{q}_{1} \\ \dot{q}_{2}
		\end{pmatrix}
		\label{FormaQuadratica}
	\end{equation}
	Il vettore $\dot{\vec{q}}$ è il vettore della velocità generalizzata, ossia il vettore delle derivate delle coordinate generalizzate. Questo non è uguale al vettore velocità in senso stretto: basta considerare il caso polare, in cui $\vec{v} = \dot{r}\hat{r} + r\dot{\theta}\hat\theta$ e non banalmente $\vec{v} = \dot{r}\hat{r}+\dot{\theta}\hat{\theta}$. L'energia cinetica è sempre pari a $T = \dfrac{1}{2}m|\vec{v}|^{2}$, in qualsiasi set di coordinate (il modulo di un vettore è un invariante). Il problema è che l'espressione della velocità $\vec{v}$ dipende fortemente dalla scelta delle coordinate (vedi appunto le polari), per cui vorremmo lavorare con la \textit{velocità generalizzata}, ossia le derivate delle coordinate generalizzate. Si può fare, ma il prezzo da pagare è la formula (\ref{Cinetica}).
	
	E comunque, la formula (\ref{Cinetica}) può essere interpretata facilmente, trattandosi di una forma quadratica. La (\ref{FormaQuadratica}), infatti, rappresenta un generico prodotto scalare fra due vettori identici (quelli della velocità generalizzata) definito dalla matrice $\mathbf{G}$. In altre parole, stiamo ridefinendo un'espressione per il modulo di un vettore (prodotto scalare del vettore per se stesso) di modo che il suo valore non cambi modificando il set di vettori di base.
	
	\begin{tcolorbox}
		Una breve riflessione sulla matrice metrica. Per fissare le idee, consideriamo una superficie sferica immersa in $\mathbb{R}^{3}$. Cosa mi rappresenta la metrica della sfera? L'idea è la seguente. Prendiamo un punto della sfera e costruiamo lo spazio tangente individuando due vettori che lo generino (la base dello spazio tangente, insomma). Tutti i vettori che abitano nello spazio tangente, di dimensione 2, possono essere individuati specificando solo due componenti (la loro proiezione sulla base dello spazio tangente). Questi vettori, dunque, possono essere pensati come appartenenti allo spazio tangente (che è bidimensionale, localmente piatto) ma anche come vettori immersi nello spazio euclideo tridimensionale $\mathbb{R}^{3}$. Per questi vettori possono definire un prodotto scalare che deriva dal fatto che appartengono anche allo spazio euclideo (quello standard, per fissare le idee). Quello che voglio fare con la matrice metrica è trovare un modo per effettuare il prodotto scalare fra questi vettori interpretandoli come bidimensionali, cioè come vettori dello spazio tangente 2D, direttamente sullo spazio tangente. Se voglio che i due prodotti scalari coincidano (quello indotto sulla superficie della sfera e quello dello spazio in cui la sfera è immerso), devo necessariamente introdurre una qualche modifica, appunto la metrica \textbf{G}. In altre parole, posso trasformare una superficie sferica in una superficie piana a patto di introdurre un prodotto scalare puntualmente definito dalla metrice $\mathbf{G}$. Questa considerazione porta anche ad una conseguenza profonda. La matrice metrica è definita su una varietà immersa in uno spazio euclideo in cui io abbia già introdotto un prodotto scalare. Ma questa scelta è arbitraria! Quello che possiamo dire, in realtà, è che una superficie ha una certa metrica rispetto ad un altro spazio, assunto euclideo. Una sfera è tale solo rispetto allo spazio tridimensionale piatto!
		
		Un ultimo chiarimento. La forma metrica determina completamente la geometria intrinseca della superficie, intendendo con tale termine tutte quelle proprietà geometriche che possono essere valutate attraverso misure condotte rimanendo entro la superficie stessa, senza "uscirne" (senza cioè esaminare la superficie bidimensionale entro uno spazio euclideo tridimensionale).
		
	\end{tcolorbox}
	La metrica, dunque, è uno strumento molto potente perché, come mostrato, permette di fare i prodotti scalari direttamente sulla varietà/spazio tangente senza doverlo abbandonare.
	\subsubsection{Componenti covarianti e controvarianti}
	Ancora un po' di matematica. Immaginiamo di prendere un campo vettoriale $\vec{F}(\vec{x})$. Definiamo ora i concetti di \textit{componenti covarianti e controvarianti}.
	
	Definiamo componente covariante il numero (non scalare) $F_{k}$:
	\begin{equation}
		F_{k} = \vec{F} \cdot \vec{e}_{k}
	\end{equation}
	avendo preventivamente definito una base di vettori. Quindi, in un certo senso, la componento covariante è la proiezione del campo $\vec{F}$ sul vettore di base $\vec{e}_{k}$.
	
	Definiamo componente controvariante il numero (non scalare) $F^{k}$ tale per cui:
	\begin{equation}
		\vec{F} = F^{k}\vec{e}_{k}
	\end{equation}
	Non è detto che le due cose siano uguali (ma comunque la conoscenza di uno dei due tipi di componenti è sufficiente per conoscere appieno il vettore $\vec{F}$). Le due componenti sono collegate dalla relazione:
	\begin{equation}
		F_{h} = \vec{F}\cdot\vec{e}_{h} = F^{k}\vec{e}_{k}\cdot\vec{e}_{h} = F^{k}G_{kh}
	\end{equation}
	Se scelgo una base dello spazio tangente che è ortonormale rispetto al prodotto impiegato (o, al contrario, se scelgo un prodotto in cui i vettori di base sono ortonormali), allora la metrica $G$ è equivalente alla matrice identità e le componenti dei due tipi sono uguali (infatti per costruire un vettore con una base ortonormale basta proiettarlo su quella base e effettuare una combinazione lineare).
	\subsubsection{Curve e geometrie}
	Diamo altre nozioni geometriche dello spazio $E_{n}$. Una curva $\gamma$ è un'applicazione da $I\subset\mathbb{R}$ allo spazio stesso :
	$$
	\gamma : t \in [a,b] \to P \in E_{n}
	$$
	La lunghezza della curva, definita formalmente come:
	\begin{equation}
		L(\gamma) = \int_{a}^{b}||\vec{v}||dt = \int_{a}^{b}\sqrt{\dot{q}_{k}G_{kh}\dot{q}_{h}}dt
	\end{equation}
	Il termine $ds$ definito come:
	\begin{equation}
		ds = \sqrt{\dot{q}_{k}G_{kh}\dot{q}_{h}}dt
		\label{DiffArco}
	\end{equation}
	è detto differenziale d'arco e indica di quanto varia la lunghezza di un segmento nell'intorno di un punto quando variano le coordinate generalizzate nell'intervallo $dt$. Anche qui entra in gioco la metrica. Ci ricordiamo che la matrice metrica ci dice come adattare il prodotto scalare in tutti gli spazi tangenti al variare del punto della varietà considerato. Dal prodotto scalare, inferiamo la geometria di quello spazio, come ad esempio la norma dei vettori (che posso pensare come la radice del prodotto scalare con se stesso). Ad esempio, nel caso delle coordinate cartesiane, il differenziale $ds$ diventa:
	$$
	ds = (\dot{x}^{2}+\dot{y}^{2})dt
	$$
	in accordo con quanto ci aspettiamo applicando il teorema di pitagora. Questa formula però vale solo per le coordinate cartesiane e la forma generale si può ricavare dalla (\ref{DiffArco}).
	
	Dati due punti generici di uno spazio, la geodetica è la curva che li congiunge aventa la minore lunghezza possibile. In uno spazio euclideo, le geodetiche sono rette. Le geodetiche godono di proprietà importanti: su tali curve, la direzione normale è normale anche alla superficie su cui sono definite (?).
	
	\subsection{Le equazioni di Newton in forma covariante}
	Abbiamo tutto quello che serve per affrontare il prossimo problema: scrivere le equazioni di Newton in \textbf{forma covariante}. Questo vuol dire che le vogliamo scrivere in una forma che sia indipendente dalla coordinate scelte per impostare i calcoli e, dunque, raggiungere l'obiettivo che ci eravamo posti. 
	
	Partiamo allora proprio dalla relazione vettoriale del principio di Newton, cercando di superarla:
	$$
	\vec{F} = m\vec{a}
	$$
	Sia definito lo spazio delle configurazioni con coordinate generalizzate $q_{i}$ e il relativo fibrato tangente. Prendendo la generica base di vettori $\displaystyle \hat{e}_{k} = \dfrac{\partial \vec{x}}{\partial q_{k}}$ adattati alle coordinate generalizzate $q_{i}$, proiettiamo la relazione vettoriale sulla base j-esima:
	$$
	\vec{F}\cdot\hat{e}_{j} = m\vec{a}\cdot\hat{e}_{j}
	$$
	Per ora occupiamoci del secondo termine
	\subsubsection{Il termine accelerazione}
	Cerchiamo di riscrivere il secondo membro dell'equazione di sopra:
	$$
	m\vec{a}\cdot\vec{e}_{j}
	$$
	L'accelerazione $\vec{a}$ è definita come $\dfrac{d\vec{v}}{dt}$ e, scrivendo $\vec{v}= \dot{q}_{k}\vec{e}_{k}$, otteniamo:
	\begin{equation}
		\vec{a} = \dfrac{d\vec{v}}{dt} = \ddot{q}_{k}\vec{e}_{k} + \dot{q}_{k}\dfrac{\partial \vec{e}_{k}}{\partial q_{h}}\dot{q}_{h}
	\end{equation}
	In cui abbiamo semplicemente derivato la velocità vettoriale rispetto al tempo, ottenendo due termini poiché prodotto di due termini, entrambi dipendenti dal tempo. Perché i vettori $\vec{e}_{k}$ possono dipendere dal tempo? Muovendomi nel tempo, cambio posizione e, a rigore, la base dello spazio tangente potrebbe variare punto per punto nello spazio. A questo punto proiettiamo sulla base j-esima moltiplicando ambo i membri per $\vec{e}_{j}$:
	\begin{equation}
		\vec{a}\cdot\vec{e}_{j} = \ddot{q}_{k}\vec{e}_{k}\cdot\hat{e}_{j} + \dot{q}_{k}\dfrac{\partial \vec{e}_{k}}{\partial q_{h}}\cdot \vec{e}_{j}\dot{q}_{h}
	\end{equation}
	Riconosciamo nel primo addendo un elemento della matrice metrica. E nel secondo addendo? Possiamo ricorrere all'identità:
	\begin{equation}
		\dfrac{\partial \hat{e}_{k}}{\partial q_{h}}\cdot\hat{e}_{j} = \dfrac{\partial}{\partial q_{n}}(\hat{e}_{k}\cdot\hat{e}_{j})-\dfrac{\partial \hat{e}_{j}}{\partial q_{h}}\cdot\hat{e}_{k}
	\end{equation}
	Dunque, sostituendo:
	\begin{equation}
		\vec{a}\cdot\vec{e}_{j} = \ddot{q}_{k}\vec{e}_{k}\cdot\vec{e}_{j} + \dot{q}_{k} \dfrac{\partial}{\partial q_{n}}(\vec{e}_{k}\cdot\hat{e}_{j})\dot{q}_{h} -  \dot{q}_{k}\dfrac{\partial \vec{e}_{j}}{\partial q_{h}}\cdot \vec{e}_{k}\dot{q}_{h}
	\end{equation}
	L'ultimo termine (quello negativo) posso riscriverlo come:
	$$
	\dot{q}_{k}\dfrac{\partial \vec{e}_{j}}{\partial q_{h}}\cdot \vec{e}_{k}\dot{q}_{h} = \dfrac{1}{2}\dot{q}_{k}\dot{q}_{h}\dfrac{\partial}{\partial q_{j}}(\vec{e}_{k}\cdot\vec{e}_{h})
	$$
	Questo perché vale la relazione:
	$$
	\dfrac{\partial \vec{e}_{k}}{\partial q_{j}} = \dfrac{\partial \vec{e}_{j}}{\partial q_{k}}
	$$
	facilmente dimostrabile dalla definizione della base per lo spazio tangente:
	$$
	\dfrac{\partial \vec{e}_{k}}{\partial q_{j}} = \dfrac{\partial}{\partial q_j} \dfrac{\partial \vec{x}}{\partial q_k} = \dfrac{\partial}{\partial q_k} \dfrac{\partial \vec{x}}{\partial q_j} =  \dfrac{\partial \vec{e}_{j}}{\partial q_{k}}
	$$
	Dunque, in totale, (vedi slide)
	\begin{equation}
		\vec{a}\cdot\hat{e}_{j} = \dfrac{d}{dt}\Bigl(\dot{q}_{k}G_{kj}\Bigl) - \dfrac{1}{2}\dot{q}_{k}\dot{q}_{h}\dfrac{\partial}{\partial q_{j}}G_{kh}
	\end{equation}
	Ora un trick matematico. Possiamo infatti verificare che
	\begin{equation}\label{key}
		\dot{q}_kG_{kj} = \dfrac{\partial}{\partial \dot{q}_j}\Bigl(\dfrac{1}{2}\dot{q}_h G_{kh}\dot{q}_h\Bigl)
	\end{equation}
	e che
	\begin{equation}\label{key}
		\dfrac{1}{2}\dot{q}_{k}\dot{q}_{h}\dfrac{\partial}{\partial q_{j}}G_{kh} = \dfrac{\partial}{\partial q_j}\Bigl(\dfrac{1}{2}\dot{q}_h G_{kh}\dot{q}_h\Bigl)
	\end{equation}
	e finalmente, sostituendo il tutto, si arriva all'equazione:
	\begin{equation}
		\vec{a}\cdot\vec{e}_{j} = \dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_j}\Bigl(\dfrac{1}{2}\dot{q}_h G_{kh}\dot{q}_h\Bigl) -\dfrac{\partial}{\partial q_j}\Bigl(\dfrac{1}{2}\dot{q}_h G_{kh}\dot{q}_h\Bigl)
	\end{equation}
	\begin{equation}
		\vec{a}\cdot\hat{e}_{j}  = \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]\Bigl(\dfrac{1}{2}\dot{q}_{k}G_{kh}\dot{q}_{h}\Bigl)
	\end{equation}
	Moltiplicando per la massa, ottengo infine:
	\begin{equation}
		m\vec{a}\cdot\hat{e}_{j}  = \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]\Bigl(\dfrac{1}{2}m\dot{q}_{k}G_{kh}\dot{q}_{h}\Bigl) =  \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]T
		\label{AccCov}
	\end{equation}
	Il termine tra parentesi tonde è palesemente l'energia cinetica del sistema. Siamo giunti dove volevamo arrivare: abbiamo riscritto il secondo membro dell'equazione di Newton in una forma covariante. Infatti non c'è più alcuna traccia di coordinate cartesiane: basta calcolare l'energia cinetica (che è un invariante, dunque è sempre la stessa in tutti i sistemi di riferimento ed inoltre abbiamo già la formula covariante per $T$) e ad essa applicare l'operatore scritto fra parentesi quadre, detto operatore lagrangiano:
	$$
	Lag(T(q,\dot{q})) =  \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]T
	$$
	e otteniamo la componente covariante dell'accelerazione moltiplicata per la massa, ossia la forza. Per fare un velocissimo esempio, proviamo a metterci in coordinate polari. Vogliamo sapere a cosa è uguale la coordinata radiale della forza, $F_{r}$. Se l'equazioni della meccanica fossero uguali per tutte le coordinate, potremmo scrivere $F_{r} = m\ddot{r}$, esattamente come avremmo scritto $F_{x} = m\ddot{x}$ in cartesiane. Purtroppo non è così. La forma generale di $F_{r}$ è data dall'equazione (\ref{AccCov}). Ci siamo già calcolati $T$ per coordinate polari, $T = \dfrac{1}{2}m(\dot{r}^{2}+r^{2}\dot{\theta}^{2})$.Applichiamo a questa espressione l'operatore lagrangiano, ponendo $q_{j} = r$:
	$$
	Lag(T) =   \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{r}}-\dfrac{\partial }{\partial r}\Bigl] \dfrac{1}{2}m(\dot{r}^{2}+r^{2}\dot{\theta}^{2}) = m\ddot{r} - r\dot{\theta}^{2} = m\vec{a}\cdot\hat{e}_{r} = F_{r}
	$$
	Che è esattamente la forma di $a_{r}$ che ci aspettavamo.
	\subsubsection{Il moto libero}
	Riassumiamo il risultato appena ottenuto scrivendo:
	\begin{equation}
		\vec{F}\cdot\hat{e}_{j} =  \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]T
	\end{equation}
	dove spesso si indica con $Q_{j} = \vec{F}\cdot\hat{e}_{j}$. Il primo membro è ancora in qualche modo da lavorare. Per ora concentriamoci sulla situazioni fisiche in cui $\vec{F}=0$, e quindi l'equazione covariante recita:
	\begin{equation}
		\Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]T = 0
		\label{MotoLibero}
	\end{equation}
	La comodità di questa equazione è che ci permette di fare a meno del formalismo vettoriale (utile perché prescindeva dal sistema di coordinate) senza tuttavia perdere di generalità. La (\ref{MotoLibero}), infatti, vale sempre, qualsiasi set di coordinate $q$ io scelga di usare per descrivere lo spazio delle configurazioni.
	
	Ma siccome io so dalla fisica che, quando la forza esterna è nulla il corpo si muove in linea retta, allora l'equazione $Lag(T)=0$ mi deve fornire come soluzione l'equazione della retta nelle coordinate $q$\footnote{Volendo generalizzare a spazi non per forza vettoriali, diremo che le curve percorse da oggetti su cui non viene applicata forza è una geodetica. Per spazi sferici, ad esempio, l'equazione $Lag(T)=0$ fornisce l'equazione parametrica degli archi di circonferenza, cioè le geodetiche}.
	
	Se il moto è libero, allora so che l'energia cinetica si deve conservare (essendo nulla l'energia potenziale e dovendosi conservare l'energia meccanica). Dovrebbe dunque verificarsi che $T$ è un integrale primo del moto, e quindi:
	$$
	\dfrac{d}{dt}T = \dfrac{d}{dt}\Bigl(\dfrac{1}{2}m\dot{q}_{k}G_{kh}\dot{q}_{h}\Bigl) = 0
	$$
	In effetti, questa equazione è effettivamente pari a 0 quando il moto è libero (solo in questi casi, ovviamente). La dimostrazione è però molto lunga e contosa, dunque ne proponiamo un'altra alternativa. Infatti possiamo scrivere l'energia cinetica sfruttando l'identità:
	$$
	T = \dot{q}_{j}\dfrac{\partial T}{\partial \dot{q}_{j}} - T
	$$
	Da cui, derivando per il tempo, ottengo\footnote{Il termine $T$ è funzione di $q \mbox{ e di }\dot{q}$, dunque quando derivo rispetto al tempo ottengo due termini di derivate parziali}:
	$$
	\dfrac{d}{dt}T = \ddot{q}_{j}\dfrac{\partial T}{\partial \dot{q}_{j}} + \dot{q}_{j}\dfrac{d}{dt}\dfrac{\partial T}{\partial \dot{q}_{j}} - \dfrac{\partial T}{\partial \dot{q}_{j}}\ddot{q}_{j} -\dfrac{\partial T}{\partial q_{j}}\dot{q}_{j} = \Bigl[\dfrac{d}{dt}\dfrac{\partial T}{\partial \dot{q}_{j}}-\dfrac{\partial T}{\partial q_{j}}\Bigl]\dot{q}_{j}
	$$
	Ed essendo il moto libero, l'ultimo termine è nullo poiché $Lag(T) = 0$. È confermato il fatto che l'energia cinetica rappresenti un integrale primo del moto
	
	\subsubsection{Esempio: coordinate polari}
	Facciamo un esempio pratico per mostrare la veridicità di quanto appena affermato. Prendiamo una particella libera di muoversi nel piano (quindi spazio delle configurazioni $\mathbb{R}^2$) ma utilizziamo le coordinate polari, le cui definizione rispetto alle cartesiane è:
	\begin{equation}
		\begin{cases}
			x = r\cos(\theta) \\
			y = r\sin(\theta)
		\end{cases}
	\end{equation}
	Calcoliamo ora la base di vettori $\vec{e}_{r}, \vec{e}_{\theta}$ che, per ogni punto di $\mathbb{R}^2$, costituisce una base per lo spazio tangente, definita come:
	\begin{equation}
		\begin{cases}
			\vec{e}_{r} = \dfrac{\partial}{\partial r}\vec{x} \\[6pt]
			\vec{e}_{\theta} = \dfrac{\partial}{\partial \theta}\vec{x}
		\end{cases}
	\end{equation}
	Il vettore $\vec{x}$ può essere scritto nella forma cartesiana\footnote{Anche qui c'è molta confusione nella notazione. Il vettore $\vec{x}$ è il raggio vettore, mentre il semplice numero scalare $x$ è una delle sue componenti in forma cartesiana. Sarebbe stato più opportuno chiamare $\vec{x} = \vec{r}$, ma amen}, $\vec{x} = (x,y) = (r\cos(\theta), r\sin(\theta))$, per cui i vettori di base degli spazi tangenti sono:
	\begin{equation}
		\begin{cases}
			\vec{e}_{r} = \dfrac{\partial}{\partial r}(r\cos(\theta), r\sin(\theta)) = (\cos(\theta), \sin(\theta)) \\[6pt]
			\vec{e}_{\theta} = \dfrac{\partial}{\partial \theta}(r\cos(\theta), r\sin(\theta)) = (-r\sin(\theta), r\cos(\theta))
		\end{cases}
	\end{equation}
	Ricordiamo che i nuovi vettori di base $\vec{e}_{r}, \vec{e}_{\theta}$ hanno una loro esistenza intrinseca negli spazi tangenti, ma qui li abbiamo scritti in coordinate cartesiane. Notiamo che non sono necessariamente versori (infatti il modulo di $\vec{e}_{\theta} = r$) ma che sono perpendicolari per qualsiasi punto del piano. Questa caratteristica non è generale ed è tipica delle coordinate polari. In generale, dunque, i vettori di base non sono nè versori nè ortogonali. Non è nemmeno necessario normalizzare (una base è una base, non ne serve una ortonormale). 
	
	Costruisco ora la matrice metrica:
	\begin{equation}
		\textbf{G} =
		\begin{pmatrix}
			\vec{e}_{r}\cdot\vec{e}_{r} & \vec{e}_{r}\cdot\vec{e}_{\theta} \\
			\vec{e}_{\theta}\cdot\vec{e}_{r} & \vec{e}_{\theta}\cdot\vec{e}_{\theta}
		\end{pmatrix} =
		\begin{pmatrix}
			1 & 0 \\
			0 & r^{2}
		\end{pmatrix}
	\end{equation}
	
	Notiamo che la matrice metrica ha determinante nullo per $r=0$ e non si comporta bene. Questo però non è un problema, perché le coordinate polari non permettono di rappresentare l'origine.
	
	Costruiamo ora l'energia cinetica utilizzando la formula formale (\ref{Cinetica}) tramite la velocità generalizzata $(\dot{r},\dot{\theta})$:
	\begin{equation}
		T = \dfrac{1}{2}m (\dot{r},\dot{\theta})
		\begin{pmatrix}
			1 & 0 \\
			0 & r^{2}
		\end{pmatrix}
		\begin{pmatrix}
			\dot{r} \\ \dot{\theta}
		\end{pmatrix} =
		\dfrac{1}{2}m(\dot{r}^{2}+r^{2}\dot{\theta}^{2})
	\end{equation}
	che è esattamente quanto già trovato. Ora applico l'operatore lagrangiano, una volta rispetto a $r$, un'altra rispetto a $\theta$ e lo pongo nullo, ottenendo:
	\begin{equation}
		\begin{cases}
			\ddot{r} = r\dot{\theta}^{2} \\
			\dfrac{d}{dt}(mr^{2}\dot{\theta}) =0
		\end{cases}
		\label{LiberoPolari}
	\end{equation}
	Risolvendo questo set di equazioni in forma parametrica, dovrei ottenere l'espressione della retta in coordinate polari.
	\subsubsection{Il momento angolare}
	La seconda equazione di (\ref{LiberoPolari}) è molto interessante. Questa ci dice che esiste una quantità, $L = mr^{2}\dot{\theta}$, la cui derivata temporale è identicamente nulla, ovvero è un integrale primo del moto. Si tratta del \textit{momento angolare} rispetto all'origine, che si conserva in assenza di forze (non solo). La sua esistenza ci aiuta molto in quanto si tratta di un integrale primo del moto, cioè:
	$$
	L = mr^{2}\dot{\theta} = const
	$$
	Da questa relazione, posso ricavare:
	$$
	\dot{\theta} = \dfrac{L}{mr^{2}}
	$$
	che, sostituita nella prima equazione di (\ref{LiberoPolari}), mi permette di scrivere:
	\begin{equation}
		m\ddot{r} = \dfrac{L^{2}}{mr^{3}}
	\end{equation}
	Essendo $L$ una quantità costante che non dipende né da $r$ né da $\theta$, l'equazione appena scritta è a tutti gli effetti un'equazione differenziale che si può risolvere per ottenere $r(t)$. La sua forma infatti è quella di un problema unidimensionale (con variabile $r$) in cui il corpo è soggetto ad un potenziale del tipo:
	\begin{equation}
		V(r) = \dfrac{L^{2}}{2mr^{2}}
	\end{equation}
	Siamo riusciti a ridurre un problema bidimensionale ad un problema unidimensionale di cui abbiamo persino ottenuto un'espressione per il potenziale $V(r)$ e noi sappiamo risolvere benissimo i problemi 1D. Questo vuol dire che anche i problemi bidimensionali in cui $F=0$ sono integrabili (essendolo sempre i sistemi unidimensionale).
	
	Come è fatto lo spazio delle fasi per tali sistemi unidimensionale derivati da quelli 2D? L'energia meccanica si scrive nella forma:
	\begin{equation}
		E = \dfrac{1}{2}m\dot{r}^{2} + \dfrac{L^{2}}{2mr^{2}}
	\end{equation}
	ed è sempre positiva. Lo spazio delle fasi assume dunque questa forma:
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\draw[->] (-.1,0) -- (5,0)node[right]{$r$};
			\draw[->] (0,-2) -- (0,2)node[above]{$\dot{r}$};
			\draw[domain=-0.9:0.9] plot ({-1/(\x*\x-1)},\x);
			\draw[dotted] (0,1) -- (5,1);
			\draw[dotted] (0,-1) -- (5,-1);
			\node[] (A) at (4,1.3) {$\dot{r}_{\infty}$};
		\end{tikzpicture}
	\end{figure}
	Le curve di livello sono pseudo-parabole rovesciate che non crescono all'infinito ma si assestano asintoticamente su di un valore, $\dot{r}_{\infty}$ pari numericamente a $\sqrt{\dfrac{2E}{m}}$. Lo spazio delle fasi è dunque l'unione di queste curve di livello che tendono ad avvicinarsi asintoticamente allo zero aumentando l'energia.
	\subsubsection{Coordinate polari in 3 dimensioni}
	Facciamo un altro esempio, quello delle coordinate polari in 3D. La loro definizione a partire dalle coordinate cartesiane è:
	\begin{equation}
		\begin{cases}
			x = r\sin(\theta)\cos(\varphi) \\
			y = r\sin(\theta)\sin(\varphi) \\
			z = r\cos(\theta)
		\end{cases}
	\end{equation}
	Ricaviamoci i vettori di base per il nuovo set di coordinate:
	\begin{equation}
		\begin{cases}
			\vec{e}_{r} = (\sin\theta\cos\varphi,\sin\theta\sin\varphi, \cos\theta) \\
			\vec{e}_{\theta} = (r\cos\theta\cos\varphi, r\cos\theta\sin\varphi, -r\sin\theta) \\
			\vec{e}_{\varphi} =(-r\cos\theta\sin\varphi, r\sin\theta\cos\varphi,0)
		\end{cases}
	\end{equation}
	La matrice metrica è:
	\begin{equation}
		\textbf{G} = 
		\begin{pmatrix}
			1 & 0 & 0 \\
			0 & r^{2} & 0 \\
			0 & 0 & r^{2}\sin^{2}\theta
		\end{pmatrix}
	\end{equation}
	e l'energia cinetica è:
	\begin{equation}
		T = \dfrac{1}{2}m (\dot{r}, \dot{\theta}, \dot{\varphi}) \textbf{G} 
		\begin{pmatrix}
			\dot{r} \\ \dot{\theta} \\ \dot{\varphi}
		\end{pmatrix}
		= \dfrac{1}{2}m(\dot{r}^{2}+r^{2}\dot{\theta}^{2}+r^{2}\dot{\varphi}^{2}\sin^{2}\theta)
	\end{equation}
	Applicando l'operatore lagrangiano a $T$, otteniamo le equazioni del moto che, per quanto ne sappiamo, dovrebbero descrivere una retta in coordinate polari:
	\begin{equation}
		\begin{cases}
			m\ddot{r} - mr\dot{\theta}^{2} - mr\sin^{2}\theta\dot{\varphi}^{2} = 0 \\
			\dfrac{d}{dt}(mr^{2}\dot{\theta}) - mr^{2}\sin\theta\cos\theta\dot{\varphi}^{2} = 0 \\
			\dfrac{d}{dt}(mr^{2}\sin^{2}\theta\dot{\varphi}) = 0
		\end{cases}
	\end{equation}
	Non risolveremo il sistema, ma ci limiteremo a notare le proprietà della terza equazione. In questo caso, la quantità $mr^{2}\sin^{2}\theta\dot{\varphi}$ corrisponde alla componente lungo $z$ del momento angolare, che è un invariante del moto (cioè un integrale primo del moto). E le altre due componenti? In teoria, l'intero vettore momento angolare si conserva in assenza di forze esterne. Ed infatti è possibile maneggiare le equazioni di sopra per far comparire anche le altre due componenti del momento angolare come integrali primi del moto. Tuttavia, $L_{x} \mbox{ e } L_{y}$ sono integrali primi molto scomodi con cui lavorare, mentre in genere si preferisce ragionare con i integrali del moto $L_{z}, E$ e modulo di $\vec{L}$, cioè $L^{2}$.
	\subsubsection{Dinamica di corpo libero sulla sfera}
	Portiamo un esempio concreto, quello di un punto materiale che è vincolato a muoversi su di una sfera (senza attrito).
	Lo spazio delle configurazioni del corpo è uno spazio sferico $S^2$, dunque non euclideo. Potremmo immergere la sfera nello spazio euclideo $\mathbb{R}^3$ usando le coordinate cartesiane $x,y,z$ vincolate dal fatto che:
	$$
	x^2+y^2+z^2 = R^2
	$$
	Oppure lo possiamo risolvere applicando assiomaticamente le equazioni di Lagrange: le equazioni del moto su spazi non euclidei sono individuate dalla lagrangiana!
	Utilizzando coordinate sferiche per descrivere la varietà $S^2$, l'energia cinetica del punto materiale diventa:
	$$
	T = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}(\theta))
	$$
	%%figura
	Questa è chiaramente un integrale primo del moto, se il punto materiale è isolato:
	$$
	E = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}(\theta))
	$$
	ma è facile verificare che anche:
	$$
	p_{\varphi}= \dfrac{\partial T}{\partial \dot{\varphi}} = mR^{2}\dot{\varphi}\sin^{2}(\theta)
	$$
	è un integrale primo del moto. Sostituendolo nell'equazione dell'energia, si ottiene infine:
	$$
	E = \dfrac{1}{2}mR^{2}\dot{\theta}^{2}+\dfrac{p_{\varphi}^{2}}{2mR^{2}\sin^{2}(\theta)}
	$$
	Essendo dunque $p_{\varphi} \mbox{ e } E$ due costanti definite dalle condizioni iniziali, possiamo interpretare l'equazione di sopra come un problema unidimensionale nella sola variabile $\theta$ e risolvere il problema per separazione di variabili. Questo metodo però implica troppi conti, proviamo a svignarcela in un altro modo. Nell'equazione unidimensionale dell'energia nella variabile $\theta$, riconosciamo un potenziale del tipo:
	$$
	V(\theta) = \dfrac{p_{\varphi}^{2}}{2mR^{2}\sin^{2}(\theta)}
	$$
	I punti di equilibrio per $\theta$ sono individuati dalla condizione:
	$$
	\dfrac{d}{d\theta}V(\theta) = 0
	$$
	e cioè per $\theta = \dfrac{\pi}{2}$. Quando $\theta$ si mantiene costante, allora $\dot{\theta} = 0$ e, dalla defizione di $p_\varphi$, ottengo che:
	$$
	\dot{\varphi} = \dfrac{p_{\varphi}^2}{mR^2} \Longrightarrow \varphi(t) = \varphi_{0}+\dfrac{p_{\varphi}^2}{mR^2}t
	$$
	cioè la variabile $\varphi$ varia linearmente. Fisicamente, il sistema sta descrivendo una circonferenza, in particolare quella dell'equatore della sfera. Dunque sappiamo che una possibile traiettoria è proprio l'equatore, percorso a velocità angolare costante. E le altre? Poiché la sfera è simmetrica per qualsivoglia rotazione, allora posso ruotare questa orbita comunque io voglia e tale sarà ancora soluzione. In altre parole, le geodetiche della sfera sono i cerchi massimi e una particella libera di muoversi e vincolata sulla sfera seguirà proprio queste traiettorie.
	\newpage 
	\section{La Lagrangiana}
	Per ora abbiamo affrontato problemi in cui le forze esterne erano nulle (e quindi pari a 0 in qualunque set di coordinate). La forma covariante dell'equazioni di Newton recita (come da (\ref{AccCov})):
	\begin{equation} \Bigl[\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_{j}}-\dfrac{\partial }{\partial q_{j}}\Bigl]T = \vec{F}\cdot\hat{e}_{j} = Q_{j}
	\end{equation}
	Proviamo a elaborare ulteriormente il termine a destra dell'uguale. Se della forza possiedo un potenziale, allora posso scrivere:
	\begin{equation}
		Q_{j} = \vec{F}\cdot\hat{e}_{j} = -\vec{\nabla }V\cdot\dfrac{\partial \vec{x}}{\partial q_{j}} = -\dfrac{\partial V}{\partial q_{j}}
	\end{equation}
	e da tale espressione sono scomparse del tutto le coordinate cartesiane e ogni riferimento al vettore posizione $\vec{x}$ (che nella meccanica newtoniana ricopre un ruolo centrale). Siamo quindi andati oltre la dinamica newtoniana, siamo in grado di generalizzare i contenuti della meccanica anche lavorando direttamente su spazi non euclidei. Questa è la grande forza del formalismo lagrangiano.
	
	Definiamo ora una nuova funzione, detta \textit{lagrangiana} $\Lambda$:
	\begin{equation}
		\Lambda = T - V = \dfrac{1}{2}m\dot{q}_{i}G_{ij}\dot{q}_{j} - V(q)
	\end{equation}
	L'energia cinetica è costruita direttamente sullo spazio tangente dello spazio delle configurazioni $\mathcal{M}$ (la scelta delle coordinate mi condiziona come costruisco il modulo quadro di un vettore) mentre il potenziale è definito direttamente nello spazio delle configurazioni! In altre parole, posso costruire la Lagrangiana direttamente sulla varietà $\mathcal{M}$ senza dover operare tramite immersioni in $\mathbb{R}^3$.
	
	Definita in questo modo la Lagrangiana, è facile verificare che, per ogni coordinate generalizzata $q_j$ che descrive lo spazio delle configurazioni:
	\begin{equation}
		\Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)\Lambda = 0
	\end{equation}
	Questo è il principio a base della meccanica lagrangiana. Non parleremo più di forze come facevamo in meccanica newtoniana: la  è un nuovo modo di vedere i fenomeni meccanici. Il principio di Newton, $\vec{F} = m\vec{a}$ tradotto in termini lagrangiani diventa proprio questa equazione, detta \textit{di Eulero-Lagrange}.
	
	Dimostrarla è facile\footnote{Dimostrare un principio? Diciamo che stiamo verificando che, se vale il principio di Newton, allroa segue naturalmente l'equazione di E-L. Una volta dimostrato, possiamo invertire il processo logico: E-L diventa il principio di natura sperimentale e $\vec{F} = m\vec{a}$ qualcosa che può essere dimostrato analiticamente}. Infatti, posto $\Lambda = T(\dot{q},q)-V(q)$:
	\begin{align}
		\Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)\Lambda &= 	\Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)T - 	\Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)V \\
		&= 	\Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)T - \dfrac{\partial}{\partial q_{j}}V = 0
	\end{align}
	poiché la funzione potenziale dipende solo dalle coordinate generalizzate e non dalla loro derivata. 
	
	Questo risultato è di fondamentale importanza. La funzione lagrangiana è uno scalare\footnote{Il fatto che sia uno scalare è relativo al set di coordinate, ossia la lagrangiana di un sistema ha lo stesso valore (specificato uno stato) indipendentemente dalle coordinate impiegate. Chiaramente la sua forma dipende dalle coordinate, ciò che rimane fisso è il valore numerico.} che rappresenta in maniera esaustiva il sistema in esame. Una volta che si conosce la lagrangiana di un sistema meccanico, si hanno tutte le informazioni sul sistema stesso, questa funzione descrive interamente la fisica del problema. Basta applicare l'operatore lagrangiano e derivare, ad esempio, le equazioni del moto (scritte rispetto alle coordinate generalizzate con cui la lagrangiana è esplicitata).
	\subsection{Invarianza di Gauge per la lagrangiana}
	La forma più generale per una lagrangiana di un sistema fisico è, dunque:
	\begin{equation}
		\Lambda(q,\dot{q},t)
	\end{equation}
	Tuttavia l'abbinamento lagrangiana-sistema fisico non è perfettamente biunivoco, nel senso che data una lagrangiana $\Lambda$ di un sistema posso costruirne un'altra, $\Lambda'$, a cui aggiungo una qualsiasi funzione espressa come derivata totale del tempo:
	\begin{equation}
		\Lambda' = \Lambda + \dfrac{d}{dt}F(q,t)
	\end{equation}
	Si può dimostrare che anche $\Lambda'$ rappresenta il medesimo sistema fisico di $\Lambda$, in quanto:
	\begin{equation}
		Lag(\Lambda) = Lag(\Lambda')
	\end{equation}
	Infatti il termine di derivata totale rispetto al tempo appartiene al kernel dell'operatore lagrangiano:
	\begin{align}
		Lag(\Lambda') &= \Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)\Bigl(\Lambda + \dfrac{d}{dt}F(q,t)\Bigl) = \\
		&= \Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl)\Bigl(\dfrac{d}{dt}F(q,t)\Bigl) = \\
		&= \Bigl(\frac{d}{dt}\dfrac{\partial}{\partial \dot{q_{j}}} - \dfrac{\partial}{\partial q_{j}}\Bigl) \Bigl(\dfrac{\partial F}{\partial q_{k}} \dot{q}_{k} +\dfrac{\partial F}{\partial t}\Bigl) = \\
		&= \dfrac{d}{dt}\dfrac{\partial F}{\partial q_{j}} - \dfrac{\partial^{2}F}{\partial q_{j}\partial q_{k}}\dot{q}_{k} - \dfrac{\partial ^{2}F}{\partial q_{j}\partial t }
	\end{align}
	Ma l'ultima riga è esattamente nulla, poiché il termine $\dfrac{d}{dt}\dfrac{\partial F}{\partial q_{j}}$ lo posso riscrivere applicando la regola di Leibniz come:
	$$
	\dfrac{d}{dt}\dfrac{\partial F}{\partial q_{j}} = \dfrac{\partial^{2} F}{\partial q_{k}\partial q_{j}}\dot{q}_{k} - \dfrac{\partial^{2} F}{\partial t\partial q_{j}}
	$$
	e quindi $Lag(\Lambda') = 0 = Lag(\Lambda)$. 
	
	Ne segue dunque che la lagrangiana di un sistema fisico è nota meno di un termine esprimibile come derivata totale del tempo. Questa invarianza, detta \textit{di gauge}, compare spesso nella fisica fondamentale. La approfondiremo più avanti, ha a che vedere con i diversi sistemi di riferimento in cui le leggi della meccanica possono essere scritte e le trasformazioni di Galileo.
	\subsection{Energia a partire dalla lagrangiana}
	Sappiamo già da studi precedenti che l'energia meccanica è, per sistemi conservativi, un integrale primo del moto garantitoci dalla struttura delle equazioni di Newton stesse e dalla conservatività delle forze meccaniche. Attraverso la lagrangiana, possiamo definire l'energia come\footnote{notazione di Einstein}:
	\begin{equation}
		H = \dfrac{\partial \Lambda}{\partial \dot{q_{j}}} \dot{q}_{j} - \Lambda 
		\label{EnLag}
	\end{equation}
	che, per sistemi meccanici conservativi, coincide con:
	$$
	H = T + V
	$$
	proprio come ci aspettavamo. Verifichiamo la validità della (\ref{EnLag}) valutando:
	\begin{align}
		\dfrac{dH}{dt} = \dfrac{d}{dt}\Bigl(\dfrac{\partial \Lambda}{\partial \dot{q_{j}}} \dot{q}_{j} - \Lambda\Bigl)
	\end{align}
	essendo $\Lambda = \Lambda(q,\dot{q},t)$. Allora:
	\begin{align}
		\dfrac{dH}{dt} &= \dfrac{d}{dt}\Bigl(\dfrac{\partial \Lambda}{\partial \dot{q_{j}}} \dot{q}_{j} - \Lambda\Bigl) = \\
		&= \dfrac{\partial \Lambda}{\partial \dot{q}_{k}}\ddot{q}_{k} + \Bigl(\dfrac{d}{dt}\dfrac{\partial \Lambda}{\partial \dot{q}_{k}}\Bigl)\dot{q}_{k} - \dfrac{\partial \Lambda}{\partial q_{k}}\dot{q}_{k} - \dfrac{\partial \Lambda}{\partial \dot{q}_{k}}\ddot{q}_{k} - \dfrac{\partial \Lambda}{\partial t} = \\
		&= \dot{q}_{k}\Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_{k}} - \dfrac{\partial}{\partial q_{k}}\Bigl)\Lambda - \dfrac{\partial \Lambda}{\partial t} = \dot{q}_{k} Lag(\Lambda) - \dfrac{\partial \Lambda}{\partial t} = \\
		&= -\dfrac{\partial \Lambda}{\partial t}
	\end{align}
	Se in particolare $\Lambda$ non dipende esplicitamente da $t$, $\Lambda = \Lambda(q,\dot{q})$, allora:
	$$
	\dfrac{dH}{dt} = -\dfrac{\partial \Lambda}{\partial t} = 0
	$$
	cioè $H$, per come è stato definito, è a tutti gli effetti un integrale primo del moto. È facile anche verificare che se $\Lambda = T(\dot{q},q) - V(q)$, allora:
	$$
	H =  \dfrac{\partial T}{\partial \dot{q}_{k}}\dot{q}_{k} - T + V
	$$
	essendo poi $T = \dfrac{1}{2}\dot{q}_{i}G_{ij}(q)\dot{q}_{j}$, allora:
	$$
	\dfrac{\partial T}{\partial \dot{q}_{k}}\dot{q}_{k} = \dfrac{1}{2}G_{kj}(q)\dot{q}_{j} + \dfrac{1}{2}\dot{q}_{i}G_{ik}(q) =  \dfrac{1}{2}G_{jk}(q)\dot{q}_{j} + \dfrac{1}{2}G_{ik}(q)\dot{q}_{i}
	$$
	Avendo potuto invertire gli indici nella matrice metrica poiché è simmetrica. Gli indici $i,j$ sono solo fantocci, quindi:
	$$
	\dfrac{\partial T}{\partial \dot{q}_{k}}\dot{q}_{k} =  \dfrac{1}{2}G_{ik}(q)\dot{q}_{i} + \dfrac{1}{2}G_{ik}(q)\dot{q}_{i} = G_{ik}(q)\dot{q}_{i}
	$$
	e 
	$$
	H =  \dfrac{\partial T}{\partial \dot{q}_{k}}\dot{q}_{k} - T + V = \dot{q}_{k}G_{ik}(q)\dot{q}_{i} - T + V = 2T - T + V = T + V
	$$
	cioè, appunto, che $H = T+V$ (questo però a patto che l'energia si conservi, dunque $H$ non dipenda esplicitamente dal tempo).
	\subsection{Coordinate cicliche e momenti}
	Una volta che ho costruito la lagrangiana $\Lambda(q,\dot{q})$, posso definire una nuova grandezza fisica, il \textit{momento generalizzato} associato alla coordinata $j$-esima:
	\begin{equation}
		p_{j} = \dfrac{\partial \Lambda}{\partial \dot{q}_{j}}
	\end{equation} 
	Nozione che generalizza il concetto di impulso anche per coordinate non cartesiane. Facciamo un esempio: nel caso di particelle libera, la lagrangiana è uguale alla energia cinetica:
	$$
	\Lambda = T
	$$
	e, usando coordinate cartesiane per tutto lo spazio tridimensionale,
	$$
	\Lambda = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2}+\dot{z}^{2})
	$$
	I momenti generalizzati associati a queste coordinate sono dunque:
	$$
	p_{x} = m\dot{x}, \mbox{               } p_{y} = m\dot{y}, \mbox{              } p_{z} = m\dot{z}
	$$
	che sono proprio le componenti di quello che, in meccanica newtoniana, abbiamo chiamato quantità di moto (d'altronde usando il formalismo lagrangiano con le coordinate cartesiane, mi aspetto di ritrovare quanto già detto da Newton).
	
	I momenti generalizzati hanno una proprietà molto particolare. Infatti, dall'equazione di Eulero-Lagrange è facile ricavare che:
	\begin{equation}
		\dfrac{d}{dt}p_{j} = \dfrac{\partial \Lambda}{\partial q_{j}}
	\end{equation} 
	Se la Lagrangiana non dipende esplicitamente dalla coordinate $q_{j}$, quest'ultima viene detta \textit{ciclica} e il suo momento generalizzato gode della proprietà:
	$$
	\dfrac{d}{dt}p_{j} = 0
	$$
	In effetti, nella Lagrangiana del punto libero in coordinate cartesiane, la terna $(x,y,z)$ è una terna di coordinate cicliche e, di conseguenza, i loro momenti generalizzati si conservano. Questo è in accordo con la legge newtoniana secondo la quale la quantità di moto di un punto materiale libero si conserva nel tempo (e, quindi, necessariamente anche le sue componenti). 
	
	
	
	Due ultimi appunti sulle coordinate cicliche e sui momenti generalizzati. Mentre le velocità generalizzate sono componenti controvarianti (variano con la matrice inversa), i momenti generalizzati veriano con la matrice diretta (e sono dunque covarianti). Inoltre, la definizione di momento non è univoca, proprio perché la lagrangiana ha invarianza di gauge. Se infatti $p_{j}$ è un momento per una lagrangiana $\Lambda$, allora posso modificare:
	
	$$
	\Lambda' = \Lambda + \dfrac{d}{dt}F(q,t) = \Lambda + \dfrac{\partial F}{\partial q_{k}}\dot{q}_{k} + \dfrac{\partial F}{\partial t}
	$$
	e
	$$
	p_{j}' = \dfrac{\partial \Lambda'}{\partial \dot{q}_{j}} = p_{j} + \dfrac{\partial F}{\partial q_{j}}
	$$
	se la coordinate $q_{j}$ è ciclica per $\Lambda$, non è detto che lo sia anche per $\Lambda'$. Tuttavia $p_{j}'$ rimane un integrale primo del moto. In altre parole, alcuni sistemi fisici sono più "comodi" quando scritti in certe coordinate poiché queste risultano cicliche e, dunque, ci regalano un integrale primo del moto (diverso dall'energia).
	\newpage
	\section{Studio di campo centrale}
	In questo capitolo ci proponiamo di studiare una situazione fisica molto ricorrente, ovvero i problemi meccanici che riguardano dei potenziale fisici di tipo \textit{centrale}, ricorrendo al formalismo lagrangiano.
	%FIGURA%
	Una forza è detta avere potenziale centrale se posso scriverla nella forma:
	\begin{equation}
		\vec{F} = f(r)\hat{r}
	\end{equation}
	dove $f(r)$ è una qualsiasi funzione del solo raggio e $\hat{r}$ è il versore diretto radialmente. In parole povere, un campo di forze è centrale se la forza stessa è sempre diretta verso l'origine delle coordinate considerate (o uscente) e dipende solo dalla distanza da quest'ultimo. Per fare un esempio, la forza gravitazionale secondo Newton:
	$$
	\vec{F}_{g} = -G\dfrac{mM}{r^{2}}\hat{r}
	$$
	esercitata da un corpo massivo $M$ posto all'origine degli assi è di tipo centrale, essendo $f(r) =GmM/r^{2}$.
	
	Tali campi centrali ammettono sempre un potenziale $V$ che sia unicamente funzione della distanza radiale, $V=V(r)$ (in fondo se mi muovo su di una circonferenza centrata nell'origine mantenendo costante il raggio, il lavoro fatto dal campo è nullo e, di conseguenza, le superfici $r=const$ sono equipotenziali). Se il moto avviene sul piano, è molto comodo vista la struttura del problema introdurre delle coordinate polari $(r,\theta)$:
	\begin{equation}
		\begin{cases}
			x = r\cos(\theta) \\
			y = r\sin(\theta)
		\end{cases}
	\end{equation}
	Così facendo, posso costruire la lagrangiana del sistema in coordinate polari: $\Lambda = \Lambda(r,\theta,\dot{r},\dot{\theta},t)$. Calcolo dapprima l'energia cinetica. Potrei fare il ragionamento con la matrice metrica, lavorando da subito nelle coordinate polari (e valutando la geometria introdotta punto per punto da questo set di coordinate). Oppure, posso calcolare l'energia cinetica in coordinate cartesiane, che è più facile:
	$$
	T=\dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2})
	$$
	appellandomi al fatto che $T= \dfrac{1}{2}m||\vec{v}||^{2}$ ed è facile interpretare il vettore velocità in coordinate cartesiane tramite derivata del raggio vettore (ben definito), $\vec{v}=(\dot{x},\dot{y})$. Mi basta poi sostituire all'espressione dell'energia cinetica la forma delle coordinate polari ottenendo:
	$$
	T=\dfrac{1}{2}m(\dot{r}^{2} + \dot{\theta}^{2}r^{2})
	$$
	e la lagrangiana diventa:
	\begin{equation}
		\Lambda = \dfrac{1}{2}m(\dot{r}^{2} + \dot{\theta}^{2}r^{2}) - V(r)
		\label{LagCentrale}
	\end{equation}
	Notiamo subito che la coordinata $\theta$ è ciclica perché non compare nell'espressione (\ref{LagCentrale}) (il potenziale dipende solo da $r$) e, di conseguenza, il suo momento generalizzato sarà un integrale primo del moto:
	\begin{equation}
		p_{\theta} = \dfrac{\partial \Lambda}{\partial \dot{\theta}} = mr^{2}\dot{\theta}
	\end{equation}
	Anche l'energia è un integrale del moto, essendo la lagrangiana non esplicitamente dipendente dal tempo:
	\begin{equation}
		H = \dfrac{1}{2}m(\dot{r}^{2} + \dot{\theta}^{2}r^{2}) + V(r)
	\end{equation}
	Ho trovato due integrali primi del moto per un sistema a due gradi di libertà: posso dunque integrare le equazioni e ottenere le soluzioni del moto nelle coordinate $(r,\theta)$. Mi basta riscrivere l'energia sostituendo $\dot{\theta}=\dfrac{p_{\theta}}{mr^{2}}$, arrivando a:
	\begin{equation}
		E = \dfrac{1}{2}m\dot{r}^{2} + \dfrac{p_{\theta}^{2}}{2mr^{2}} + V(r)
		\label{En1d}
	\end{equation}
	Abbiamo ridotto la dimensionalità del problema poiché ora, nell'espressione dell'energia, compare solo la variabile $r$: la formula (\ref{En1d}) descrive l'energia di un sistema unidimensionale! Possiamo infatti interpretare i due termini funzioni della sola coordinata $r$ come un \textit{potenziale efficace} che si manifesta quando riduciamo la dimensionalità del problema:
	\begin{equation}
		E = \dfrac{1}{2}m\dot{r}^{2} + V_{eff}(r) = \dfrac{1}{2}m\dot{r}^{2} +  \dfrac{p_{\theta}^{2}}{2mr^{2}} + V(r)
	\end{equation}
	In altre parole, lo studio di un punto materiale in un campo centrale bidimensionale può essere facilmente ridotto allo studio di un sistema unidimensionale soggetto ad un potenziale efficace:
	$$
	V_{eff}(r) = \dfrac{p_{\theta}^{2}}{2mr^{2}} + V(r)
	$$
	Notiamo che finché $p_{\theta} \neq 0$, allora il termine aggiuntivo del potenziale efficace diverge necessariamente a $\infty$ quando $r\to 0$, cioè è impossibile cadere nella sorgente del campo stesso.
	
	Una volta nota l'espressione dell'energia per un sistema unidimensionale, posso separare le variabili e trovare le soluzioni del problema a livello analitico parametrizzate all'energia $E$:
	\begin{equation}
		t = \int_{r}^{r_{0}}\dfrac{dr}{\sqrt{\dfrac{2}{m}(E-V_{eff}(r))}} = \int_{r}^{r_{0}}\dfrac{dr}{\sqrt{\dfrac{2}{m}(E-\dfrac{p_{\theta}^{2}}{2mr^{2}} + V(r))}}
		\label{SoluzKep}
	\end{equation}
	da cui, invertendo la funzione, ricavo $r(t)$. Per trovare poi $\theta(t)$, basta ritornare all'altra dimensione sapendo che:
	\begin{equation}
		\theta(t) = \int_{t}^{0}\dfrac{p_{\theta}}{mr^{2}(t)}dt
		\label{Theta}
	\end{equation}
	Ricordiamo, comunque, che le stesse soluzioni $(r(t),\theta(t))$ possono essere ricavate a partire dalla lagrangiana applicando l'operatore lagrangiano e ponendolo uguale a $0$.
	\subsection{Punti critici del potenziale efficace}
	Possiamo ricavarci i punti critici del potenziale efficace semplicemente ponendo:
	\begin{equation}
		\dfrac{d}{dr}V_{eff}(r_{cr}) = 0
	\end{equation}
	In questi punti, la soluzione per la coordinata radiale è stazionaria, cioè $r(t) = r_{cr}$. Attenzione però che questi punti sono di equilibrio solo per una coordinata, $r$, mentre non è detto lo sia anche per $\theta$. D'altronde, se $r(t)= r_{cr}$, allora dalla (\ref{Theta}) ricavo che:
	$$
	\theta(t) = \dfrac{p_{\theta}}{mr^{2}_{cr}}t + \theta_{0}
	$$
	per cui necessariamente $\theta$ non è in equilibrio. Quello che però si ottiene è che, nei punti critici, l'orbita descritta dal punto materiale è una circonferenza percorsa a velocità angolare costante! Tale orbita potrà essere stabile o instabile a seconda che il potenziale abbia un minimo o un massimo.
	\subsection{Potenziale di Keplero}
	Cerchiamo di fornire un esempio molto particolare. Un campo di forze il cui potenziale abbia la forma:
	\begin{equation}
		V(r) = -\dfrac{k}{r}
	\end{equation}
	è detto \textit{kepleriano}. Questo potenziale descrive la struttura della forza gravitazionale, motivo per cui è un potenziale molto importante nella fisica classica. Ricaviamo la forma del potenziale efficace:
	\begin{equation}
		V_{eff}(r) = -\dfrac{k}{r} + \dfrac{p_{\theta}^{2}}{2mr^{2}}
		\label{PotKeplEff}
	\end{equation}
	Ora possiamo studiare la dinamica del problema concentrandoci momentaneamente sulla sola coordinata radiale. Il potenziale efficace (\ref{PotKeplEff}) ha un grafico del tipo:
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\draw[->] (-0.5, 0) -- (4.2, 0) node[right] {$r$};
			\draw[->] (0, -2) -- (0, 4.2) node[above] {$V(r)$};
			\draw[domain=0.245:4.5, samples = 500] plot ({\x}, {0.7/(\x*\x) - 2/(\x)});
		\end{tikzpicture}
	\end{figure}
	La presenza di una conca negativa è fondamentale per la limitatezza delle orbite celesti. Infatti, considerando livelli energetici minori di $0$ (ma comunque maggiore di $V_{min}$), il moto di un punto materiale è confinato fra un $r_{min}$ e un $r_{max}$, definiti \textit{epicentro e apocentro} dell'orbita. Quando l'energia è esattamente uguale a $0$, allora esiste un punto di minima distanza dall'origine, un epicentro, ma il corpo riesce ad allontanarsi indefinitamente dalla sorgente, arrivando all'infinito con una velocità nulla. Per energie maggiori di $0$, l'orbita è di nuovo non limitata (nel senso che fugge all'infinito) con una velocità residua $v_{\infty}\neq0$. Quando invece $E = V_{min}$, allora ricadiamo in un punto singolare e l'orbita diventa circolare. Per trovare tale valore, basta imporre:
	$$
	\dfrac{d}{dr}V_{eff}(r) = 0
	$$
	$$
	\dfrac{k}{r^2} - \dfrac{p_{\theta}^2}{mr^3}=0
	$$
	$$
	kr = 
	$$
	$$
	r =\dfrac{p_{\theta}^2}{mk}
	$$
	%%FIGURA SPAZIO DELLE FASI%%
	\subsection{Chiusura delle orbite kepleriane}
	Abbiamo detto che, nei moti kepleriani piani, le orbite di energia negativa sono limitate, nel senso che la coordinata radiale è vincolata a stare nel range $[r_{min},r_{max}]$ (apocentro ed epicentro). Questo vuol dire che il moto radiale è periodico e tale periodo equivale a (lo possiamo ricavare da (\ref{SoluzKep})):
	\begin{equation}
		T = 2\int_{r_{min}}^{r_{max}}\dfrac{dr}{\sqrt{\dfrac{2}{m}(E-V_{eff}(r))}}
		\label{PeriodoRadiale}
	\end{equation}
	che corrisponde formalmente al tempo che impiega il punto materiale a passare da un primo apocentro al successivo.
	
	Tuttavia questo non implica che il moto sia complessivamente periodico! Il problema è sul piano e ci stiamo dimenticando dell'altra coordinate del problema, l'angolo $\theta(t)$. Chiamiamo $\Delta \theta$ l'angolo spazzato dal corpo quando il punto passa da apocentro ad epicentro. Allora le orbite saranno chiuse se:
	$$
	2n\Delta\theta = 2\pi m \>\>\>\>\>\>\>\> m,n \in \mathbb{N}
	$$
	Questa condizione è necessaria perché, quando il corpo compie una periodicità radiale (apocentro-apocentro, cioè percorre $2\Delta\theta$) anche l'angolo ritorni alla posizione precedente (o comunque impiega un numero di periodicità radiali intere per farlo). La condizione di chiusura può essere posta come:
	\begin{equation}
		\Delta\theta = \dfrac{m}{n}\pi
		\label{CondChiusKep}
	\end{equation}
	ossia l'angolo $\Delta\theta$ deve essere un razionale rispetto a $\pi$. Cosa accadrebbe se così non fosse? Immaginiamo un corpo materiale che parte dall'epicentro. Compie un intero periodo radiale (dunque ritorna all'epicentro) ma la posizione non è esattamente quella iniziale perché l'angolo $\Delta\theta$ non è pari a $2\pi$. Andando avanti nelle periodicità radiale, il punto materiale non ritornerebbe mai nell'esatta posizione iniziale, ma sarebbe sempre sfalsata di un certo angolo (in fondo i numeri da $0$ a $2\pi$ sono infiniti, quindi il punto materiale può attraversarli tutti ad ogni periodo radiale senza che ne ripeta due). In tal caso, il corpo riempie densamente l'orbita e, ipoteticamente, occuperà tutte le posizione possibili fra $r_{min}$ e $r_{max}$ senza che il moto complessivo sia mai periodico. 
	
	Se invece la condizione sopra riportata è verificata, allora il moto è complessivamente periodico (e l'orbita si chiuse dopo $m$ giri, cioè una periodicità angolare corrisponde a $m$ periodicità radiali).  
	%%DISEGNO RIEMPIMENTO DENSO%%
	
	\medskip
	
	La cosa sorprendente è che, dato un potenziale casuale, è molto più probabile che la fisica che induce non implichi orbite chiuse (è come scegliere un numero a caso fra i reali e sperare che sia un razionale. Ha una probabilità nulla). Tuttavia, tutte le orbite classiche che osserviamo sono effettivamente chiuse: il potenziale kepleriano deve dunque rispettare la condizione di (\ref{CondChiusKep}). Verifichiamolo.
	
	Dalla (\ref{PeriodoRadiale}), ricavo che:
	$$
	dt = \dfrac{dr}{\sqrt{\dfrac{2}{m}(E-V_{eff}(r))}}
	$$
	E quindi sostituendo nella (\ref{Theta}), l'angolo spazzato $\Delta\theta$ vale:
	\begin{equation}
		\Delta\theta = \int_{r_{min}}^{r_{max}}\dfrac{\dfrac{p_{\theta}dr}{mr^{2}}}{\sqrt{\dfrac{2}{m}(E-V_{eff}(r))}}
	\end{equation}
	Potremmo risolvere tale integrale sostituendo la forma analitica di $V(r)$ e verificare che effettivamente un potenziale siffatto obbedisce all'equazione (\ref{CondChiusKep}). Questa strada però è molto tortuosa e preferiamo seguirne un'altra. 
	
	Vogliamo infatti verificare non solo se il potenziale kepleriano ammette orbite chiuse ma, in generale, vogliamo individuare tutte le possibili forme $V(r)$ che ne ammettono.
	\subsubsection{Chiusura in intorni di orbite circolari}
	Cominciamo con questa missione. Dapprima cerchiamo di studiare la chiusura delle orbite per intorni dell'orbita circolare, ossia quando la traiettoria fisica è abbastanza vicina a quella circolare\footnote{Il perché sarà chiaro dopo}. Riprendiamo l'espressione dell'energia nel potenziale di campo centrale:
	$$
	E = \dfrac{1}{2}m\dot{r}^{2} + \dfrac{p_{\theta}^2}{2mr^2}+V(r)
	$$
	Operiamo un cambio di variabili, 
	$$
	u = \dfrac{1}{r}
	$$
	Allora
	$$
	\dot{r} = \dfrac{dr}{dt} = \dfrac{dr}{du}\dfrac{du}{dt} = \Bigl(-\dfrac{1}{u^2}\Bigl)\dfrac{du}{d\theta}\dfrac{d\theta}{dt} = \Bigl(-\dfrac{\dot{\theta}}{u^2}\Bigl)\dfrac{du}{d\theta}
	$$
	La derivata temporale di $\theta$ la posso esprimere con $p_{\theta}$:
	$$
	\dot{\theta} = \dfrac{p_{\theta}}{mr^2} = \dfrac{p_{\theta}}{m}u^2 
	$$
	e allora:
	$$
	\dot{r} = - \dfrac{p_{\theta}}{m}\dfrac{du}{d\theta}
	$$
	Allora l'energia si esprime come:
	$$
	E = \dfrac{p_{\theta}^{2}}{2m}\Bigl(\dfrac{du}{d\theta}\Bigl)^2 + \dfrac{p_{\theta}^2}{2m}u^2 + V\Bigl(\dfrac{1}{u}\Bigl)
	$$
	$$
	E' = \dfrac{1}{2}\Bigl(\dfrac{du}{d\theta}\Bigl)^2 + \dfrac{1}{2}u^2 + \dfrac{m}{p_{\theta}^2} V\Bigl(\dfrac{1}{u}\Bigl)
	$$
	Abbiamo dunque riscritto il problema come se fosse rappresentato da una variabile $u$ funzione del parametro $\theta$. Per questo problema, il potenziale efficace vale:
	$$
	V_{eff}(u) = \tilde{V}(u) = \dfrac{1}{2}u^2 + \dfrac{m}{p_{\theta}^2} V\Bigl(\dfrac{1}{u}\Bigl)
	$$
	che si compone di un termine elastico e di un termine che dipende dal potenziale in esame. Quello che faremo, ora, è di consideare delle orbite vicine a quelle circolari (cioè per cui $u$ si mantiene costante rispetto a $\theta$, e quindi rispetto al tempo). Per trovare il valore di $u_c$ per cui si ha orbita circolare impongo:
	$$
	\dfrac{d\tilde{V}}{du}(u_c) = 0
	$$
	$$
	u_c - \dfrac{m}{p_{\theta}^2 u_c^{2}} V'\Bigl(\dfrac{1}{u}\Bigl) = 0
	$$
	cioè l'orbita circolare è tale da rispettare:
	\begin{equation}
		V'\Bigl(\dfrac{1}{u_c}\Bigl) = \dfrac{u_c^3 p_{\theta}^2}{m}
		\label{eqref}
	\end{equation}
	Calcolo anche la derivata seconda del potenziale nel punto critico:
	$$
	\dfrac{d^2\tilde{V}}{du^2}(u_c) = k = 3 + \dfrac{1}{u_c^4}\dfrac{d^2 V}{du^2}\Bigl(\dfrac{1}{u_c}\Bigl) \dfrac{m}{p_\theta^2}
	$$
	A questo punto espando il potenziale efficace attorno a $u_c$:
	$$
	\tilde{V}(u) = V(u_c) + \dfrac{1}{2}\dfrac{d^2\tilde{V}}{du^2}(u_c)(u-u_c)^2 + O((u-u_c)^2) = V(u_c) + \dfrac{1}{2} k (u-u_c)^2 + O((u-u_c)^2) 
	$$
	essendo la derivata prima nulla per definizione di punto critico. Trascurando i termini di $O((u-u_c)^2)$, posso scrivere l'equazione differenziale dell'energia in maniera più semplice:
	\begin{equation}
		E' = \dfrac{1}{2}\Bigl(\dfrac{du}{d\theta}\Bigl)^2 + \dfrac{1}{2} k (u-u_c)^2
		\label{KepCirc}
	\end{equation}
	che è un'approssimazione per orbite abbastanza vicine a quella circolare. Questa equazione mi permette di scrivere:
	$$
	d\theta = \dfrac{du}{\sqrt{2E'-k(u-u_c)^2}}
	$$
	e quindi, per orbite abbastanza simili a quella circolare, l'angolo di chiusura vale:
	$$
	\Delta \theta =\int_{u_{min}}^{u_{max}} \dfrac{du}{\sqrt{2E' - k(u-u_c)^2}}
	$$
	Questo integrale può effettivamente essere svolto ma non lo faremo. Infatti l'equazione (\ref{KepCirc}) è l'energia caratteristica di un oscillatore armonico con massa unitaria in cui il parametro non è il tempo, bensì l'angolo. La pulsazione delle sue oscillazioni è:
	$$
	\omega^2 = k
	$$
	e il periodo:
	$$
	T = \dfrac{2\pi}{\sqrt{k}}
	$$
	Ma tale periodo corrisponde a due volte l'angolo $\Delta\theta$ (il parametro dell'oscillatore non è il tempo ma l'angolo), quindi facilmente:
	\begin{equation}\label{key}
		\Delta \theta = \dfrac{\pi}{\sqrt{k}} = \dfrac{\pi}{\sqrt{\dfrac{d^2\tilde{V}}{du^2}(u_c)}}
	\end{equation}
	Ora, se la quantità a denominatore varia con l'orbita, allora è impossibile che tutte le orbite siano chiuse. Se per un'orbita vale infatti la condizione di chiusura, spostandomi ad un'orbita arbitrariamente vicina cambierei il denominatore e dunque romperei la condizione di chiusura.
	
	Se voglio orbite definitivamente chiuse almeno in prossimità di quella circolare, il fattore $k$ deve rimanere costante:
	$$
	k = 3 + \dfrac{1}{u_c^4}\dfrac{d^2 V}{du^2}\Bigl(\dfrac{1}{u_c}\Bigl) \dfrac{m}{p_\theta^2} = c
	$$
	cioè
	$$
	\dfrac{1}{u}\dfrac{d^2 V}{du^2}\Bigl(\dfrac{1}{u_c}\Bigl) =  \dfrac{u^3 p_{\theta}^2}{m}
	$$
	Dalla (\ref{eqref}), possiamo riscrivere:
	\begin{equation}\label{key}
		\dfrac{1}{u}\dfrac{d^2 V}{du^2}\Bigl(\dfrac{1}{u_c}\Bigl) = \dfrac{dV}{du}\Bigl(\dfrac{1}{u}\Bigl) (c-3)
	\end{equation}
	$$
	\dfrac{V''(r)}{V'(r)} = \dfrac{1}{r}(c-3)
	$$
	$$
	\ln(V'(r)) = (c-3)\ln(r) + a = \ln(ar^{c-3})
	$$
	$$
	V'(r) = ar^{c-3}
	$$
	Da cui arriviamo alla forma finale:
	\begin{equation}
		V(r) = \dfrac{a}{c-2}r^{c-2}
		\label{PotKepl1}
	\end{equation}
	oppure, se $c=2$:
	$$
	V(r) = a\ln(r)
	$$
	Concludiamo allora che, se vogliamo che in intorni della traiettoria circolare le orbite siano chiuse, allora la forma del potenziale deve necesseriamente essere quella di (\ref{PotKepl1}). Notiamo che se $c<0$, allora il potenziale efficace:
	$$
	V_{eff}(r) = \dfrac{p_{\theta}^{2}}{2mr^2}+\dfrac{a}{c-2}r^{c-2}
	$$
	per $r\to 0$ tende a $-\infty$ poiché di ordine maggiore rispetto al potenziale centrifugo e di segno negativo. Allora, è possibile che il corpo cada nel centro del campo (avvicinandosi con velocità infinita). Questo non è concepibile e, dunque, si pone in genere $c>0$ e $c\neq2$ per evitare il potenziale logaritmico. Ora però dobbiamo imporre la condizione di chiusura (per ora ci siamo solo premurati che l'angolo rimanga costante fra orbite vicine alla circolare, ma dobbiamo anche richiedere che tale valore costante sia tale da renderle chiuse). Calcoliamo esplicitamento $\Delta\theta$ una volta individuata una possibile famiglia di potenziali passando da $\tilde{V}_{eff}(u)$ sapendo che tali potenziali hanno la forma $V(r)=Ar^{c-2} = A u^{2-c}$:
	$$
	\tilde{V}_{eff}(u) = \dfrac{1}{2}u^2 + \dfrac{m}{p_{\theta}^2} V(\dfrac{1}{u}) = \dfrac{1}{2}u^2 +A \dfrac{m}{p_{\theta}^2}u^{2-c}
	$$
	e
	$$
	k = \dfrac{d^2\tilde{V}_{eff}(u)}{du^2} = 1+ A \dfrac{m}{p_{\theta}^2}(2-c)(1-c)u^{-c}
	$$
	La condizione di orbita circolare diventa
	\begin{equation}
		\begin{aligned}
			\dfrac{d\tilde{V}_{eff}(u)}{du}= u+A\dfrac{m}{p_{\theta}^2}(2-c)u^{1-c}&=0 \\
			1 +A\dfrac{m}{p_{\theta}^2}(2-c)u^{-c} &=0 \\
			A\dfrac{m}{p_{\theta}^2}(2-c)u^{-c} &=-1 
		\end{aligned}
	\end{equation}
	Sostituendo di sopra nella formula per $k$, ottengo che:
	\begin{equation}\label{key}
		k = 1-(1-c) = c
	\end{equation}
	e quindi l'angolo di interesse è
	\begin{equation}\label{key}
		\Delta\theta = \dfrac{\pi}{\sqrt{c}}
	\end{equation}
	questo è commensurabile con $\pi$ se e solo se $c$ è un quadrato perfetto. In tal caso, abbiamo assicurato che le orbite vicine all'orbita circolare siano anche chiuse.
	
	
	
	Ricapitolando, abbiamo scoperto che i potenziali centrali dalla forma:
	\begin{equation}\label{key}
		V(r) = A r^{c-2}
	\end{equation}
	con $c>0, c\neq 2$ realizzano la condizione di chiusure per orbite abbastanza vicine a quella circolare se $c$ è un quadrato perfetto\footnote{Non solo, in realtà. Basta che la sua radice sia razionale, quindi accettiamo anche valore come $c = \dfrac{9}{16}$. Vogliamo cioè un generico quadrato perfetto razionale.}. Questo chiaramente non basta per concludere che tutte le orbite siano sempre chiuse, vedremo più avanti come scremare ulteriormente i potenziali candidati. In base al valore di $c$, abbiamo anche che:
	\begin{equation}\label{key}
		\Delta \theta = \dfrac{\pi}{\sqrt{c}}
	\end{equation}
	Notiamo che se $c=1$, il potenziale è quello kepleriano. Buona notizia, visto che sospettiamo che questo abbia la proprietà della chiusura delle orbite.
	\subsubsection{Chiusura delle orbite: parte II}
	Abbiamo imposto la chiusura delle orbite negli intorni di uno specifico punto comodo, quello delle orbite circolari. Abbiamo identificato una condizione necessaria, ma non sufficiente perché non sappiamo cosa possa succedere ad orbite distanti da quella circolare. Abbiamo trovato un'infinità di potenziali che rispettano la condizione di chiusura per intorni di circolare, ma la ricerca non è ancora finita.
	
	Proviamo a rifare lo stesso calcolo, stavolta considerando le orbite che tendono all'orbita separatrice (cioè l'orbita ad energia nulla che riesce a fuggire all'infinito con velocità arbitrariamente piccola). Prendiamo allora i candidati potenziali che abbiamo ottenuto sopra:
	$$
	V(r)=Ar^{c-2}
	$$
	con $c > 0, c \neq 2$ e con $c$ quadrato perfetto razionale. Vogliamo ora valutare:
	\begin{equation}\label{key}
		\lim_{E\to 0} \Delta \theta (E)
	\end{equation}
	E fare in qualche modo le stesse considerazioni di prima. Riprendiamo l'energia del problema gravitativo scritta nella variabile $u$ e parametro $\theta$:
	\begin{equation}\label{key}
		E' = \dfrac{1}{2}\Bigl(\dfrac{du}{d\theta}\Bigl)^2 + \dfrac{1}{2}u^2 + Au^{2-c}
	\end{equation} 
	Posso separare le variabili e ottenere
	\begin{equation}\label{key}
		d\theta = \dfrac{du}{\sqrt{E'-u^2-2\dfrac{Am}{p_{\theta}^2}u^{2-c}}}
	\end{equation}
	e dunque l'angolo è
	\begin{equation}\label{key}
		\Delta\theta = \int_{u_{min}}^{u_{max}} \dfrac{du}{\sqrt{E'-u^2-2\dfrac{Am}{p_{\theta}^2}u^{2-c}}}
	\end{equation}
	Come ci aspettavamo, $\Delta\theta = \Delta\theta(E)$, cioè tale angolo dipende dall'energia dell'orbita. Studiamo cosa succede per $E\to0$, quindi:
	\begin{equation}\label{key}
		\lim_{E\to 0}\Delta\theta =  \int_{0}^{u_{max}} \dfrac{du}{\sqrt{-u^2-2\dfrac{Am}{p_{\theta}^2}u^{2-c}}} = \int_{0}^{u_{max}} \dfrac{du}{u\sqrt{-1-2\dfrac{Am}{p_{\theta}^2}u^{-c}}} 
	\end{equation}
	Essendo $u_{min} = 0$ perché, se $E=0$, allora il corpo riesce a fuggire a $r\to\infty$, cioè $u=0$. Sostituisco $x = u^{-c}$ e $dx = -c u^{-c-1}du = -c \dfrac{x}{u}du$, dunque l'integrale diventa:
	\begin{equation}\label{key}
		\lim_{E\to 0}\Delta\theta = -\int_{\infty}^{x_{min}} \dfrac{1}{c}\dfrac{\dfrac{u}{x}dx}{u\sqrt{-1-2\dfrac{Am}{p_{\theta}^2}x}}  = \dfrac{1}{c}\int_{x_{min}}^{\infty} \dfrac{dx}{x\sqrt{-1-2\dfrac{Am}{p_{\theta}^2}x}} 
	\end{equation}
	Ora invece sostituisco:
	$$
	y = -\dfrac{2Am}{p_{\theta}^2}x
	$$
	da cui
	\begin{equation}\label{key}
		\lim_{E\to 0}\Delta\theta = \dfrac{1}{c}\int_{y_{min}}^{\infty} \dfrac{dy}{y\sqrt{y-1}} 
	\end{equation}
	Quanto vale $y_{min}$? Risalendo dalla catena di sostituzioni, deve essere che:
	$$
	y_{min} = -\dfrac{2Am}{p_{\theta}^2}u^{-c} = -\dfrac{2Am}{p_{\theta}^2}r_{min}^{c}
	$$
	Il valore di $r_{min}$ lo trovo imponendo:
	$$
	E = 0 = V_{eff}(r) = \dfrac{p_{\theta}^2}{2mr^2}+Ar^{c-2}
	$$
	$$
	0=\dfrac{p_{\theta}^2}{2m}+Ar^{c}
	$$
	$$
	r^{c}_{min} = -\dfrac{p_{\theta}^2}{2Am}
	$$
	Da cui $y_{min} = 1$ e
	\begin{equation}\label{key}
		\lim_{E\to 0}\Delta\theta = \dfrac{1}{c}\int_{1}^{\infty} \dfrac{dy}{y\sqrt{y-1}} 
	\end{equation}
	Ultima sostituzione, 
	$$
	y = z^2 + 1, \quad \quad dy = 2zdz
	$$
	e l'integrale diventa
	\begin{equation}\label{key}
		\lim_{E\to 0}\Delta\theta = \dfrac{1}{c}\int_{0}^{\infty} \dfrac{2zdz}{(z^2+1)z} = \dfrac{1}{c}\int_{0}^{\infty} \dfrac{2dz}{z^2+1} = \dfrac{2}{c}(\arctan(\infty)-\arctan(0)) = \dfrac{\pi}{c}
	\end{equation}
	Abbiamo che, per orbite prossime a quella separatrice, il valore di $\Delta\theta$ non dipende da $E$ (visto che $c$ è costante). Questa è cosa buona e giusta ma non basta: vogliamo orbite chiuse, quindi richiediamo che $c$ sia un razionale
	
	
	Possiamo finalmente concludere la dimostrazione sulle orbite chiuse. Abbiamo valutato cosa succede per orbite arbitrariamente vicine a orbite circolari ottendendo il risultato:
	\begin{equation}\label{key}
		\Delta\theta = \dfrac{\pi}{\sqrt{c}}
	\end{equation}
	Mentre per orbite vicine a quella che fugge all'infinito, abbiamo che
	\begin{equation}\label{key}
		\Delta\theta = \dfrac{\pi}{c}
	\end{equation}
	Se ipotizziamo che $\Delta\theta$ sia una funzione dell'orbita, ad esempio  $\Delta\theta = \Delta\theta(E)$, allora tale valore dovrà variare con continuità fra i due estremi $E_{min}$ (l'energia minima, quella dell'orbita circolare) e $E=0$ (l'energia massima per orbite limitate, quella della separatrice). Ma noi sappiamo i valori di $\Delta\theta$ ai due estremi delle energia: se questi due valori non coincidono, per il teorema di Weierstrass sulle funzioni continue, allora $\Delta\theta$ assume tutti i valori possibili fra:
	\begin{equation}\label{key}
		\dfrac{\pi}{c} < \Delta\theta < \dfrac{\pi}{\sqrt{c}}
	\end{equation}
	E questa cosa non va bene perché allora esisteranno orbite in cui $\Delta\theta$ è irrazionale rispetto a $\pi$ e l'orbita non è chiusa. Devo avere necessariamente che i due estremi coincidano se voglio una condizione di chiusura globale, per tutte le orbite limitate, cioè:
	\begin{equation}\label{key}
		\dfrac{\pi}{c} = \dfrac{\pi}{\sqrt{c}}
	\end{equation}
	e cioè $c=1$, che è proprio caratteristico del potenziale di Keplero. 
	
	In realtà ci sarebbe anche il potenziale elastico, $V(r) = Ar^2$ ma non l'abbiamo individuato con questo secondo metodo perché abbiamo richiesto implicitamente che $V(r)\to0$ quando $r\to\infty$. Quello che possiamo allora concludere che il potenziale kepleriano di forma:
	\begin{equation}\label{key}
		V(r) = -\dfrac{k}{r}
	\end{equation}
	è \textit{l'unico potenziale} che si attenua all'infinito a godere della proprietà di avere orbite definitivamente chiuse, ovunque.
	
	\subsection{Potenziale elastico e sovrapposizione di Lagrangiane}
	Prendiamo un potenziale elastico nel piano $V(r) = \dfrac{k}{2}r^{2} = k(x^{2}+y^{2})$. La lagrangiana prende la forma molto simmetrica (se scritta in coordinate cartesiane):
	\begin{equation}
		\Lambda = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2}) - \dfrac{k}{2}(x^{2}+y^{2})
		\label{LagXY}
	\end{equation}
	che posso riscrivere come:
	$$
	\Lambda = \dfrac{1}{2}(m\dot{x}^{2}-kx^{2}) + \dfrac{1}{2}(m\dot{y}^{2}-ky^{2}) = \Lambda_{x} + \Lambda_{y}
	$$
	Quando applico l'operatore di Lagrange rispetto alla variabile $x$, ad esempio, tutto il termine $\Lambda_{y}$ scompare e non modifica l'evoluzione temporale della coordinata $x$. La Lagrangiana così scritta è la somma di due lagrangiane indipendenti e possiamo interpretare il sistema totale come la sovrapposizione di due sistemi (oscillatori in questo caso) totalmente indipendenti. È facile verificare che le energia di tali sottosistemi sono ancora integrali primi del moto per la lagrangiana risultante:
	$$
	E_{x} = \dfrac{1}{2}m\dot{x}^{2} + \dfrac{1}{2}kx^{2}
	$$
	$$
	E_{y} = \dfrac{1}{2}m\dot{y}^{2} + \dfrac{1}{2}ky^{2}
	$$
	Da questa proprietà dell'operatore lagrangiano segue un'importanta caratteristica della funzione lagrangiana: la lagrangiana di due sistemi meccanici non interagenti è la somma algebrica della lagrangiana dei due sottosistemi, ognuno con le sue coordinate. In altre parole, le lagrangiane sono sommabili per sistemi indipendenti.
	
	Volendo trovare l'equazione del moto per la lagrangiana di (\ref{LagXY}), basta separare le variabili a partire dalle equazioni per l'energia e ottenere i due moti $x(t), y(t)$. Ponendo ad esempio $x(0)=x_{0}, y(0) = 0, \dot{x}(0) = 0, \dot{y}(0) = v_{0}$, otterremo:
	\begin{equation}
		\begin{cases}
			x(t) = x_{0}\cos(\omega t) \\
			y(t) = \dfrac{v_{0}}{\omega}\sin(\omega t)
		\end{cases}
	\end{equation}
	%%DISEGNO%%
	E la soluzione generale per $r(t)$, essendo $r^{2}(t) = x^{2}(t) + y^{2}(t)$, vale:
	$$
	r(t) = \sqrt{x_{0}^{2}\cos^{2}(\omega t) + \dfrac{v_{0}^{2}}{\omega^{2}}\sin^{2}(\omega t)}
	$$
	Questa soluzione descrive un'ellisse nel piano $x-y$, data dall'equazione:
	$$
	\dfrac{x^{2}}{x_{0}^{2}} + \omega^{2}\dfrac{y^{2}}{v_{0}^{2}} = 1
	$$
	L'ellisse è un'orbita chiaramente chiusa, quindi è verificato che anche il potenziale elastico genera orbite chiuse.
	\subsubsection{Un altro esempio di sistemi interagenti}
	Il ragionamento appena esposto può essere utilizzato anche nel verso opposto. Immaginiamo di avere un problema unidimensionale in cui esiste un potenziale della forma:
	\begin{equation}
		V(x) = \dfrac{L}{2mx^{2}} + \dfrac{k}{2}x^{2}
		\label{PotEsempio}
	\end{equation}
	con $L,k$ parametri arbitrari fisici. Da considerazioni precedenti, sappiamo che i problemi unidimensionali sono sempre integrabili e potremmo ricavare le equazioni del moto dall'equazione dell'energia:
	$$
	E = \dfrac{1}{2}m\dot{x}^{2} + \dfrac{L}{2mx^{2}} + \dfrac{k}{2}x^{2}
	$$
	Oppure potremmo notare una particolare somiglianza fra il potenziale (\ref{PotEsempio}) e il potenziale efficace generato da Keplero. Se infatti rinominiamo $x=r$:
	$$
	V(r) = \dfrac{L}{2mr^{2}} + \dfrac{k}{2}r^{2}
	$$
	e introduciamo una nuova variabile $\theta(t)$ tale che sia verificata la condizione:
	$$
	L = mr^{2}(t)\dot{\theta}(t)
	$$
	formalmente, dunque, $\theta(t)$ non è libera di assumere qualsiasi valore ma è vincolata da $r(t)$ (come è giusto che sia, il problema è unidimensionale in fondo). Stiamo complessificando il problema aggiungendo una dimensione aggiuntiva ($\theta$) di cui poi ci sbarazzeremo per semplificare i calcoli vincolandola ad un certo comportamento di $r(t)$. Ora che siamo in una situazione bidimensionale, possiamo riscrivere la coppia $(r,\theta)$ come:
	\begin{equation}
		\begin{cases}
			x(t) = r(t)\cos(\theta(t)) \\
			y(t) = r(t)\sin(\theta(t))
		\end{cases}
	\end{equation}
	Introducendo due variabili alternative $x,y$ che possiamo interpretare come coordinate per lo stesso problema. L'energia ora diventa molto più facile e simmetrica,
	$$
	E = \Bigl(\dfrac{1}{2}m\dot{x}^{2} + \dfrac{1}{2}kx^{2}\Bigl) + \Bigl(\dfrac{1}{2}m\dot{y}^{2} + \dfrac{1}{2}ky^{2}\Bigl)
	$$
	Nelle nuove coordinate $(x,y)$, la lagrangiana è la somma di due sistemi indipendenti, e dunque le soluzioni per $x(t), y(t)$ sono semplici. Bisogna a questo punto solo valutare le condizioni iniziali. Ponendo, ad esempio, $r(0) = r_{0} \mbox{ e } \dot{r}(0) = 0$, dovrà necessariamente essere che $\theta(0)=0 \mbox{ e } \dot{\theta}(0) = \dfrac{L}{mr_{0}^{2}}$ (per come è stata definita la variabile $\theta(t)$). Abbiamo in pratica stabilito le condizioni iniziali su $\theta$ ricordando che $\theta$ non è un grado di libertà in più e dunque deve essere determinata una volta noto $r$. Le medesime condizioni iniziali tradotte per $x,y$ diventano:
	\begin{equation}
		\begin{cases}
			x_{0} = r_{0}  \>\>\>\>\>\>\>\>\> \dot{x}_{0} = 0 \\
			y_{0} = 0  \>\>\>\>\>\>\>\>\> \dot{y}_{0} = \dfrac{L^{2}}{mr_{0}} \\
		\end{cases}
	\end{equation}
	da cui deduco le soluzioni:
	\begin{equation}
		\begin{cases}
			x(t) = r_{0}\cos(\omega t) \\
			y(t) = \dfrac{L^{2}}{mr_{0}\omega}\sin(\omega t)
		\end{cases}
	\end{equation}
	con $k = \omega/m$. Tornando alla variabile fisica di interesse, $r$, otterremo alla fine:
	$$
	r(t) = \sqrt{r_{0}^{2}\cos^{2}(\omega t) + \dfrac{L^{4}}{m^{2}r_{0}^{2}\omega^{2}}\sin^{2}(\omega t)}
	$$
	Abbiamo ottenuto una forma analitica per $r(t)$ senza valutare la separazione di variabili prodotta dall'energia.
	Questo ragionamento poteva essere applicato anche per una generica forma del potenziale:
	$$
	V(r) = \dfrac{A}{r^{2}} + Br^{2}
	$$
	\subsection{Considerazioni di scala}
	I potenziali fisici aventi la forma:
	$$
	V(r) = k r^{\alpha}
	$$
	sono omogenei di ordine $\alpha$, cioè godono della proprietà:
	$$
	V(\lambda r) = \lambda^{\alpha} V(r)
	$$
	Possiamo pensare la trasformazione $r \rightarrow \lambda r$ come un riscalamento moltiplicativo delle unità di misura spaziali (dunque non solo come un artificio matematico). Quello che ci proponiamo di fare in questa sezione è di verificare cosa accade alle equazioni del moto quando effettuiamo tali riscalamenti dello spazio ma anche del tempo.
	
	Cominciamo da una considerazione sulla lagrangiana. È facile verificare che, riscalando la lagrangiana di un fattore arbitrario $c$:
	$$
	\Lambda \rightarrow c\Lambda
	$$
	le equazioni del moto (soluzioni di $Lag(\Lambda) = 0$) rimangono inalterate.
	Andiamo ora a riscalare sia lo spazio che il tempo ridefinendo due nuove variabili $x',t'$:
	\begin{equation}
		x' = \lambda x \>\>\>\>\>\>\>\>\>\>\>\> t' = \mu t
	\end{equation}
	In altre parole, le nuove variabili $x',t'$ rappresentano lo spazio percorso e il tempo intercorso secondo altre unità di misura rispetto a quelle di $x,t$. Nelle nuove unità di misura, la velocità riscala come:
	$$
	v' = \dfrac{\lambda}{\mu}v
	$$
	e la Lagrangiana (se il potenziale è omogeneo di grado $\alpha$) diventa:
	$$
	\Lambda' = T' - V' = \dfrac{\lambda^{2}}{\mu^{2}}T-\lambda^{\alpha}V
	$$
	In generale, dunque, la lagragiana non viene semplicemente riscalata in maniera lineare e moltiplicativa. La Lagrangiana appena descritta dunque rappresenta generalmente una fisica diversa da quella iniziale, $\Lambda$, e consegue che le soluzioni del moto scritte nelle nuove unità di misura $x'(t')$ non sono le stesse di quelle nelle precedenti unità di misura (cioè non posso prendere la forma analitica di $x(t)$ e sostituire brutalmente $x\rightarrow x'$, $t'\rightarrow t)$.
	\begin{comment}
		A titolo d'esempio, consideriamo un oscillatore armonico in cui:
		$$
		x(t) = A\sin(\omega t)
		$$
		dove ad esempio $x$ è espresso in metri e $t$ in secondi. Se volessi passare ad una descrizione in $km$ e $h$, potrei semplicemente scrivere:
		$$
		x'(t') = A'\sin(\omega t')
		$$
		dove $A'$ è una condizione iniziale fissata da $x'(0) = \lambda x(0) = \lambda A$, dunque:
		$$
		x'(t') = \lambda A \sin(\omega t')
		$$
		che è la soluzione di una lagrangiana quadratica prodotta dall'oscillatore armonico (e $\omega$ è la stessa essendo ricavata dalla forma dell'equazione differenziale che definisce il problema). Ma questa soluzione non va bene. Infatti, se
		$$
		\lambda = \dfrac{1}{1000} \>\>\>\>\>\>\>\> \mu = \dfrac{1}{3600}
		$$
		al tempo $t_{0}= \dfrac{1}{\omega}, t'_{0} = \dfrac{1}{3600\omega}$ il corpo si trova a:
		\begin{equation}
			\begin{cases}
				x(t_{0}) = A\sin(1) \\
				x'(t'_{0}) = \dfrac{1}{1000}A\sin\Bigl(\dfrac{1}{3600}\Bigl) 
			\end{cases}
		\end{equation}
		I due valori di $x,x'$ devono rappresentare la stessa posizione, quindi devono essere l'uno $1000$ l'altro. Questo è evidentemente falso (gli argomento dei due seni sono diversi). Il problema, qui, è dovuto al fatto che nella soluzione corretta ci saremmo aspettati un fattore $\mu$ anche dentro all'argomento del seno, dovuto al fatto che anche $\omega$ dipende dalla scelta delle unità di misura.
	\end{comment}
	C'è però un caso particolare. Se il riscalamento spaziale/temporale avviene di modo che:
	\begin{equation}
		\dfrac{\lambda^{2}}{\mu^{2}} = \lambda^{\alpha}
		\label{Scala}
	\end{equation}
	ovvero
	$$
	\mu = \lambda^{\dfrac{2-\alpha}{2}}
	$$
	allora:
	$$
	\Lambda' \rightarrow (\lambda^{\alpha})\Lambda = c\Lambda
	$$
	cioè la lagrangiana viene riscalata perfettamente di un solo fattore moltiplicativo e le soluzioni del moto, per quanto detto in precedenza, sono sempre le stesse. Quindi, se $x(t)$ era soluzione, posso ottenere $x'(t')$ semplicemente sostituendo $x\rightarrow x'$, $t'\rightarrow t)$. Questa però non è esattamente la soluzione che cercavamo, ma solo una delle soluzione possibili. Bisogna infatti fare in modo che le condizioni iniziali siano coerenti: se $x(t=0) = x_{0}$, allora $x'(t'=0) = \lambda x(t=0) = \lambda x_{0}$. Ne segue che la soluzione corretta deve avere la forma:
	$$
	x'(t') = \lambda x (t ) = \lambda x(t' \lambda^{\dfrac{\alpha-2}{2}})
	$$
	e questa sarà la soluzione coerente con le condizioni iniziali adattate. 
	
	Il discorso che abbiamo fatto si presta, in un certo senso, ad una generalizzazione che va oltre il semplice problema del cambio di unità di misura. Abbiamo infatti ricavato un'importante proprietà delle soluzioni di problemi fisici con potenziali omogenei: se $x(t)$ è una soluzione, ne posso ottenere di altre che risolvono le stesse equazioni del moto (ma con condizioni iniziali diverse) semplicemente "riscalando" le coordinate in una certa maniera! Facciamo un esempio: si consideri un problema in cui l'orbita nel piano delle fasi sia:
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-4,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,-3) -- (0,3) node[above] {$\dot{x}$};
			\draw(0,0) ellipse (1cm and 0.75cm);
		}
	\end{figure}
	Allora riscalare spazio e tempo con il vincolo di (\ref{Scala}) vuol dire allungare/stretchare in una certa maniera i due assi del piano delle fasi (la dipendenza dal tempo è implicita in $\dot{x}$) di modo che l'orbita ellittica raffigurata sia ancora una possibile soluzione del problema (con altre condizioni iniziali, perché ora l'ellisse apparirà più piccola/grande). Non avessimo rispettato la condizione di (\ref{Scala}), corriamo il rischio che, nelle nuove coordinate apicate, l'orbita ellittica non sia soluzione (perché, ad esempio, le soluzioni sono circolari).
	
	Possiamo però pensarla in maniera differente. Se, a partire dalla soluzione ellittica mostrata, deformiamo l'orbita (l'orbita, non le coordinate) di modo che segua le regole di (\ref{Scala}), allora la nuova orbita è ancora soluzione del problema! La vecchia orbita deformata atterra su di un orbita che risolve ancora il problema (ma parte da una condizione iniziale differente):
	
	\begin{figure}[H]
		\centering
		\tikz{
			\draw[->] (-4,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,-3) -- (0,3) node[above] {$\dot{x}$};
			\draw(0,0) ellipse (2cm and 1.5cm);
			\draw(0,0) ellipse (1cm and 0.75cm);
			\draw[->] (1,0.5)  -- (1.5, 0.7);
			\draw[->] (-1,-0.5)  -- (-1.5, -0.7);
			\draw[->] (-1,0.5)  -- (-1.5, 0.7);
			\draw[->] (1,-0.5)  -- (1.5, -0.7);
		}
		\caption{\textit{Se l'equazione $x(t)$ risolveva il problema (ellisse più piccola), allora anche la soluzione $x_{1}(t) = \lambda x(t \lambda^{\alpha/2-1})$, l'ellisse più grande, è una possibile soluzione del problema. Non è strettamente necessario che la forma venga preservata (cioè che anche la seconda orbita sia ellittica), l'importante è che sia soluzione anch'essa dell'equazione del moto.}}
	\end{figure}
	Questa \textit{considerazione di scala} ci consente di ricavare in maniera rapida alcune proprietà note relativi a problemi fisici in cui il potenziale è omogeneo. Si consideri, ad esempio, un problema in cui le orbite siano periodiche. Data una soluzione $x(t)$ con $x(t+T) = x(t)$, allora ne posso costruire di infinite riscalando spazio e tempo in maniera conforme a (\ref{Scala}). Prendiamone una, $x'(t) = \lambda x(t \lambda^{\alpha/2-1}) $ con un certo $\lambda$ fissato. Il periodo di percorrenza della seconda orbita scala come il tempo, perciò mi aspetto che
	$$
	T' = T \lambda^{1-\dfrac{\alpha}{2}}
	$$
	Mentre una generica distanza caratteristica dell'orbita $d$ viene chiaramente riscalata come $d' = \lambda d$. Se ipotizzo che debba esistere una certa relazione funzionale fra $T$ e $d$, allora questa deve avere la forma:
	$$
	T \propto  d^{1-\alpha /2}
	$$
	se questa è valida, infatti è vera anche:
	$$
	T' \propto  (d')^{1-\alpha /2}
	$$
	Attenzione: qui le grandezze apicate vanno intese non come la stessa grandezza espressa in un'unità di misura differente, ma come due grandezze diverse inerenti a due diverse orbite.
	
	Se $\alpha = 2$, allora $T \propto d^{0}$, cioè il periodo di un'orbita è indipendente dalla sua dimensione. Questo ci torna: il potenziale quadratico è tipico degli oscillatori armonici e, in tal caso, il periodo è effettivamente indipendente dall'energia dell'orbita (legata alla sua ampiezza). Se invece $\alpha=-1$, allora $T\propto d^{3/2}$ e ritroviamo la terza legge di Keplero ($\alpha = -1$ è tipico del potenziale gravitazionale).
	\subsubsection{Dipendenza funzionale di $E$ da $I$}
	Consideriamo un problema unidimensionale in cui le orbite siano chiuse, così da poter parlare di azione:
	\begin{equation}
		I =\dfrac{1}{2\pi} \oint_{H=E} p\>dx
		\label{Azione}
	\end{equation}
	L'energia si scrive come\footnote{Perché le orbite siano definitivamente chiuse, l'esponente del potenziale deve essere pari}:
	$$
	E = \dfrac{p^{2}}{2m} + kx^{2a}
	$$
	da cui, sostituendo $p$ nell'espressione dell'azione, si ricava che:
	\begin{equation}
		I =\dfrac{1}{\pi} \int_{H=E} \sqrt{2E - kx^{2a}}dx
	\end{equation}
	A livello dimensionale, l'azione è un'energia per tempo, per cui scalerà secondo:
	$$
	I' = \dfrac{\lambda^{2}}{\mu} I 
	$$
	Imponendo la condizione di (\ref{Scala}), si ottiene che l'azione scalerà:
	$$
	I' = \lambda^{1+a} I
	$$
	Al contrario l'energia scala come:
	$$
	E' = \lambda^{2a}E
	$$
	Con gli stessi ragionamenti fatti in precedenza, ci accorgiamo che per un problema fisico unidimensionale a potenziale omogeneo, azione e energia devono seguire una relazione del tipo:
	$$
	E \propto I^{\dfrac{2a}{1+a}}
	$$
	La stessa relazione potevamo ricavarla direttamente dalla formula (\ref{Azione}). Infatti, essendo:
	\begin{equation}\label{key}
		T(E) = 2\int_{x_1}^{x_2} \dfrac{dx}{\sqrt{2(E-kx^{2\alpha})}}
	\end{equation}
	Vogliamo estrarre la dipendenza dall'energia in questo integrale. Allora definiamo una nuova variabile:
	$$
	u = \dfrac{x}{E^{1/2\alpha}}, 	\quad \quad x^{2\alpha} = u^{2\alpha} E
	$$
	e dunque:
	$$
	dx = E^{1/2\alpha} du
	$$
	\begin{equation}\label{key}
		T(E) = 2 E^{1/2\alpha} \int_{u_1}^{u_2} \dfrac{du}{\sqrt{2(E-kE u^{2\alpha})}} =  2 E^{1/2\alpha-1/2}\int_{u_1}^{u_2} \dfrac{du}{\sqrt{2(1-ku^{2\alpha})}}
	\end{equation}
	e dunque:
	\begin{equation}
		T(E) \propto E^{\frac{1-\alpha}{2\alpha}}
		\label{Periodo}
	\end{equation}
	Poiché ci ricordiamo che:
	\begin{equation}\label{key}
		\dfrac{dI}{dE} = T(E)
	\end{equation}
	allora la relazione fra $I$ ed $E$ risulta essere:
	\begin{equation}\label{key}
		I  \propto E^{\frac{1+\alpha}{2\alpha}}
	\end{equation}
	
	La relazione (\ref{Periodo}) ci fornisce informazioni molto importanti. Se, infatti, $\alpha=0$, e cioè il potenziale omogeneo $V$ ha la forma:
	$$
	V = kx^2
	$$
	allora avremo che:
	$$
	T(E) \propto E^0 = 1
	$$
	cioè il periodo non dipende dall'energia dell'orbita. Questo è proprio il caso dell'oscillatore armonico, come abbiamo già visto, nel quale il periodo è dato una volta noto $\omega$, indipendentemente dall'ampiezza di oscillazione. Se, invece, $\alpha = -\dfrac{1}{2}$, allora abbiamo un potenziale di natura kepleriana:
	$$
	V = -\dfrac{k}{r}
	$$
	e:
	$$
	T(E) \propto E^{-\dfrac{3}{2}}
	$$
	conformemente a quanto già trovato.
	
	\subsection{Forma delle orbite kepleriane}
	Torniamo al problema del potenziale in campo centrale. Se il potenziale può essere scritto come:
	$$
	V(r) = -\dfrac{k}{r^{a}}
	$$
	Allora l'energia assume la forma semplice e unidimensionale (come da (\ref{En1d})):
	$$
	E = \dfrac{1}{2}m\dot{r}^{2} + \dfrac{p_{\theta}^{2}}{2mr^{2}} - \dfrac{k}{r}
	$$
	potendo definire dunque un \textit{potenziale efficace} del tipo $V_{eff}(r) =  \dfrac{p_{\theta}^{2}}{2mr^{2}} - \dfrac{k}{r}$. Posto $u = \dfrac{1}{r}$, come al solito, avremo:
	$$
	E' = \dfrac{1}{2}\Bigl(\dfrac{du}{d\theta}\Bigl)^{2} + \dfrac{1}{2}u^{2} - \dfrac{mk}{p_{\theta}^{2}}u
	$$
	essendo $E' = \dfrac{mE}{p_{\theta}^2}$. Nella variabile $u$ (che, attenzione, è parametrizzata all'angolo e non al tempo), il potenziale efficace diventa:
	$$
	\tilde{V}_{eff}(u) = \dfrac{1}{2}u^2-\dfrac{mk}{p_{\theta}^2}u
	$$
	E dunque cogliamo l'analogia con un problema unidimensionale con variabile $u$ e tempo $\theta$ ( e massa unitaria). La relativa equazione di Newton sarebbe:
	\begin{equation}\label{key}
		\dfrac{d^2u}{d\theta^2} = -u+\dfrac{mk}{p_{\theta}}
	\end{equation}
	dove il primo termine sarebbe l'accelerazione, cioè la derivata seconda \textbf{non} nel tempo ma nel parametro di $u$, che è $\theta$. Questa è un'equazione differenziale che abbiamo già incontrato spesso trattandosi di un oscillatore armonico con forzante costante.  La soluzione è somma dell'omogenea e della particolare, che coincide col termine costante stesso:
	\begin{equation}\label{key}
		u(\theta) = A\cos(\theta-\theta_0)+\dfrac{mk}{p_{\theta}^2}
	\end{equation}
	Pongo $\theta_{0} = 0$ per comodità. Dobbiamo ora determinare il parametro $A$ dalle condizioni iniziali. 
	Ponendo $\theta =0, \pi$ si ottengono le posizioni di pericentro e apocentro:
	\begin{equation}\label{key}
		\begin{cases}
			u(0) = A + \dfrac{mk}{p_{\theta}^2} \\
			u(\theta) = -A + \dfrac{mk}{p_{\theta}^2}
		\end{cases}
	\end{equation}
	Questo perché il coseno varia da -1 a 1 e, dunque, $u(\theta)$ ha estremi definiti. A cosa equivale, ad esempio, $u_{p}$, cioè relativo al pericentro? In tale punto, la quantità $\dfrac{du}{d\theta}$ si annulla perché vi è un'inversione del moto e quindi l'energia diventa, in tali punti:
	$$
	E' = \dfrac{m}{p_{\theta}^2} E = \dfrac{1}{2}u_{p}^2-\dfrac{km}{p_{\theta}^2}u_p
	$$
	Questa è un'equazione di secondo grado in $u_p$ che, risolta, dà come soluzione:
	$$
	u_{1,2} = \dfrac{km}{p_{\theta}^2}\pm\sqrt{\Bigl(\dfrac{km}{p_{\theta}^2}\Bigl)^2+\dfrac{2m}{p_{\theta}^2}E}
	$$
	Le due soluzioni sono chiaramente l'apocentro e il pericentro\footnote{Se $E>0$, allora esiste una sola soluzione accettabile, l'altra è negativa. Questa corrisponde al fatto che per energie positive l'orbita non è limitata e c'è solo un'inversione. Inoltre l'argomento della radice deve essere maggiore di $0$ e questo corrisponde alla richiesta che l'energia $E$ sia più grande del minimo di potenziale.}. Il pericentro è la soluzione con segno $+$, cioè la più grande.
	\begin{equation}\label{key}
		u_p =  \dfrac{km}{p_{\theta}^2}+\sqrt{\Bigl(\dfrac{km}{p_{\theta}^2}\Bigl)^2+\dfrac{2m}{p_{\theta}^2}E}
	\end{equation}
	eguagliando questa espressione per $u_p$ con quella di prima, $u_p = A + \dfrac{km}{p_{\theta}^2}$, otteniamo finalmente che il termine $A$ vale:
	\begin{equation}\label{key}
		A =\sqrt{\Bigl(\dfrac{km}{p_{\theta}^2}\Bigl)^2+\dfrac{2m}{p_{\theta}^2}E}= \dfrac{km}{p_{\theta}^2}\sqrt{1+\dfrac{2Ep_{\theta}^2}{k^2m}}
	\end{equation}
	e quindi, ritornando a $r$:
	\begin{equation}\label{key}
		r(\theta) = \dfrac{1}{\dfrac{km}{p_{\theta}^2}\sqrt{1+\dfrac{2Ep_{\theta}^2}{k^2m}}\cos(\theta)+\dfrac{mk}{p_{\theta}^2}}
	\end{equation}
	\begin{equation}\label{key}
		r(\theta) = \dfrac{\dfrac{p_{\theta}^2}{mk}}{\sqrt{1+\dfrac{2Ep_{\theta}^2}{k^2m}}\cos(\theta)+1}
	\end{equation}
	definendo per comodità:
	\begin{equation}\label{key}
		P = \dfrac{p_{\theta}^2}{mk}
	\end{equation}
	
	\begin{equation}
		e =\sqrt{1+\dfrac{2Ep_{\theta}^2}{k^2m}}
	\end{equation}
	La forma dell'orbita diventa:
	\begin{equation}\label{key}
		r(\theta) = \dfrac{P}{1+e\cos(\theta)}
	\end{equation}
	che è esattamente l'equazione di una conica nel piano con un fuoco nel centro del campo centrale. Il parametro $e$, detto \textit{eccentricità}, regola la natura della quadrica: se $e<1$, allora la curva è un'ellisse, mentre se $e=1$ è una parabola. Per valori maggiori dell'unità, si tratta di iperboli.
	\subsubsection{Le leggi di Keplero}
	A partire dalla formula analitica del potenziale di Keplero, Newton riuscì a dimostrare su carta la validità delle tre leggi di Keplero, scoperte sperimentalmente.
	\begin{itemize}
		\item La prima legge di Keplero afferma che le orbite sono piane, chiuse ed ellittiche. L'abbiamo già ampiamento dimostrato
		\item La seconda legge ci dice che il raggio vettore spazza aree uguali in tempi uguali. Riformulato in altre parole, la velocità areolare si mantiene costante. Per dimostrarlo, immaginiamo uno spostamento infinitesimo nel piano, da $\vec{r}(t)$ a $\vec{r}(t+dt)$. Il tratto percorso può essere considerato rettilineo. L'area infinitesima spazzata vale:
		$$
		dA = \dfrac{1}{2}r^2(t)d\theta
		$$
		e quindi:
		$$
		\dot{A} = \dfrac{1}{2}r^2(t)\dot{\theta}
		$$
		Ma noi sappiamo che:
		$$
		p_{\theta} = mr^2\dot{\theta} = const
		$$
		e quindi
		$$
		\dot{A} = \dfrac{p_{\theta}}{2m} = const
		$$
		\item La terza legge di Keplero ci dice che il periodo di un orbita è proporzionale al semiasse maggiore alla potenza $3/2$. L'abbiamo già dimostrato per considerazioni di scala, ma possiamo anche verificarlo analiticamente. Il periodo di un'orbita è, infatti:
		$$
		T = \dfrac{A}{\dot{A}}
		$$
		che segue dalla definizione stessa di velocità areolare $\dot{A}$ (e non mi servono integrali perché è costante). L'area di un'ellisse è:
		$$
		A = \pi ab
		$$
		con $a$ semiasse maggiore, $b$ semiasse minore. Fra questi vale una relazione geometrica:
		$$
		e = \sqrt{1-\dfrac{b^2}{a^2}}
		$$
		quindi
		$$
		b = a\sqrt{1-e^2} = a\sqrt{\dfrac{2Ep_{\theta}^2}{k^2m}}
		$$
		Ma:
		$$
		a = \dfrac{2k}{E}
		$$
		dunque:
		$$
		b = \sqrt{a}\sqrt{\dfrac{p_{\theta}^2}{km}}
		$$
		L'area è allora:
		$$
		A = \pi a^{3/2}\sqrt{\dfrac{p_{\theta}^2}{km}}
		$$
		e il periodo:
		$$
		T = 2\pi a^{3/2}\sqrt{\dfrac{m}{k}}
		$$
	\end{itemize}
	\newpage
	\section{Altre applicazioni della meccaninca lagrangiana}
	\subsection{Problema dei due corpi}
	Studiamo il cosiddetto problema dei due corpi, ovvero la dinamica di un sistema nello spazio tridimensionale in cui sono immersi due punti materiali di massa $m_1, m_2$ isolati\footnote{Attenzione, questo problema è diverso dal caso precedente del punto materiale soggetto a campo centrale. In quel caso la sorgente del campo era fissa nell'origine, qui invece le due sorgenti si possono muovere. I due problemi sono in realtà collegati, ma lo vedremo solo a posteriori.}. I due corpi possono interagire mutuamente. Stabilendo un sistema di riferimento arbitrario nello spazio, la lagrangiana del sistema è:
	\begin{equation}\label{key}
		\Lambda=  \dfrac{1}{2}m_1(\dot{\vec{r}}_{1})^{2} + \dfrac{1}{2}m_2(\dot{\vec{r}}_{2})^{2} - V(\vec{r}_1,\vec{r}_2)
	\end{equation}
	Se però il sistema è isolato, il potenziale $V$ non può che dipendere dalla distanza relativa fra i due corpi, $ \vec{r} = \vec{r}_1-\vec{r}_2 $. Questo perché il potenziale deve essere uno scalare, cioè invariante per traslazione/rotazione degli assi coordinati (non può certo dipendere da dove io ponga l'origine degli assi. I due corpi sono immersi nello spazio isotropo e omogeneo, non c'è posizione o direzione privilegiata). Il raggio vettore $\vec{r}$, in realtà, non è propriamente un vettore in senso fisico in quanto fortemente legato all'origine del sistema di riferimento (non covaria col gruppo di Galileo): il vero vettore è lo spostamento, $\Delta \vec{r}$. Non solo: il potenziale deve dipendere al massimo dal modulo della distanza relativa, che chiamiamo:
	$$
	r = |\vec{r}_1-\vec{r}_2|
	$$
	
	Allora la lagrangiana diventa
	\begin{equation}\label{key}
		\Lambda=  \dfrac{1}{2}m_1(\dot{\vec{r}}_{1})^{2} + \dfrac{1}{2}m_2(\dot{\vec{r}}_{2})^{2} - V(r)
	\end{equation}
	Facciamo ora un cambio di coordinate, definendo due nuovi vettori:
	\begin{equation*}\label{key}
		\vec{r}_{CM} = \dfrac{m\vec{r}_1+m_2\vec{r}_2}{m_1+m_2} 
	\end{equation*}
	\begin{equation*}\label{key}
		\vec{r} = \vec{r}_1 - \vec{r}_2
	\end{equation*}
	Da cui
	\begin{equation}\label{key}
		\dot{\vec{r}}_{CM} = \vec{v}_{CM} = \dfrac{m\vec{v}_1+m_2\vec{v}_2}{m_1+m_2} 
	\end{equation}
	\begin{equation*}\label{key}
		\dot{\vec{r}} = \dot{\vec{r}}_1 - \dot{\vec{r}}_2
	\end{equation*}
	e le velocità iniziali diventano
	\begin{equation}
		\vec{r}_1 = \vec{r}_{CM} - \dfrac{m_2}{m_1+m_2}\vec{r}
		\label{trasfRaggio}
	\end{equation}
	\begin{equation*}\label{key}
		\vec{r}_2 = \vec{r}_{CM} + \dfrac{m_1}{m_1+m_2}\vec{r}
	\end{equation*}
	$$
	\downarrow
	$$
	
	\begin{equation}\label{key}
		\dot{\vec{r}}_1 = \vec{v}_{CM} - \dfrac{m_2}{m_1+m_2}\dot{\vec{r}}
	\end{equation}
	\begin{equation*}\label{key}
		\dot{\vec{r}}_2 = \vec{v}_{CM} + \dfrac{m_1}{m_1+m_2}\dot{\vec{r}}
	\end{equation*}
	Allora la lagrangiana del sistema diventa, con le nuove coordinate,
	\begin{equation}\label{key}
		\Lambda(\vec{r}_{CM},\vec{r}) = \dfrac{m_1+m_2}{2}\vec{v}_{CM}\>^{2} + \dfrac{m_1 m_2}{m_1 + m_2} \dfrac{1}{2} \dot{\vec{r}}\>^{2} - V(|\vec{r})
	\end{equation}
	Definiamo la \textit{massa ridotta} come:
	$$
	\mu = \dfrac{m_1 m_2}{m_1+m_2}
	$$
	e la massa totale $M = m_1+m_2$,
	\begin{equation}\label{key}
		\Lambda(\vec{r}_{CM},\vec{r}) = \dfrac{1}{2}M\vec{v}_{CM}\>^{2} + \dfrac{1}{2} \mu \dot{\vec{r}}\>^{2} - V(|\vec{r})
	\end{equation}
	Quest'ultima equazione è significativa. Infatti la lagrangiana appena scritta è formata da due termini indipendenti, una lagrangiana relativa alla coordinate $\vec{r}_{CM}$, la lagrangiana del centro di massa, e una lagrangiana relativa alla coordinata $\vec{r}$, la lagrangiana propria del sistema
	\begin{equation}\label{key}
		\Lambda(\vec{r}_{CM},\vec{r}) = \Lambda_{CM}(\vec{r}_{CM}) + \Lambda(\vec{r})
	\end{equation}
	\begin{equation}\label{key}
		\begin{aligned}
			\Lambda_{CM} = \dfrac{1}{2}M\vec{v}_{CM}\>^{2} \\
			\Lambda(\vec{r}) = \dfrac{1}{2}\mu\dot{\vec{r}}\>^{2} - V(r)
		\end{aligned}
	\end{equation}
	In altre parole, ogni sistema a due corpi può essere pensato come la sovrapposizione indipendente di due sistemi diversi. Il primo, quello del centro di massa, e il secondo, che descrive le interazione relative dei due corpi. È facile verificare che $\vec{r}_{CM}$ è coordinata ciclica e quindi $\vec{p} = M\dot{\vec{r}}_{CM} = M\vec{v}_{CM}$ è integrale primo del moto (corrisponde alla quantità di moto totale del sistema, equivalente alla quantità di moto del centro di massa). Essendo questo conservato, allora necessariamente $\vec{v}_{CM} = const$, dunque spesso viene comodo porsi nel sistema di riferimento in cui $\vec{v}_{CM} = 0$ indefinitamente nel tempo, così che la lagrangiana del sistema diventi banalmente:
	$$
	\Lambda = \dfrac{1}{2}\mu\dot{\vec{r}}\>^{2} - V(r)
	$$
	Dunque il solo termine \textit{relativo} della lagrangiana descrive la fisica del sistema vista dal sistema di riferimento in cui il centro di massa è fermo. Questa Lagrangiana descrive un punto materiale soggetto ad un potenziale di tipo centrale, esattamente il problema già risolto! Ci siamo dunque ricondotti al caso già esaminato. Se $V$ è il potenziale kepleriano, allora $\vec{r}$ descrive ellissi con un fuoco nel centro di massa del sistema binario. Ma poiché fra $\vec{r}$ e $\vec{r}_1$ c'è una relazione di tipo lineare (lo stesso vale per $\vec{r}_2$), allora anche i due vettori $\vec{r}_1,\vec{r}_2$ descrivono due ellissi con un fuoco nel centro di massa (riscalate dal fattore di (\ref{trasfRaggio}), quindi ad esempio se $m_1 << m_2$, allora $\vec{r}_2 \approx \vec{r}_{CM} = 0$).
	
	
	C'è anche di più. Il sistema è invariante per rotazioni, poiché il potenziale e la cinetica dipendono solo dal modulo di $\vec{r}$. Allora si deve conservare il vettore momento angolare $\vec{L}$, calcolato rispetto a qualsiasi polo:
	$$
	\vec{L} = \mu \vec{r}\times\dot{\vec{r}}
	$$ 
	Se $\vec{L}$ si conserva, allora necessariamente $\vec{r} \mbox{ e } \dot{\vec{r}}$ devono essere sempre nello stesso piano. In altre parole, la fisica del sistema a due corpi si svolge sempre in un piano e non riempie tutto lo spazio tridimensionale. Allora conviene usare coordinate polari nel piano di moto\footnote{In realtà non nel piano del moto fisico. Il vettore $\vec{r}$ rappresenta la distanza relativa, ed è tale vettore che spazza un piano. Centriamo $\vec{r}$ nel centro del sistema e usiamo le polari in questo nuovo sistema traslato.} (nel sistema di riferimento del centro di massa):
	$$
	\Lambda = \dfrac{1}{2}\mu (\dot{r}^{2} + r^2\dot{\theta}^2) - V(r)
	$$
	dove appunto $|\vec{r}| = r$ e $\theta$ è l'angolo identificato dal vettore $\vec{r}$ rispetto ad un asse fisso. Avendo come integrale primo del moto il momento angolare (che in questo caso è perpendicolare al piano di $\vec{r}$), sappiamo che possiamo identificare $\vec{L}_{z}$ come $p_{\theta}$, riducendo dunque ulteriormente la dimensionalità del problema. Arriviamo allora ad una forma di lagrangiana che dipende unicamente dalla coordinata scalare $r$, modulo della distanza fra i corpi. Ma un sistema unidimensionale è sempre integrabile, grazie alla presenza dell'integrale energia, dunque il problema dei due corpi è perfettamente risolvibile.\footnote{Ricapitolando: la quantità di moto conservata permette di sbarazzarmi del termine del centro di massa. Da $6$ gradi di libertà, scendo a $3$. Il momento angolare lungo $z$, l'asse uscente dal piano, garantisce la planarità del moto e il suo modulo contribuisce a togliere $\theta$, scendendo ancora di due gradi di libertà. La conservazione dell'energia riduce l'ultimo grado di libertà rimasto.}
	
	A titolo d'esempio, lo stesso problema ma con tre corpi non può essere risolto con i metodi dell'analisi (non abbiamo abbastanza integrali primi per ridurre la dimensionalità del problema).
	\subsection{Sezione d'urto di particelle}
	
	
	\newpage
	\section{Vincoli}
	La meccanica lagrangiana permette di affrontare in maniera molto naturale ed efficace tutti quei problemi meccanici in cui lo spazio delle configurazioni dei corpi è limitato, cioè in problemi \textit{vincolati}. Esistono diversi tipi di vincoli, ma il più ricorrente è il vincolo \textit{olonomo}, sostanzialmente una forma funzionale del tipo:
	$$
	f(x,y,z) = 0
	$$
	che definisce una varietà, lo spazio delle configurazioni $\mathcal{M}$; le equazioni del moto devono necessariamente appartenere a tale varietà. In altre parole, un vincolo è olonomo se limita secondo certe relazioni analitiche solo i possibili valori delle coordinate e non stabilisce limitazioni sulle velocità generalizzate. Così, ad esempio, un pendolo sferico è un classico problema vincolato. Lo spazio delle configurazioni, in coordinate cartesiane, non è più lo spazio euclideo $\mathbb{R}^{3}$, bensì il luogo geometrico descritto dalla relazione:
	$$
	x^{2}+y^{2}+z^{2} = R^{2}
	$$
	che corrisponde alla varietà bidimensionale $\mathcal{M} = S^{2}(0,1)$, cioè la sfera unitaria. Per completezza, un vincolo è detto \textit{anolonomo} se è descritto da una relazione funzionale del tipo:
	$$
	f(x,y,z,\dot{x},\dot{y},\dot{z}) = 0
	$$
	esprimendo dunque vincoli anche alle velocità del sistema. Nel nostro caso, tuttavia, ci limiteremo solo a vincoli olonomi (che agiscono sullo spazio delle configurazioni e non su quello delle fasi).
	\subsection{L'approccio Newtoniano}
	Il problema del punto materiale vincolato viene risolto in meccanica newtoniana mediante l'aggiunta di determinate forze, dette \textit{reazioni vincolari}, il cui compito è quello di mantenere il corpo sulla varietà per tutti i tempi. Ricordiamo, infatti, che la meccanica newtoniana funziona bene purché ci si trovi ad operare nello spazio euclideo $\mathbb{R}^{3}$: per modificare ciò, volendo cioè che la dinamica del problema non occupi tutto $\mathbb{R}^{3}$ ma solo un suo sottospazio, una sua varietà $\mathcal{M}$, è necessario in primis immergere $\mathcal{M}$ in $\mathbb{R}^{3}$. E poi, per fare in modo che il moto del corpo stia in $\mathcal{M}$, la meccanica newtoniana prescrive l'aggiunta di nuove forze \textit{non attive} il cui valore è incognito a priori e che siano in grado di mantenere l'orbita nella varietà.
	
	L'equazione di Newton diventa in questo caso:
	\begin{equation}
		\vec{F} + \vec{R} = m\vec{a}
		\label{NewtonVincolata}
	\end{equation}
	dove $\vec{R}$ è la forza di reazione vincolare aggiunta ad hoc e $\vec{F}$ è la forza che chiameremo attiva, cioè di cui si conosce il valore a priori. L'eq (\ref{NewtonVincolata}) tuttavia non basta da sola per risolvere le orbite del moto, in quanto $\vec{R}$ è inizialmente sconosciuta. Aggiungendo l'equazione caratteristica del vincolo, però, completiamo il numero di gradi di libertà richiesti e possiamo risolvere per $\vec{x}(t)$, ottenendo inoltre l'informazione di $\vec{R}$.
	%%MAGAri aggiungi forma potenziale per N, quello infinitesimo!
	\subsection{L'approccio Lagrangiano}
	Per quanto funzionante, l'approccio newtoniano sembra aggiungere gradi di libertà aggiuntivi inutili per poi tornare alla domanda iniziale (cioè il moto del corpo). L'atto di immergere la varietà $\mathcal{M}$, che ha una struttura bidimensionale, nello spazio a tre gradi di libertà $\mathbb{R}^{3}$ introduce una dimensionalità in più (rappresentata dalla reazione vincolare) inutile ai fini dell'individuazione delle equazioni del moto. La meccanica lagrangiana consente di evitare tutta questa complessificazione operando direttamente sulla varietà $\mathcal{M}$ che diventa il nuovo spazio delle configurazioni effettivo. Vogliamo dimostrare l'equivalenza dei due metodi (reazione vincolare in $\mathbb{R}^3$ o lagrangiana direttamente su $\mathcal{M}$)
	
	Se il vincolo non dipende dal tempo, allora in genere si definiscono delle coordinate generalizzate $\vec{q}$ che permettano di scrivere la condizione di vincolo come\footnote{Queste sono coordinate di $\mathbb{R}^3$, non propriamente della varietà}:
	\begin{equation}
		q_{n} = const
	\end{equation}
	dove $q_n$ è l'ultima coordinata generalizzata\footnote{Chiaramente l'ordine non è obbligatorio, ma piuttosto una questione di comodità}. In realtà la varietà $\mathcal{M}$ viene descritta solo dalle $q_1, q_2, ... q_{n-1}$ essendo $n-1$-dimensionale. L'ultima coordinata serve per descrivere la varietà immersa in $\mathbb{R}^3$ (e siccome vogliamo dimostrare l'equivalenza logica dei due procedimenti, l'immersione è d'obbligo). Ad esempio, la sfera unitaria è chiaramente ben mappata da $\theta,\varphi$ ma, se voglio immergerla nello spazio tridimensionale $\mathbb{R}^3$ mi tocca anche specificare il raggio (costante).
	
	
	
	Enunciamo ora un importante teorema della meccanica analitica, il \textit{Principio dei lavori virtuali}. 
	\begin{tcolorbox}
		Si definisce spostamento virtuale $\delta \vec{x}$ uno spostamento infinitesimo compatibile con i vincoli \textbf{considerati istanteaneamente fissi} all'istante $t$ se dipendenti dal tempo. Il lavoro virtuale $\delta W$ di una forza $\vec{F}$ è definito come:
		$$
		\delta W = \vec{F} \cdot \delta\vec{x}
		$$
		Allora, il lavoro virtuale per una reazione vincolare $\vec{R}$ è sempre nullo: $\delta W_{vin} = \vec{R}\cdot\delta\vec{x}=0$ 
	\end{tcolorbox}
	È importante capire bene la differenza fra spostamento virtuale $\delta \vec{x}$ e spostamento reale $d\vec{x}$. Se il vincolo non dipende dal tempo, allora le due cose coincidono perfettamente (ed infatti il vincolo non fa lavoro, cioè non modifica l'energia del sistema). Se il vincolo, invece, dipende dal tempo, la faccenda è più complicata. Lo spostamento virtuale viene considerato come se il vincolo fosse istantaneamente fermo, dunque:
	$$
	\delta \vec{x} =\sum_{i=1}^{n-1} \dfrac{\partial \vec{x}}{\partial q_{i}}dq_{i}
	$$
	e sommo solo sulle prime $n-1$-esime coordinate poiché l'ultima è istantaneamente costante.
	Nello spostamento reale devo anche tenere conto del fatto che il vincolo si sta muovendo e dunque:
	$$
	d\vec{x} = \sum_{i=1}^{n-1} \dfrac{\partial \vec{x}}{\partial q_{i}}dq_{i} + \dfrac{\partial \vec{x}}{\partial q_{n}}dq_{n} = \sum_{i=1}^{n-1} \dfrac{\partial \vec{x}}{\partial q_{i}}dq_{i} + \dfrac{\partial \vec{x}}{\partial q_{n}}\dot{q}_ndt
	$$
	Solo lo spostamento reale contribuisce e definire la fisica del sistema (infatti la velocità si costruisce come $d\vec{x} = \vec{v}dt$, e non $\delta \vec{x} = \vec{v}dt$). Il principio dei lavori virtuali sancisce la nullità solo del lavoro rispetto alla spostamento virtuale e non rispetto allo spostamento reale. Infatti, se il vincolo cambia nel tempo, le reazioni vincolari possono fare lavoro e cambiare energia del sistema vincolato.
	
	Chiarita la differenza fra lavoro virtuale e reale, riprendiamo l'equazione di Newton con la reazione vincolare incognita e la forza attiva $\vec{F}$:
	$$
	\vec{F} + \vec{N} = m\vec{a}
	$$
	moltiplicando il tutto per lo spostamento virtuale $\delta x$, avremo che, sfruttando il principio dei lavori virtuali,
	$$
	(\vec{F} + \vec{N})\cdot\delta\vec{x} = \vec{F}\cdot\delta\vec{x} =  m\vec{a}\cdot\delta\vec{x}
	$$
	Esplicitando $\delta\vec{x}$,
	$$
	\vec{F}\cdot\sum_{i=1}^{n-1} \dfrac{\partial \vec{x}}{\partial q_{i}}dq_{i} =  m\vec{a}\cdot\sum_{i=1}^{n-1} \dfrac{\partial \vec{x}}{\partial q_{i}}dq_{i}
	$$
	e cioè:
	$$
	\sum_{i=1}^{n-1}\Bigl(m\vec{a}\cdot\dfrac{\partial \vec{x}}{\partial q_{i}} - \vec{F}\cdot\dfrac{\partial \vec{x}}{\partial q_{i}}\Bigl) = 0
	$$
	Ma questa è proprio l'equazione di Newton in forma covariante (sulla componente $i$-esima)! Non solo: ci siamo totalmente sbarazzati del termine di reazione vincolare. A questo punto, basta trovare la funzione lagrangiana $\Lambda$ sulla varietà $\mathcal{M}$ costruita con la mappa $q_1, q_2, ..., q_{n-1}$ ignorando totalmente la presenza della forza di reazione vincolare e le equazioni del moto sono soluzioni della:
	$$
	\Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_i} - \dfrac{\partial }{\partial q_i}\Bigl)\Lambda = 0
	$$
	dove chiaramente $i = 0,1,2, \dots, n-1$. Abbiamo ottenuto $n-1$ equazioni, che è proprio quello che ci aspettavamo considerando varietà $n-1$ dimensionali, e risolviamo dunque per $q_1(t), q_2(t), ..., q_{n-1}(t)$ (e chiaramente $q_n = const$ da vincolo). I due metodi allora, reazione vincolare e lagrangiana su varietà, sono equivalenti.
	
	Riassumendo, in meccanica lagrangiana non si parla di forze vincolari (o meglio, di potenziali di reazioni vincolari) e per individuare le equazioni del moto basta costruire la Lagrangiana direttamente sulla varietà che il vincolo esprime, dimenticandosi poi della sua presenza. In questo modo, è come se si stesse risolvendo un problema svincolato il cui spazio delle configurazione però è più esotico rispetto al classico spazio euclideo $\mathbb{R}^{3}$.
	
	
	
	
	\subsection{ Un esempio: il vincolo sferico}
	
	Consideriamo il caso di un vincolo sferico, ossia di un punto materiale obbligato a muoversi su di una superficie sferica descritta dall'equazione $x^{2}+y^{2}+z^{2} = 1$ (invariante nel tempo). Conviene costruirsi delle coordinate lagrangiane che si adattino il meglio possibile alla forma del vincolo: la scelta, in questo caso, ricade chiaramente sulle coordinate sferiche:
	\begin{equation}
		\begin{cases}
			x = r \cos(\phi)\sin(\theta) \\
			y = r \sin(\phi)\sin(\theta) \\
			z = r \cos(\theta)
		\end{cases}
	\end{equation}
	Le coordinate sferiche si adattano bene a questo vincolo perché possiamo tradurre la relazione di vincolo nella più semplice:
	$$
	r = R
	$$
	rendendo i calcoli un po' più semplici. Quello che faremo, dunque, sarà considerare la varietà bidimensionale in cui vivono le due coordinate lagrangiane $(\phi,\theta)$ (che non è euclidea) e proprio in questo spazio definiremo una fisica attraverso Lagrange senza bisogno di immergersi nello spazio tridimensionale (in questo esempio, infatti, la dimensionalità del problema è chiaramente $2$, perciò una delle tre coordinate cartesiane è sempre in qualche modo ridondante). Nello spazio delle configurazioni $\mathcal{M} = S^{2}(0,R)$ (descritto dalle coordinate locali $\theta,\phi$) la metrica associata risulta :
	\begin{equation}
		G = 
		\begin{pmatrix}
			R^{2} & 0 \\
			0 & R^{2}\sin^{2}\theta
		\end{pmatrix}
	\end{equation}
	E la matrice metrica ci permette di fare il prodoto scalare (o la norma) di due vettori $(\dot{\theta},\dot{\phi})$ appartenenti allo spazio tangente alla sfera senza necessariamente immergere tali vettori nello spazio euclideo. Così, l'energia cinetica assume la forma:
	\begin{equation}
		T = \dfrac{m}{2}(\dot{\theta},\dot{\varphi})
		\begin{pmatrix}
			R^{2} & 0 \\
			0 & R^{2}\sin^{2}\theta
		\end{pmatrix}
		\begin{pmatrix}
			\dot{\theta}\\
			\dot{\varphi}
		\end{pmatrix}
		= \dfrac{m}{2}R^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}\theta)
	\end{equation}
	Se la forza peso è l'unica forza, allora 
	$$
	V(\theta,\varphi) = mgR\cos\theta
	$$
	e infine:
	$$
	\Lambda = \dfrac{m}{2}R^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}(\theta)) - mgR\cos\theta
	$$
	Da cui posso ricavare le equazioni del moto per $\theta(t)$ e $\varphi(t)$ applicando l'operatore di Lagrange in $\theta, \varphi$ (o osservando che $p_{\varphi}$ è ciclica). 
	\subsection{Calcolo esplicito della reazione vincolare}
	E se volessi calcolarmi esplicitamente la reazione vincolare? Con l'approccio newtoniano questo era parte del lavoro necessario per individuare le equazioni del moto ed anzi ne costitutiva, se vogliamo, un effetto collaterale. La meccanica lagrangiana invece si concentra principalmente sulle orbite e ignora la forma della reazione vincolare. Ma se volessimo calcolarla? 
	
	Poiché la forza vincolare ha lavoro virtuale nullo (principio del lavoro virtuale), allora necessariamente la reazione vincolare è perpendicolare alla varietà istante per istante e punto per punto:
	$$
	\vec{R} \cdot \delta \vec{x} \iff \vec{R} \in \mathcal{N}_{\mathcal{M}}(t)
	$$
	intendendo con $\mathcal{N}_{\mathcal{M}}(t)$ lo spazio normale alla varietà all'istante $t$. Tale spazio è necessariamente determinato dal vettore $\vec{n} = \dfrac{\partial \vec{x}}{\partial q_n}$, e dunque
	$$
	\vec{R} \parallel \dfrac{\partial \vec{x}}{\partial q_n}
	$$
	Allora, riprendendo l'equazione di Newton completa di reazione vincolare:
	$$
	m\vec{a} = \vec{F} + \vec{R}
	$$
	e proiettando sullo spazio normale, parallelo al vincolo, avremo che $\vec{R}\cdot\vec{n} = R|n|$ e\footnote{Il vettore $\partial\vec{x}/\partial q_n$ non è un versore, è solo una base dello spazio tangente istantaneo, niente garantisce sia anche di norma unitaria} l'equazione diventa:
	$$
	m\vec{a}\cdot\hat{n} = \vec{F}\cdot\vec{n} + R
	$$
	cioè:
	$$
	R |n| = (m\vec{a}\cdot\dfrac{\partial \vec{x}}{\partial q_n} - \vec{F}\cdot \dfrac{\partial \vec{x}}{\partial q_n})
	$$
	Per quanto visto in precedenza, il membro a destra è l'equazione di Newton in cui compaiono solo le forze attive in forma covariante espressa per la coordinate $n$-esima, perciò:
	\begin{equation}
		R =\dfrac{1}{|\vec{n}|} Lag_{q_n}(\Lambda)
		\label{EqNorm}
	\end{equation}
	In questo caso, il termine $Lag_{q_n}(\Lambda)$ non è necessariamente pari a 0, poiché tale equazione fa riferimento ad una situazione in cui non esiste la forza vincolare, e quindi rappresenta un problema fisico diverso da quello che vogliamo studiare noi (rappresenta cioè un problema non vincolato in cui sia presente solo la forza $\vec{F}$). La Lagrangiana $\Lambda$ in (\ref{EqNorm}) deve essere costruita lasciando $q_n$ libero, come se $\vec{R}$ fosse temporaneamente assente, tenendo conto solo della presenza di $\vec{F}$. Solo in un secondo momento andremo ad imporre che $q_n = const = q_0$. In altre parole, abbiamo l'equazione:
	\begin{equation}
		N = \dfrac{1}{|\vec{n}|}Lag_{q_n}(\Lambda_{libera})|_{q_n=q_0} =  \dfrac{1}{|\vec{n}|}\Bigl(\dfrac{d}{dt}\dfrac{\partial \Lambda_{lib}}{\partial \dot{q_n}} - \dfrac{\partial \Lambda_{lib}}{\partial q_n}\Bigl)\Bigl|_{q_n = q_0}
		\label{ReazioneVincolare}
	\end{equation}
	
	
	Abbiamo scoperto una certa analogia: se applico l'operatore di Lagrange nella variabile $q_n$ sulla lagrangiana in un problema in cui la variabile $q_n$ è vincolata, ottengo esattamente l'espressione del vincolo su quella variabile. Applicando l'operatore di Lagrange sulle altre coordinate libere, ottengo le equazioni del moto
	\subsubsection{Applicazione al moto su sfera}
	Torniamo all'esempio precedente, quello del punto materiale che si muove sulla sfera di raggio costante.
	La lagrangiana non vincolata, dove è presente solo la forza peso, sarà evidentemente:
	$$
	\Lambda =\dfrac{m}{2}\dot{r}^2+ \dfrac{m}{2}r^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}(\theta)) - mgr\cos(\theta)
	$$
	Quindi\footnote{Visto che $\vec{n} = \partial\vec{x}/\partial r $ ha norma unitaria}:
	$$
	N =\dfrac{d}{dt}\dfrac{\partial \Lambda}{\partial \dot{r}} - \dfrac{\partial \Lambda}{\partial r}\Bigl|_{r=R}
	$$
	e cioè, in questo specifico caso:
	$$
	N = m\ddot{r}  -mr\dot{\theta}^{2}-mr\dot{\varphi}^{2}\sin^{2}(\theta) + mg\cos(\theta)
	$$
	Imponendo ora $r=R$ (e quindi $\ddot{r}=0$), avrò che
	$$
	N =  -mR\dot{\theta}^{2}-mR\dot{\varphi}^{2}\sin^{2}(\theta) + mg\cos(\theta)
	$$
	che è l'espressione in coordinate lagrangiane della forza vincolare. Notiamo che possiamo riscrivere i primi due addendi dell'espressione di $N$ come:
	$$ -m(R\dot{\theta}^{2}+R\dot{\varphi}^{2}\sin^{2}(\theta))  = -\dfrac{m}{R}(\dot{\theta}^{2}+ \dot{\varphi}^{2}\sin^{2}(\theta)) = -\dfrac{m}{R}v^{2}
	$$
	che corrisponde, in meccanica newtoniana, all'accelerazione centripeta. Dall'espressione precedente di $N$ leggiamo dunque che la forza vincolare deve resistere la componente radiale della forza peso (il termine $mgr\cos(\theta)$) e fornire l'accelerazione centripeta (termine appena calcolato) perché il punto materiale effettui traiettorie curve (a curvatura costante) sulla sfera. Tutto torna, effettivamente.
	
	\subsubsection{Punto di rilascio}
	Potremmo provare a risolvere un problema leggermente diverso. Un punto materiale è vincolato su di una sfera ma, ora, vi è solamente appoggiato sopra. Vogliamo calcolare l'angolo (dalla verticale) oltre il quale il punto si stacca dalla superficie sferica e cade verso il basso. In questa situazione, il vincolo è tale da impedire solo i movimento radiali diretti verso l'interno, dunque la forza vincolare può esercitare solo forze esterne (negative). Abbiamo già calcolato che la reazione vincolare $N$ è pari a:
	$$
	N = - \dfrac{mv^{2}}{R} + mg\cos(\theta)
	$$
	Il modulo della velocità lo possiamo ricavare dalla conservazione dell'energia (valida in virtù dell'idealità del vincolo stesso), per cui possiamo scrivere:
	$$
	E = T + V = \dfrac{1}{2}mv^{2}+mgR\cos(\theta)
	$$
	In totale, otteniamo che:
	$$
	N = -\dfrac{2(E-mgR\cos(\theta))}{R} + mg\cos(\theta)
	$$
	Se nel punto sommitale l'energia è solamento gravitazionale (cioè il punto parte da fermo), allora $E = mgR$ e avremo che:
	$$
	N =-2mg +2mg\cos(\theta) + mg\cos(\theta) = -2mg + 3mg\cos(\theta) 
	$$
	Per quanto abbiamo detto, tale problema ammette solo forze vincolari negative \footnote{Il segno è chiaramente convenzionale. Qua serve negativo perché il segno dell'accelerazione centripeta è negativo}, e quindi:
	$$
	\cos(\theta) < \dfrac{2}{3}
	$$
	Tali valori di $\theta$ sono dunque quelli per cui il punto materiale si mantiene attaccato alla guida sferica.
	\subsection{Vincolo dipendente dal tempo}
	Affrontiamo una variante del problema appena esposto in cui il vincolo è pulsante, cioè variabile nel tempo. In altre parole, la condizione vincolante diventa:
	\begin{equation}
		x^{2}+y^{2}+z^{2} = R^{2}(t)
	\end{equation}
	o, equivalentemente,
	$$
	r(t) = R(t)
	$$
	Lo spostamento virtuale rimane:
	$$
	\delta \vec{x} = \dfrac{\partial \vec{x}}{\partial \theta} d\theta + \dfrac{\partial \vec{x}}{\partial \varphi} d\varphi
	$$
	ed è solo rispetto a questo che la forza vincolare non compie lavoro. Lo spostamento reale invece tiene conto anche della variazione nel tempo, dunque:
	$$
	d\vec{x} = \dfrac{\partial \vec{x}}{\partial \theta} d\theta + \dfrac{\partial \vec{x}}{\partial \varphi} d\varphi + \dfrac{\partial \vec{x}}{\partial r}dr = \dfrac{\partial \vec{x}}{\partial \theta} d\theta + \dfrac{\partial \vec{x}}{\partial \varphi} d\varphi + \dfrac{\partial \vec{x}}{\partial r}\dot{r}dt
	$$
	Questa espressione è quella corretta da utilizzare per valutare la velocità assoluta del punto materiale sulla sfera pulsante. I primi due addendi costituiscono la velocità tangenziale sulla sfera come se fosse congelata mentre il terzo addendo esprime la velocità radiale dovuta alla dilatazione/contrazione della superficie sferica stessa. Attenzione ad un particolare: la derivata parziale in $r$ va chiaramente calcolata in $r=r(t)$.  
	
	Riprendendo le coordinate sferiche, per cui:
	$$
	\vec{x} = (r\cos(\varphi)\sin(\theta), r\sin(\varphi)\sin(\theta), rcos(\theta))
	$$
	Ricavo che la velocità risulta essere:
	\begin{equation}
		\begin{cases}
			\dot{x} = \dot{R}\sin(\theta)\cos(\varphi)+R\dot{\theta}\cos(\theta)\cos(\varphi) - R\dot{\varphi}\sin(\theta)\sin(\varphi) \\
			\dot{y} = \dot{R}\sin(\theta)\sin(\varphi)+R\dot{\theta}\cos(\theta)\sin(\varphi) - R\dot{\varphi}\sin(\theta)\sin(\varphi) \\
			\dot{z} = \dot{R}\cos(\theta) - \dot{\theta}R\sin(\theta)
		\end{cases}
	\end{equation}
	E facendo i calcoli ($T= \dfrac{1}{2}(\dot{x}^{2}+\dot{y}^{2}+\dot{z}^{2})$, $V = mgz$), otteniamo la lagrangiana del sistema pulsante:
	\begin{equation}
		\Lambda = \dfrac{m}{2}\dot{R}^{2} + \dfrac{m}{2}R^{2}(t)(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}(\theta)) - mgR(t)\cos(\theta)
		\label{Sferapulsante}
	\end{equation}
	L'espressione della lagrangiana appena ricavata è molto interessante. Il primo termine è una pura derivata temporale e, per quanto già detto sulle invarianze di gauge, può essere omesso senza alterare la fisica del problema che stiamo descrivendo. Tolto quel pezzo, la lagrangiana che segue è la stessa di quella ricavata nel caso stazionario in cui al posto di $R = const$ abbiamo una generica $R(t)$. In questo caso, per ricavare la soluzione del caso pulsante è sembrato sufficiente riadattare la lagrangiana già scritta in precedenza aggiungendo la dipendenza temporale del raggio dal tempo. Tuttavia questa regola non è generale e il fatto che qui funzioni è accidentale: in genere l'aggiunta di un vincolo temporale altera la struttura della lagrangiana stessa in maniera più profonda.
	
	Se volessi trovare degli integrali primi del moto, potrei notare che $\varphi$ è una coordinate ciclica per cui il suo momento coniugato è un integrale primo:
	$$
	p_{\varphi} = \dfrac{\partial \Lambda}{\partial \dot{\phi}} = mR^{2}(t)
	$$
	A dirla tutta, nonostante questa quantità rispetti la proprietà:
	$$
	\dfrac{d}{dt}p_{\varphi} = 0
	$$
	non possiamo utilizzarlo come tale poiché dipende esplicitamente dal tempo. Notiamo che neppure l'energia definita al solito:
	$$
	H = T + V
	$$
	è un integrale primo del moto poiché la lagrangiana dipende esplicitamente dal tempo. Possiamo però valutare il lavoro svolto dalla reazione vincolare, sapendo che:
	$$
	\dfrac{\partial \Lambda}{\partial t} = -\dfrac{dH}{dt}
	$$
	e chiaramente la sola forza che può modificare l'energia del sistema è quella non conservativa, cioè la reazione vincolare, dunque la sua potenza è proprio:
	$$
	P_{vinc} = -\dfrac{\partial \Lambda}{\partial t} 
	$$
	
	\subsection{Vincolo paraboloide}
	Consideriamo un punto materiale che sia vincolato a muoversi su di un paraboloide descritto dall'equazione:
	\begin{equation}
		\begin{cases}
			x = r\cos(\theta) \\
			y = r\sin(\theta)\\
			z = -\dfrac{r^{2}}{2}a
		\end{cases}
	\end{equation}
	soggetto al potenziale gravitazionale e ad un potenziale elastico del tipo $V = \dfrac{kr^{2}}{2}$. A livello geometrico, $r$ corrisponde alla distanza dall'asse $z$ (dunque è come se il punto materiale fosse legato all'asse verticale da una molla). Vogliamo trovare la lagrangiana di tale sistema. Ho già le coordinate adattate per descrivere la dinamica del punto materiale che si muovo lungo il paraboloide, perfettamente identiche al set di equazioni che definisce la varietà stessa\footnote{In realtà avremmo preferito avere coordinate per cui esista una relazione del tipo $q_n = const$. In questo caso non è strettamente necessario, almeno finché vogliamo solo calcolare le equazioni del moto. La Lagrangiana va costruita direttamente sulla varietà (paraboloide). Avessimo voluto calcolare esplicitamente la reazione vincolare, allora convenica cercare una forma $q_n = const$}. Calcolo allora l'energia cinetica passando per la metrica:
	\begin{equation}
		G =
		\begin{pmatrix}
			1+a^{2}r^{2} & 0 \\
			0 & r^{2}
		\end{pmatrix}
	\end{equation}
	e dunque:
	\begin{equation}
		\Lambda = \dfrac{m\dot{r}^{2}}{2}(1+a^{2}r^{2}) + \dfrac{m\dot{\theta}^{2}}{2}r^{2} + mgr^{2}\dfrac{a}{2} -  \dfrac{k}{2}r^{2}
	\end{equation}
	La coordinata $\theta$ è ciclica, dunque un integrale primo del moto sarà:
	$$
	p_{\theta} = \dfrac{\partial \Lambda}{\partial \dot{\theta}} = mr^{2}\dot{\theta}
	$$
	da cui posso agevolmente ricavare:
	$$
	\dot{\theta} = \dfrac{p_{\theta}}{mr^{2}}
	$$
	L'altro integrale primo del moto è l'energia, cioè:
	$$
	E =  \dfrac{m\dot{r}^{2}}{2}(1+a^{2}r^{2}) + \dfrac{m\dot{\theta}^{2}}{2}r^{2} - mgr^{2}\dfrac{a}{2} +  \dfrac{k}{2}r^{2}
	$$
	e sostituendo il valore di $\dot{\theta}$ appena ricavato avremo che:
	$$
	E = \dfrac{m\dot{r}^{2}}{2}(1+a^{2}r^{2})- mgr^{2}\dfrac{a}{2} +  \dfrac{k}{2}r^{2} + \dfrac{p_{\theta}^{2}}{2mr^{2}} = \dfrac{m\dot{r}^{2}}{2}(1+a^{2}r^{2})+ \dfrac{1}{2}r^{2}( k-mga) + \dfrac{p_{\theta}^{2}}{2mr^{2}}
	$$
	Ci siamo ricondotti ad una forma unidimensionale per il problema del paraboloide con un potenziale efficace formato da un termine quadratico (elastico) ed un termine centrifugo (ricorda dunque molto il problema già svolto nella sezione delle analogie)\footnote{Il termine cinetico contiene anche un fattore $r^2$. Questo non è problematico: l'energia cinetica può dipendere dalla coordinate tramite la metrica. Esisterà un'altra coordinata unidimensionale per cui l'espressione della energia cinetica è una pura forma quadratica delle solo velocità generalizzate, ma in questo caso non è necessario operare tale cambio di coordinata}.
	
	Ci chiediamo ora se possano esistere orbite circolari per questo problema. Notiamo subito che il potenziale efficace individuato ha un termine elastico che può variare segno a seconda del valore di $k-mga$. In particolare, se $k> mga$, il potenziale ha coefficiente positivo e mi aspetto un'orbita circolare (a $r$ costante) proprio come nel problema di Keplero. Se, tuttavia, $k<mga$, il grafico del potenziale efficace ha questo andamento:
	%GRAFICO
	E necessariamento non avremo valori minimi che generino le orbite circolari. Imponiamo dunque $k>mga$ e calcoliamo il valore di tale raggio risolvendo:
	$$
	\dfrac{dV_{eff}}{dr} = 0
	$$
	ottenendo infine:
	$$
	r^{4}_{c} = \dfrac{p_{\theta}^{2}}{m(k-mga)}
	$$
	\newpage
	\section{Potenziali generalizzati}
	Abbiamo definito la funzione Lagrangiana come:
	\begin{equation}
		\Lambda(q,\dot{q}) = T(q,\dot{q}) - V(q)
	\end{equation}
	e, perché le equazioni di Eulero-Lagrange funzionassero, abbiamo sempre richiesto che il potenziale fosse unicamente funzione delle coordinate e non delle velocità generalizzate. Così facendo, infatti, si ottiene che:
	$$
	Lag_{q_i}(V) = \Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_i}-\dfrac{\partial}{\partial q_i}\Bigl) V = -\dfrac{\partial V}{\partial q_i}
	$$
	E allora davvero è verificata la relazione:
	$$
	Lag_{q_i}(T-V) = 0
	$$
	Tuttavia è possibile mostrare che il potenziale può anche dipendere dalle velocità generalizzate a patto che tale dipendenza segua determinate condizioni. Infatti, scrivendo $V = V(q,\dot{q})$, possiamo calcolarci la forza che tale potenziale detto \textit{generalizzato} esprime operando con l'operatore di Lagrange\footnote{Attenzione! Se $V$ è generalizzato, la forza che genera non è banalmente il suo gradiente. Perché l'equazione di Eulero-Lagrange continui a valere, la forza generalizzata dovrà essere calcolata come $Lag(V(q,\dot{q})) \neq \vec{\nabla}V$}:
	\begin{equation}
		\begin{split}
			F_i &= Lag_{q_i}(V(q,\dot{q})) = \dfrac{d}{dt}\dfrac{\partial V}{\partial \dot{q}_i} - \dfrac{\partial V}{\partial q_i} = \\
			&= \dfrac{\partial^2 V}{\partial q_k \partial \dot{q}_i}\dot{q}_k + \dfrac{\partial^2 V}{\partial \dot{q}_k \partial \dot{q}_i}\ddot{q}_k - \dfrac{\partial V}{\partial q_i}
		\end{split}
	\end{equation}
	Nell'ultima riga osserviamo che compare un termine proporzionale a $\ddot{q}_k$, cioè proporzionale all'accelerazione del punto. Questo però è in contraddizione con i Principi della Meccanica, poiché la forza non può dipendere dall'accelerazione, essendo questa determinata dalla forza stessa. Necessariamente, dunque, il termine quadratico deve essere nullo
	$$
	\dfrac{\partial^2 V}{\partial \dot{q}_k \partial \dot{q}_i} = 0
	$$
	e cioè l'hessiana del potenziale (fatta rispetto alle velocità generalizzate) è identicamente nulla, dunque il potenziale può essere lineare nelle $\dot{q}$:
	\begin{equation}
		V(\dot{q}) = \dot{q}_{i}A^{i}(q)
		\label{PotGen}
	\end{equation}
	Abbiamo ottenuto un risultato di importanza fondamentale. Perché un potenziale possa essere fisico, o dipende esclusivamente dalle coordinate ($V=V(q)$) oppure è ammissibile che esso dipenda anche dalle coordinate generalizzate in forma lineare, come prescritto dalla (\ref{PotGen}). Questi tipi di potenziale vengono appunto detti \textit{generalizzati}.
	
	Notiamo in ultimo che il vettore $\vec{A}$ (funzione delle sole coordinate) descritto nella (\ref{PotGen}) è un vettore costruito di modo da essere covariante, essendo le velocità generalizzate controvarianti. In questo modo, ho ottenuto una quantità scalare (richiesta anch'essa di fondamentale importanza per un potenziale fisico)
	\subsection{Forza generata da potenziali generalizzati}
	Come è fatta a livello analitico la forza generata da un potenziale generalizzato? Per potenziali classici, valeva che:
	$$
	F_i = - \dfrac{\partial V}{\partial q_i} \iff \vec{F} = -\vec{\nabla} V
	$$
	Se il potenziale è generalizzato della forma di Eq.(\ref{PotGen}), allora in generale vale che:
	\begin{equation}
		\begin{split}
			F_j &= Lag_{q_j}(V) = \Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_j}-\dfrac{\partial}{\partial q_j}\Bigl) (\dot{q}_i A^{i}(q)) = \\
			&= \dfrac{d}{dt}A^j (q) - \dfrac{\partial A^i}{\partial q_j}\dot{q}_i = \dfrac{\partial A^j}{\partial t} + \dfrac{\partial A^j}{\partial q_i}\dot{q}_i - \dfrac{\partial A^i}{\partial q_j}\dot{q}_i = \\
			&= \dot{q}_i \Bigl(\dfrac{\partial A^j}{\partial q_i} -\dfrac{\partial A^i}{\partial q_j}\Bigl)
		\end{split}
		\label{ForzaGen}
	\end{equation}
	Avendo supposto nulla la derivata parziale delle componenti covarianti di $\vec{A}$ rispetto al tempo. 
	
	Se il problema da affrontare è unidimensionale, allora necessariamente $F_j = 0$ e, di conseguenza, non posso avere potenziali generalizzati in sistemi a una dimensione. D'altronde, se la dimensione è pari a $1$, allora è facile verificare che:
	$$
	V = \dot{q}A(q) = \dfrac{d}{dt}F(q)
	$$
	dove $F(q)$ è la primitiva di $A(q)$ rispetto a $q$ che, almeno in una dimensione, esiste indubbiamente a causa del teorema fondamentale del calcolo integrale. Poiché il potenziale generalizzato unidimensionale è semplicemente una derivata temporale nel tempo, allora questo termine può essere omesso tranquillamente per invarianza di gauge. I potenziali generalizzati possono avere senso solo in $n>2$.
	
	Notiamo, infine, che il vettore $\vec{A}$ non è univocamente definito. Infatti, posso sommare a questo il gradiente di un qualsiasi campo scalare e la Lagrangiana del sistema rimarrebbe inalterata. Se infatti pongo un nuovo vettore $\vec{A}$ tale da essere $\vec{A}' = \vec{A}+\vec{\nabla}F$, allora
	$$
	A'_j = A_j + \dfrac{\partial F}{\partial q_j}
	$$
	e
	$$
	V' = \dot{q}_j A'_j = \dot{q}_j A_j  + \dot{q}_j\dfrac{\partial F}{\partial q_j} = V + \dfrac{dF}{dt}(q)
	$$
	e quindi, ai fini della Lagrangiana, $V'$ è assolutamente equivalente a $V$.
	\subsection{Potenziali generalizzati in coordinate cartesiane}
	Mettiamoci momentaneamente in coordinate cartesiane (in cui covariante e controvariante coincidono come concetti poiché la base è ortonormale ovunque). Allora un generico potenziale generalizzato ha la forma:
	$$
	V(x,\dot{x}) = \dot{x}_j A_j(x)
	$$
	e, per quanto ricavato in (\ref{ForzaGen}), la forza corrispondente a tale potenziale generalizzato è:
	$$
	F_j = \dot{x}_i \Bigl(\dfrac{\partial A^j}{\partial x_i} -\dfrac{\partial A^i}{\partial x_j}\Bigl)
	$$
	Questa forma ricorda molto la definizione di rotore. Se infatti considero la seguente espressione:
	$$
	\vec{v} \times (\vec{\nabla}\times \vec{A})
	$$
	Allora effettivamente noto che
	$$
	(\vec{v} \times (\vec{\nabla}\times \vec{A}))_j = \dot{x}_i \Bigl(\dfrac{\partial A^j}{\partial x_i} -\dfrac{\partial A^i}{\partial x_j}\Bigl) 
	$$
	Dimostriamolo. Ricordiamo la definizione di prodotto scalare con il tensore di Ricci:
	$$
	\vec{a}\times \vec{b} = \varepsilon_{ijk}a_jb_k
	$$
	quindi
	$$
	(\vec{v} \times (\vec{\nabla}\times \vec{A}))_i = \varepsilon_{ijk}v_j(\vec{\nabla}\times \vec{A})_k = \varepsilon_{ijk}v_i \varepsilon_{klm}\dfrac{\partial A^{m}}{\partial x_l}= \varepsilon_{ijk}\varepsilon_{klm}v_j \dfrac{\partial A^{m}}{\partial x_l}
	$$
	Dal corso di fluidi, ricordiamo l'identità:
	$$
	\varepsilon_{ijk}\varepsilon_{klm} = \delta_{il}\delta_{jm}-\delta_{im}\delta_{jl}
	$$
	e quindi
	$$
		(\vec{v} \times (\vec{\nabla}\times \vec{A}))_i =( \delta_{il}\delta_{jm}-\delta_{im}\delta_{jl})v_j \dfrac{\partial A^{m}}{\partial x_l}
	$$	
	$$
	(\vec{v} \times (\vec{\nabla}\times \vec{A}))_i =v_j\Bigl( \dfrac{\partial A^{j}}{\partial x_i}- \dfrac{\partial A^{i}}{\partial x_j}\Bigl)
	$$	
	volendo l'indice $j$ (ho fatto la formula iniziale con l'indice $i$ perché mi piaceva di più il tensore di Ricci scritto $\varepsilon_{ijk}$):
$$
(\vec{v} \times (\vec{\nabla}\times \vec{A}))_j = \dot{x}_i \Bigl(\dfrac{\partial A^j}{\partial x_i} -\dfrac{\partial A^i}{\partial x_j}\Bigl) 
$$
	In altre parole, in coordinate cartesiane la forza generata da un potenziale generalizzato può essere espressa come:
	\begin{equation}
		\vec{F} = \vec{v} \times (\vec{\nabla}\times \vec{A})
	\end{equation}
	Questa equazione ricorda molto la forza di Lorentz. Infatti, battezzando $\vec{B} = \vec{\nabla}\times \vec{A}$, allora scopriamo che la forza magnetica è proprio generata da un potenziale generalizzato del tipo:
	\begin{equation}
		\vec{F} = \dfrac{q}{c}\vec{v}\times\vec{B}
	\end{equation}
	E il suo potenziale caratteristico è:
	\begin{equation}
		V_m = \dfrac{q}{c}\vec{A}\cdot\vec{v}
	\end{equation}
	con $\vec{B} = \vec{\nabla}\times\vec{A}$. In effetti, l'operatore rotore $\vec{\nabla}\times$ è trasparente per l'aggiunta di un gradiente di un campo scalare, esattamente come avevamo ricavato in precedenza.
	
	Riassumendo, in fisica esistono dei particolari potenziali, detti generalizzati, che dipendono linearmente dalle velocità generalizzate e che in coordinate cartesiane possono essere espressi mediante rotori di campi vettoriali $\vec{A}$. La forza di Lorentz è un esempio caratteristico di questi tipi di potenziali generalizzati.
	\subsection{Terza equazione di Maxwell e lavoro delle forze generalizzate}
	Sapendo che:
	$$
	F_j = \dot{x}_i \Bigl(\dfrac{\partial A^j}{\partial x_i} -\dfrac{\partial A^i}{\partial x_j}\Bigl)
	$$
	calcoliamo il lavoro svolto dai potenziali generalizzati passando per la loro potenza erogata (in coordinate cartesiane):
	$$
	P = \vec{F}\cdot\vec{v} = \dot{x}_i\dot{x}_j \Bigl(\dfrac{\partial A^j}{\partial x_i} -\dfrac{\partial A^i}{\partial x_j}\Bigl)
	$$
	Questa sommatoria dà come risultato totale zero, poiché per ogni coppia di indice $(i,j)$, la relativa anticoppia $(j,i)$ è di segno opposto e, dunque, la annulla nella somma. 
	
	Concludiamo allora che le forze derivanti da potenziali generalizzati non possono fare lavoro. Questo è vero finché vale la condizione assunta in precedenza per cui:
	$$
	\dfrac{\partial A^j}{\partial t} = 0
	$$
	Se così non fosse, allora la forza generalizzata potrebbe fare lavoro con potenza:
	\begin{equation}
		P = \dfrac{\partial A_j}{\partial t}\dot{x}_j
		\label{PotenzaGen}
	\end{equation}
	Questa situazione è in perfetto accordo con le leggi dell'elettromagnetismo di Maxwell. Se, infatti, $\vec{B}$ è statico, allora è vero che la forza di Lorentz non fa lavoro, come appena dimostrato. Se invece $\vec{B}$ dipende dal tempo, allora anche $\vec{A}$ dipende dal tempo e il campo magnetico comincia a fare lavoro. In realtà, in elettromagnetismo è spesso affermato che il campo magnetico non fa mai lavoro. Questo perché quando un campo magnetico varia nel tempo, induce un campo elettrico responsabile del lavoro svolto. Se diamo per buona questa assunzione, allora il campo elettrico che viene creato dalla variazione del campo $\vec{B}$ dovrà avere la forma:
	\begin{equation}
		\vec{E} = -\dfrac{\partial \vec{A}}{\partial t}
		\label{eq7}
	\end{equation}
	Infatti così facendo il campo elettrico ipotizzato erogherebbe una potenza:
	$$
	P_e = -\dfrac{\partial A_j}{\partial t}\dot{x}_j
	$$
	che, a meno di costanti moltiplicative, è proprio quanto ricavato in (\ref{PotenzaGen}). Applicando l'operatore di rotore ad entrambi i membri della (\ref{eq7}), otteniamo:
	$$
	\vec{\nabla}\times \vec{E} = - \dfrac{\vec{\nabla}\times\vec{A}}{\partial t}
	$$
	Ma sappiamo che $\vec{\nabla}\times\vec{A} = \vec{B}$, perciò:
	\begin{equation}
		\vec{\nabla}\times \vec{E} = - \dfrac{\partial \vec{B}}{\partial t}
		\label{Maxwell3}
	\end{equation}
	che è esattamente la terza equazione di Maxwell, ricavata da considerazioni di provenienza analitica. Il fatto che valga tale relazione in elettromagnetismo è dunque conseguenza della natura di potenziale generalizzato del campo magnetico (e della nostra convenzione di considerare $\vec{B}$ come campo a lavoro sempre nullo).
	
	\subsection{Energia con potenziali generalizzati}
	La forma pià generale della lagrangiana di un sistema fisico è dunque:
	\begin{equation}
		\Lambda(q,\dot{q}) = T(q,\dot{q}) - V(q) + kA^{i}(q)\dot{q}_i
	\end{equation}
	dove l'ultimo termine rappresenta il possibile potenziale generalizzato. Come cambia l'espressione dell'energia $H$? Calcoliamola esplicitiamente attraverso la relazione:
	\begin{equation}
		H = \dfrac{\partial \Lambda}{\partial \dot{q}_i}\dot{q}_i - \Lambda = \dfrac{\partial \Lambda}{\partial \vec{v}}\cdot \vec{v} - \Lambda
	\end{equation}
	e, poiché $V_gen = k\vec{A}\cdot\vec{v}$ in coordinate cartesiane, allora il contributo del potenziale generalizzato è nullo e rimane vera la formula:
	$$
	H = T + V
	$$
	Anche se avessi $A = A(t)$, otterrei un contributo nullo però l'energia del sistema, somma della componente cinetica e potenziale classica, non sarebbe più conservata (nonostante $H$ non dipenda da $t$, quello che conta è $\Lambda$, che dipende esplicitamente da $t$). 
	In generale, dunque, il potenziale generalizzato non rientra nel computo dell'energia del sistema (a riprova del fatto che, se costante nel tempo, non compie lavoro). L'energia si conserva se $A$ non dipende dal tempo.
	\newpage
	\section{Relatività galileiana}
	Lo studio dei fenomeni meccanici richiede che sia scelto un sistema di riferimento. Le leggi del moto in sistemi di riferimento diversi possono avere forma diverse. I Principi di Newton assicurano l'esistenza di tutta una serie di sistemi di riferimento, detti \textit{inerziali}, in cui le leggi della meccanica sono particolarmente semplici e assumono, ad esempio, la celebre forma $\vec{F} = m\vec{a}$. Poichè l'uso del formalismo lagrangiano è strettamente legato alla validità del secondo principio di Newton, allora possiamo utilizzare il metodo fin qui esposto (trovare la lagrangiana, risolvere le equazioni di Eulero-Lagrange) solo se le coordinate generalizzate impiegate si riferiscono ad un sistema inerziale.
	\subsection{Lagrangiana e trasformazioni di Galileo}
	Cosa succede alla funzione lagrangiana se passo da un sistema inerziale $S$ ad un sistema, sempre inerziale, $S'$ in moto rispetto al primo di velocità $\vec{V}$? La lagrangiana che scriverebbe un ipotetico osservatore solidale a $S'$ è uguale a quella scritta in $S$ nella parte potenziale\footnote{I potenziali dipendono dalle coordinate, che però variano in seguito a trasformazioni di Galileo, perciò anche il termine potenziale potrebbe variare. Questo però non capita perché tutti i potenziali fisici dipendono da differenza di coordinate, da spostamenti e non da posizioni, che sono invarianti per Galileo.}, ma varierebbe in quella cinetica. In particolare,
	$$
	T' = \dfrac{1}{2}m\vec{v}'\cdot\vec{v}'= \dfrac{1}{2}m(\vec{v}+\vec{V}^2) = T + 2\vec{v}\cdot\vec{V}+V^{2}
	$$
	Dove $\vec{v}'$ è la velocità di un punto materiale registrata da $S'$ e $\vec{v}$ quella di $S$, legate dalle relazioni di Galileo. Notiamo, però, che:
	$$
	T' = T + \dfrac{d}{dt}(2\vec{x}\cdot\vec{V}+V^{2}t)
	$$
	e quindi la Lagrangiana scritta da un osservatore in $S'$ nelle sue coordinate è uguale alla Lagrangiana scritta da un osservatore in $S$, poiché differiscono solo per un termine di derivata temporale:
	$$
	\Lambda(\vec{x},\vec{v}) = \Lambda(\vec{x}',\vec{v}')
	$$
	Questo non vuol dire che le soluzioni del moto siano esattamente uguali, cioè $x(t) = x'(t)$, ma semplicemente che hanno la stessa forma e differiscono solo per le condizioni iniziali (diversi da $S$ a $S'$). Il fatto che però le due Lagrangiane siano uguali è di fondamentale importanza: anche per la meccaninca lagrangiana, i sistemi inerziali sono tutti equivalenti, in quanti condividono la medesima funzione $\Lambda$. Anche per questa riformulazione della meccaninca, le leggi fondamentali della fisica sono invarianti per sistemi inerziali, basta trovarne uno e scrivere la Lagrangiana in quel sistema e il gioco è fatto, non c'è sistema privilegiato.
	\subsection{Sistemi rotanti}
	Il formalismo Lagrangiano funziona se il sistema viene descritto in un sistema di riferimento inerziale. Così, ad esempio, un sistema di riferimento rotante non è inerziale e non è possibile descrivere direttamente la fisica di quel sistema con coordinate locali rotanti nella lagrangiana. C'è però un metodo alternativo che consente di lavorare direttamente nei sistemi non inerziali col prezzo di aggiungere forze fittizie di natura non fisica. Proprio come in meccanica newtoniana era possibile operare in sistemi non inerziali aggiungendo forze fittizie, vogliamo trovare un equivalente in meccanica lagrangiana.
	
	Costruiamo allora un sistema di riferimento inerziale fisso $S$ e un sistema di riferimento rotante $S'$ che condividano l'origine degli assi (cartesiani). Identifichiamo con $\vec{X}\in S$ la terna di coordinate con cui rappresentiamo la posizione nel sistema inerziale (il raggio vettore in $S$). In altre parole, se $\vec{e}_{1},\vec{e}_{2},\vec{e}_{3}$ sono una base di tale sistema fermo, allora:
	$$
	\vec{X} = (X_1,X_2,X_3) \iff \vec{r} = X_1
	\vec{e}_1 + X_2
	\vec{e}_2 +X_3 \vec{e}_3$$
	Identifichiamo invece con $\vec{x}\in S'$ il raggio vettore come lo scriverebbe un osservatore nel sistema rotante\footnote{Ovviamente l'osservatore non inerziale è ignaro di esserlo}. Se la base del sistema rotante è $\vec{e'}_{1},\vec{e'}_{2},\vec{e'}_{3}$ (dipendente dal tempo), allora avremo analogamente a sopra:
	$$
	\vec{x} = (x_1,x_2,x_3) \iff \vec{r} = x_1
	\vec{e'}_1 + x_2
	\vec{e'}_2 +x_3 \vec{e'}_3
	$$
	Allora, fra $\vec{X}$ e $\vec{x}$ sussiste la relazione:
	$$
	\vec{X} = R(t)\vec{x}
	$$
	dove $R(t)$ è una matrice di rotazione e, perciò, ortogonale. Calcolo ora la derivata temporale di $\vec{X}$, che coincide con la velocità assoluto del punto materiale scritta nelle coordinate fisse:
	$$
	\dot{\vec{X}} = \dot{R}(t)\vec{x} + R(t)\dot{\vec{x}}
	$$
	Se $\dot{R}(t) = 0$, cioè il sistema non sta ruotando nel tempo, ottengo che:
	$$
	\dot{\vec{X}} = R(t)\dot{\vec{x}}
	$$
	Che è ragionevole. Il termine a sinistra rappresenta la velocità assoluta di un punto materiale scritta nel sistema $S$. Il termine a destra rappresenta la velocità di un punto rispetto al sistema $S'$ vista però dalle coordinate si $S$. Queste due concidono, e tale relazione è la conferma della covarianza del vettore velocità per rotazioni degli assi cartesiani\footnote{Infatti si ha che $|\dot{\vec{X}}| = |R\dot{\vec{x}}| = |\dot{\vec{x}}|$, poiché $R$ ortogonale, cioè il modulo del vettore velocità assoluta è invariante per rotazioni del sistema di riferimento, è uno scalare. Le leggi delle fisici più fondamentale non dipendono dalle componenti della velocità (che sono controvarianti) ma devono dipendere dal modulo di questa, che davvero è uno scalare (ad esempio nell'energia cinetica che figura nella lagrangiana)}
	
	Se invece $R$ varia nel tempo, allora questo non è più vero. La velocità assoluta (quella riferita al sistema $S$ inerziale) non è semplicemente la velocità riferita al sistema non inerziale ($\dot{\vec{x}}$) ruotata (R$\dot{\vec{x}}$), ma devo aggiungere un altro pezzo, il termine $\dot{R}(t)\vec{x}$ (dovuto alla non inerzialità di $S'$). Riscriviamo la trasformazione:
	$$
	\dot{\vec{X}} = \dot{R}(t)\vec{x} + R(t)\dot{\vec{x}}
	$$
	$$
	\vec{V} = \dot{R}(t)\vec{x} + \vec{v}
	$$ 
	dove \begin{itemize}
		\item $\vec{V}\in S$ è il vettore di velocità assoluta, cioè la velocità misurata dal sistema inerziale (nella base inerziale)
		\item $\vec{v} = R\dot{\vec{x}} \in S$ è la velocità misurata dal sistema rotante scritta nella base inerziale (infatti $\dot{\vec{x}}$ è la velocità che vede $S'$ nelle sue coordinate, la ruoto applicando $R$ e ottengo $\vec{v}$). Questa è la velocità relativa
		\item  $\dot{R}(t)\vec{x} \in S$ è un termine aggiuntivo
	\end{itemize}
	Siccome vogliamo descrivere la dinamica di un sistema dinamico non inerziale usando le sue coordinate, riscriviamo la relazione di trasformazione delle velocità nella base del sistema rotante. Per farlo basta moltiplicare per l'inversa della matrice di rotazione entrambi i membri dell'uguaglianza. Poiché la matrice è ortogonale, l'inversa coincide con la trasposta, da cui:
	\begin{equation}
		R^{T}\dot{\vec{X}} = R^{T}\dot{R}\vec{x} + \dot{\vec{x}}
		\label{VelAss}
	\end{equation}
	E questa terna di numeri rappresenta la velocità assoluta scritta nella base rotante (cioè la velocità osservata da un sistema inerziale proiettata però nelle coordinate rotanti). Perché vogliamo questa scrittura? Perché l'obiettivo è quello di descrivere la fisica di un sistema rotante rimanendo nelle sue coordinate, nonostante non sia inerziale.
	\footnote{Notiamo che la velocità assoluta scritta nelle coordinate rotanti non è uguale a $\dot{\vec{x}}$, cioè la velocità osservata da $S'$. Questo sarebbe stato vero se il secondo sistema fosse fermo rispetto al primo e, al massimo, orientato diversamente.}
	
	Riprendiamo in mano l'equazione (\ref{VelAss}) e osserviamola meglio. Concentriamoci sul termine di composizione matriciale
	$$
	R^{T}\dot{R}
	$$
	Notiamo in primis che tale matrice è antisimmetrica. Infatti, derivando $R^{T}R = I$, otteniamo che:
	$$
	\dot{R}^{T}R + R^{T}\dot{R} = 0
	$$
	Ma $\dot{R}^{T}R = (R^{T}\dot{R})^{T}$ e quindi:
	$$
	(R^{T}\dot{R})^{T} = - R^{T}\dot{R} 
	$$
	La matrice $R^{T}\dot{R}$ è dunque antisimmetrica, poiché è uguale all'opposto della sua trasposta. Le matrici antisimmetriche $3\times3$ godono di una particolare proprietà, cioè sono isomorfe ai vettori di $\mathcal{R}^{3}$. Infatti una generica matrice antisimmetrica $\Omega \in M^{3\times3}$ deve avere forma:
	\begin{equation}
		\Omega = 
		\begin{pmatrix}
			0 & a & b \\
			-a & 0 & c \\
			-b & -c & 0 \\
		\end{pmatrix}
	\end{equation}
	e può essere messo in isomorfismo con il vettore $\vec{\omega} = (a,b,c)$. Voglio istituire l'isomorfismo di modo che applicare la matrice $\Omega$ su un generico vettore $\vec{x}$ equivale ad effettuare il prodotto vettoriale fra $\omega \mbox{ e } \vec{x}$:
	$$
	\Omega \vec{x} = \vec{\omega}\times\vec{x}
	$$
	È possibile farlo? La risposta è affermativa. Infatti, se $\vec{x} = \vec{\omega}$, allora $\vec{\omega}\times\vec{x} = 0$ e quindi $\Omega \vec{\omega} = 0$, cioè $\omega$ appartiene al kernel di $\Omega$. La matrice $\Omega$ ha allora questa forma:
	\begin{equation}
		\Omega = 
		\begin{pmatrix}
			0 & -\omega_z & \omega_y \\
			\omega_z & 0 & \omega_x \\
			-\omega_y & \omega_x & 0 \\
		\end{pmatrix}
	\end{equation}
	e così facendo, allora davvero:
	$$
	\Omega \vec{x} = R^{T}\dot{R}\vec{x} = \vec{\omega}\times\vec{x}
	$$
	Tornando all'espressione (\ref{VelAss}), possiamo allora affermare che deve esistere un vettore speciale chiamato $\vec{\omega}$ che appartiene allo spazio di $S'$ attraverso il quale scriveremo:
	\begin{equation}
		R^{T}\dot{\vec{X}} = \vec{\omega}\times\vec{x} + \dot{\vec{x}}
		\label{VelAss2}
	\end{equation}
	Dovremmo dimostrare che tale vettore $\vec{\omega}$ coincide con il vettore di velocità angolare che già conosciamo dagli studi pregressi, ma non lo faremo.
	
	A questo punto scriviamo la lagrangiana di un punto materiale come la vedrebbe un osservatore del sistema rotante. Ricordando che la velocità assoluta (quella con cui si costruisce la lagrangiana) va espressa nelle coordinate del sistema rotante\footnote{Le due cose non si contraddicono. La velocità assoluta è un vettore, un'entità geometrica indipendente dal sistema di riferimento con cui la si descrive: è un vettore a tutti gli effetti. Nel sistema rotante, si farebbe esperienza di una velocità vettoriale totalmente diversa non solo perché cambiano le coordinate, ma perché la velocità cambia da sistema di riferimento a sistema di riferimento. Una volta individuato in maniera precisa il vettore, questo può essere scritto in una base arbitraria, quella del sistema fisso o quella del sistema rotante. Così, ad esempio, $\vec{x}$ e $\vec{X}$ non sono propriamente vettori, ma solo terne di numeri che rappresentano il medesimo vettore, lo spostamento $\vec{r}$, secondo due basi differenti.}, facciamo appello all'equazione (\ref{VelAss2}) e otteniamo un'energia cinetica:
	\begin{equation}
		T = (R^{T}\dot{\vec{X}})^2 = \dfrac{1}{2}m\dot{\vec{x}}^{2} + m\dot{\vec{x}}\cdot(\vec{\omega}\times\vec{x})+ \dfrac{1}{2}m (\vec{\omega}\times\vec{x})^{2}
	\end{equation}
	e dunque, la lagrangiana in coordinate cartesiane per sistemi rotanti (scritta nelle coordinate non inerziali) diventa:
	\begin{equation}
		\Lambda = \dfrac{1}{2}mv^{2} + m\vec{v}\cdot(\vec{\omega}\times\vec{x}) + \dfrac{1}{2}m(\vec{\omega}\times\vec{x})^{2} - V(x)
		\label{LagRot}
	\end{equation}
	Notiamo subito che il fatto di essere un sistema non inerziale porta con sè alcune modifiche alla Lagrangiana che non è più banalmente $T-V$, ma deve tenere conto di altri termini. Infatti, l'addendo $1/2\> m\vec{v}^{2}$, rappresenta la forma dell'energia cinetica come verrebbe scritta da un osservatore interno al sistema in esame. Se tale sistema fosse inerziale, non avremmo avuto altri termini aggiuntivi. Concludiamo che, per far funzionare la Lagrangiana anche nei sistemi rotanti, dobbiamo modificarne la definizione.
	\subsection{Forza di Coriolis}
	Riprendiamo la nuova definizione della Lagrangiana per sistemi di riferimento rotanti, scritta in (\ref{LagRot}). I termini aggiuntivi hanno un'interessante interpretazione fisica. Il secondo termine, detto \textit{centrifugo}, è un potenziale fittizio in quanto dipende solo dalle coordinate. Questo corrisponde con la forza centrifuga di cui si fa esperienza nei sistemi rotanti. Il primo termine, invece, ha la forma di un potenziale generalizzato in quanto è lineare nella velocità $\vec{v}$. Che forza genera questo tipo di potenziale? Applicando i metodi della sezione precedente e supponendo che $\vec{\omega}$ avremo che:
	\begin{equation}
		\begin{aligned}
			\vec{F} &= \Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \vec{v}} - \dfrac{\partial}{\partial \vec{x}}\Bigl) (m\vec{v}\cdot(\vec{\omega}\times\vec{x}) = m\dfrac{d}{dt}(\vec{\omega}\times\vec{x}) - 
			\dfrac{\partial }{\partial x} m\vec{x}\cdot(\vec{v}\times\vec{\omega})
			\\
			\vspace{2cm}
			&= m\vec{\omega}\times\vec{v} - m(\vec{v}\times\vec{\omega}) = 2m\vec{v}\times\vec{\omega} \\
		\end{aligned}
		\label{ForzaCoriolis}
	\end{equation}
	Questa è l'espressione cartesiana della cosiddetta \textit{forza di Coriolis}, un'altra forza fittizia che compare solo nei sistemi di riferimento rotanti. Notiamo, in ultimo, che tale espressione è molto simile alla forza di Lorentz per il campo magnetico. C'è, infatti, una profonda connessione fra il vettore $\vec{\omega}$ e $\vec{B}$ ...
	\subsubsection{Pendolo di Foucault}
	Un classico esempio di problema fisico in cui è necessario tenere conto della forza di Coriolis è quello del pendolo di Foucault. Consideriamo il seguente set-up: una punto materiale di massa $m$ nel piano $xy$ attaccato ad una molla centrata nell'origine degli assi. Tale piano è in realtà posto in maniera tangente su di una sfera che ruota attorno al suo asse polare con velocità angolare $\vec{\Omega}$ costante. Qual è il moto del punto? Se decidiamo di descrivere la situazione fisica nel sistema di riferimento rotante solidale alla sfera il cui origine coincide col punto di tangenza (e con l'estremo fissato della molla), allora è necessario tenere conto delle forze di natura non inerziale che naturalmente insorgono nella lagrangiana. 
	
	Cominciamo a scrivere $\vec{\Omega}$ nel sistema rotante appena identificato\footnote{Il vettore di velocità angolare va scritto nella base rotante perché il metodo sopra esposto funzioni}:
	$$
	\vec{\Omega} = (0,\Omega \sin(\alpha), \Omega \cos(\alpha))
	$$
	dove $\alpha$ è la latitudine del punto materiale. Allora la Lagrangiana scritta nel sistema di riferimento rotante con coordinate cartesiane è:
	\begin{equation}
		\Lambda = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2}) + m\Omega \cos\alpha (x\dot{y}-\dot{x}y) - \dfrac{k}{2}(x^2+y^2) + O(\Omega^2)
	\end{equation}
	Il termine centrifugo dipende da $\Omega^2$ e per ora lo trascuriamo perché assumiamo $\Omega$ piccolo. Il termine centrale è proprio il potenziale generalizzato derivante dalla forza apparente di Coriolis. 
	
	Per risolvere tale sistema, possiamo considerare il trucchetto di porre come nuove coordinate:
	$$
	z = x+iy \>\>\>\>\>\>\>\>\>\>\>\> \bar{z} = x-iy
	$$
	Allora scriveremo che:
	$$
	z\bar{z} = x^2 + y^2,  \>\>\>\>\>\>\>\>\>\>\>\>  \dot{z}\dot{\bar{z}} = \dot{x}^2 + \dot{y}^2
	$$
	Invece se faccio:
	$$
	\dot{z}\bar{z} = (\dot{x}x+y\dot{y})+i(\dot{y}x-\dot{x}y)
	$$
	e quindi:
	$$
	(\dot{y}x-\dot{x}y) = -\dfrac{1}{2}i (\dot{z}\bar{z}-\dot{\bar{z}}z)
	$$
	e la Lagrangiana in forma complessa assume la forma:
	$$
	\Lambda = \dfrac{1}{2}m\dot{z}\dot{\bar{z}} - \dfrac{1}{2}kz\bar{z} -im\Omega\cos\alpha(\dot{z}\bar{z}-\dot{\bar{z}}z)
	$$
	Se ora applico l'operatore di Lagrange rispetto a $\bar{z}$, ottengo l'equazione:
	$$
	\Bigl(\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{\bar{z}}}-\dfrac{\partial}{\partial \bar{z}}\Bigl)\Lambda = 0 \iff \dfrac{1}{2}m\ddot{z} + im\Omega\cos\alpha\dot{z}+\dfrac{1}{2}kz = 0
	$$
	che si riduce ad un'equazione differenziale del secondo ordine lineare ed omogenea:
	$$
	\ddot{z} + 2i\Omega\cos\alpha \dot{z} +\omega^{2}_{0} z = 0
	$$
	con $\omega_0^2 = k/m$ pulsazione naturale della molla. Questa equazione è facile da risolvere. Ipotizzando una soluzione del tipo $z(t) = Ae^{\lambda t}$, deve essere necessariamento che 
	$$
	\lambda = -i\Omega\cos\alpha \pm i\omega_0 + O(\Omega^{2}) \approx  i(\Omega\cos\alpha \pm \omega_0)
	$$
	La soluzione allora è:
	\begin{equation}
		z(t) = e^{i\Omega\cos\alpha t}(Ae^{i\omega_0 t}+ Be^{-i\omega_0 t})
		\label{SoluzFouc}
	\end{equation}
	La soluzione nel piano complesso è uguale alla soluzione nel piano $xy$ essendo le due coordinate cartesiane le parti reali ed immaginarie di $z$. Notiamo che il termine fra parentesi della (\ref{SoluzFouc}) rappresenta un'ellisse nel piano, che è la soluzione che ci saremmo aspettati se il sistema fosse inerziale. Il termine moltiplicativo $exp(i\Omega\cos\alpha)$ aggiunge una rotazione aggiuntiva: è come se l'ellisse tracciata nel piano rotasse ella stessa (fenomeno di precessione). La velocità di tale precessione è legata al valore di $\Omega\cos\alpha$, dunque è massima ai poli e minima all'equatore della sfera.
	\subsection{Potenziale di Lorentz come potenziale rotante}
	Riprendiamo l'esercizio precedente e modifichiamolo leggermente. La sfera non è più posta in rotazione e dunque il sistema di riferimento è perfettamente inerziale. Aggiungiamo però un campo magnetico $\vec{B}$ che formi un angolo costante di $\alpha$ rispetto alla direzione $z$. Se la massa possiede una carica $q$, allora tale sentirà l'effetto del campo $\vec{B}$. Il sistema è inerziale, quindi non devono aggiungere termini esotici alla lagrangiana che diventa:
	\begin{equation}
		\Lambda = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2}) +\dfrac{q}{c}\vec{A}\cdot\vec{v} - \dfrac{k}{2}(x^2+y^2) 
	\end{equation}
	dove in questo caso è necessario aggiungere il potenziale generalizzato dovuto al campo magnetico. Nel capitolo precedente, quello sui potenziali generalizzati, non ci siamo posti il problema della determinazione del campo vettoriale $\vec{A}$. Noi vogliamo che tale potenziale generalizzato produca la solita forza di Lorentz a cui siamo abituati. Richiederemmo cioè che:
	$$
	\Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \vec{v}} - \dfrac{\partial}{\partial \vec{x}}\Bigl)\Bigl(\dfrac{q}{c}\vec{v}\cdot\vec{A}\Bigl) = \dfrac{q}{c}\vec{v}\times\vec{B}
	$$
	Potremmo svolgere i calcoli e imporre $\vec{A}$ perché valga la relazione di Lorentz. Oppure lavoriamo in analogia col potenziale generalizzato che è proprio della forza di Coriolis; infatti, vogliamo che valga:
	\begin{equation}
		\begin{aligned}
			(\vec{\Omega}\times\vec{x})\cdot\vec{v} \>\>\>\>\>\>\>\>\>\>\>\>\>\>\> \mbox{             genera             }\>\>\>\>\>\>\>\>\>\>\>\>\>\>\> 2(\vec{\Omega}\times\vec{v})
			\\
			\dfrac{q}{c}\vec{A}\cdot\vec{v}\>\>\>\>\>\>\>\>\>\>\>\>\>\>\> \mbox{             genera             }\>\>\>\>\>\>\>\>\>\>\>\>\>\>\> \dfrac{q}{c}\vec{B}\times\vec{v}
		\end{aligned}
	\end{equation}
	E quindi è facile vedere che deve essere:
	\begin{equation}
		\vec{A} = \dfrac{1}{2}\vec{B}\times\vec{x}
		\label{A}
	\end{equation}
	Allora la Lagrangiana munita di termine magnetica diventa automaticamente:
	\begin{equation}
		\Lambda = \dfrac{1}{2}m(\dot{x}^{2}+\dot{y}^{2}) +\dfrac{q}{2c}(\vec{B}\times\vec{x})\cdot\vec{v} - \dfrac{k}{2}(x^2+y^2) 
	\end{equation}
	Notiamo di nuovo la sorprendente analogia col caso di Coriolis. In questo caso il sistema è perfettamente inerziale ma è soggetto ad una forza magnetica. Nel caso di Coriolis, il sistema è in rotazione con una velocità angolare $\vec{\Omega}$ costante. Le lagrangiana di queste due situazioni sono molto simili\footnote{Avevamo ignorato il termine centrifugo, però. Nel caso magnetico il conto è senza approssimazioni.}, nonostante l'apparente distanza concettuale (basta identificare $\vec{B}$ con $\vec{\Omega}$). Una particella soggetta a tale campo magnetico oscillerebbe con una pulsazione di precessione caratteristica che vale, secondo l'analogia fra $\vec{B}$ e $\vec{\Omega}$,
	$$
	\Omega_m = \dfrac{qB_0}{2c}
	$$
	detta anche frequenza di Larmor
	\subsubsection{Esercizio}
	Consideriamo un punto materiale vincolato a muoversi su di una sfera e soggetto ad un campo magnetico costante $\vec{B} = B_0 \hat{z}$. Chiaramente faremo uso delle coordinate sferiche, grazie alle quali l'energia cinetica diventa:
	$$
	T = \dfrac{1}{2}mR^2(\dot{\theta}^2+\dot{\phi}^2\sin^2\theta)
	$$
	Il campo magnetico crea un potenziale generalizzato del tipo $\vec{A}\cdot\vec{v}$ dove $\vec{A}$, per quanto appena ricavato, vale\footnote{Il rotore, il prodotto vettoriale hanno senso solo in coordinate cartesiane. Ritorneremo alle coordinate sferiche fra poco}:
	$$
	\vec{A} = \dfrac{1}{2}\vec{B}\times\vec{x} = \dfrac{1}{2}(0,0,B_0)\times(x,y,z) =\dfrac{1}{2}B_0 (-y,x,0)
	$$
	Dovremmo ritornare alle coordinate sferiche. Notiamo che il vettore $(-y,x,0)$ è uguale a $\vec{e}_\varphi$, quindi:
	$$
	\vec{A} = \dfrac{1}{2}B_0\vec{e}_\varphi
	$$
	E quindi il termine di potenziale generalizzato magnetico è:
	$$
	V_m = \dfrac{q}{c}\vec{A}\cdot\vec{v} = \dfrac{q}{2c}B_0\vec{e}_\varphi(\dot{\theta}\vec{e}_\theta + \dot{\varphi}\vec{e}_\varphi) = \dfrac{qB_0}{2c}\dot{\varphi} (\vec{e}_\varphi\cdot\vec{e}_\varphi) = \dfrac{qB_0}{2c}\dot{\varphi}R^2\sin^2(\theta)
	$$
	Notiamo un fatto interessante. Il prodotto scalare che abbiamo appena fatto è quello classico, cioè quello che coincide col prodotto euclideo nella base cartesiana. Siccome $\vec{A}$ era scritto nella nuova base, potremmo fare il prodotto scalare nelle coordinate generalizzate utilizzando la metrica, che esiste apposta per questo scopo. Infatti, $\vec{A} = (0,\dfrac{1}{2}B_0)$ in base sferica e:
	\begin{equation}
		\vec{A}\cdot\vec{v} = 
		\begin{pmatrix}
			0 &
			\dfrac{1}{2}B_0
		\end{pmatrix}
		\begin{pmatrix}
			R^2 & 0 \\
			0 & R^2 \sin^2(\theta)
		\end{pmatrix}
		\begin{pmatrix}
			\dot{\theta} \\
			\dot{\varphi}
		\end{pmatrix}
		= \dfrac{qB_0}{2c}\dot{\varphi}R^2\sin^2(\theta)
	\end{equation}
	La Lagrangiana del sistema è dunque:
	\begin{equation}
		\Lambda = \dfrac{1}{2}mR^2(\dot{\theta}^2+\dot{\varphi}^2\sin^2\theta) + \dfrac{qB_0}{2c}\dot{\varphi}R^2\sin^2(\theta)
	\end{equation}
	L'energia è sicuramente integrale primo del moto e anche il momento generalizzati di $\varphi$ lo è, essendo $\varphi$ coordinata ciclica:
	$$
	p_\varphi = mR^2\dot{\varphi}\sin^2(\theta) + \dfrac{qB_0}{2c}R^2\sin^2(\theta)
	$$
	L'energia del sistema si scrive come energia cinetica, dunque:
	$$
	H = T = \dfrac{1}{2}mR^2(\dot{\theta}^2+\dot{\phi}^2\sin^2\theta)
	$$
	e il potenziale magnetico giustamente non compare. Isolando $\dot{\varphi}$ dalla prima equazione, ottengo:
	$$
	\dot{\varphi} = \dfrac{p_{\varphi}}{mR^2\sin^2\theta} - \dfrac{qB_0}{2mc}
	$$
	e inserendo tale espressione nell'energia si ha:
	$$
	H = \dfrac{1}{2}mR^2\dot{\theta}^2 + \dfrac{p_\varphi^2}{2mR^2\sin^2\theta} + \dfrac{q^2B_{0}^{2}R^2}{8mc^2}\sin^2\theta - \dfrac{p_\varphi q B_0}{2mc}
	$$
	L'ultimo termine è una costante, quindi posso sbarazzarmene e ottengo la forma per l'energia:
	\begin{equation}
		H = \dfrac{1}{2}mR^2\dot{\theta}^2 + \dfrac{p_\varphi^2}{2mR^2\sin^2\theta} + \dfrac{q^2B_{0}^{2}R^2}{8mc^2}\sin^2\theta
	\end{equation}
	Questa è formata da un termine puramente cinetico ed un termine di potenziale efficace funzione di $\sin\theta$. Tale potenziale efficace va all'infinito per $\theta=0,\pi$ e ha quindi un minimo in tale intervallo, corrispondente ad una soluzione di equilibrio stabile per $\theta$ (e $\varphi$ varia linearmente).
	\newpage
	\section{Teorema di Noether e simmetrie fondamentali}
	Ci apprestiamo ora ad enunciare un risultato fondamentale della fisica teorica classica che va sotto il nome di \textit{Teorema di Noether}. Prima però un po' di matematica
	\subsection{Gruppi e simmetrie}
	Diamo la definizione matematica di gruppo $\mathcal{G}$:
	\begin{tcolorbox}
		Un insieme $\mathcal{G}$ dotato di un'operazione binaria interna $\cdot$, detta di composizione, è detto \textit{gruppo} se:
		\begin{itemize}
			\item L'operazione di composizione è associativa, cioè:
			$$
			a\cdot(b\cdot c) = (a\cdot b)\cdot c \>\>\>\>\>\> \forall a,b,c \in \mathcal{G}
			$$
			\item Esiste un elemento del gruppo, detta \textit{unità} e indicata con $1$, tale per cui:
			$$
			a\cdot 1 = 1\cdot a = a \>\>\>\>\>\> \forall a \in \mathcal{G}
			$$
			\item Esiste sempre l'inverso compositivo di qualsiasi elemento del gruppo, detto $a^{-1}$, cioè:
			$$
			\forall a \in \mathcal{G}, \> \exists a^{-1} : a\cdot a^{-1} = a^{-1}\cdot a = 1
			$$
		\end{itemize}
	\end{tcolorbox}
	Nella definizione di gruppo non è richiesta la commutatività della composizione. Se un gruppo $\mathcal{G}$ rispetta tale condizione, allora è dettpo \textit{gruppo abeliano}.
	
	Il flusso di fase definito nelle prime pagine è, a tutti gli effetti, un gruppo abeliano parametrizzato dal tempo. Infatti, basta considerare l'insieme continuo delle trasformazioni $\mathcal{G} = \{\phi^{t}, \> t\in \mathbb{R}\}$. La struttura di gruppo è facilmente verificabile grazie alla proprietà fondamentale del flusso di fase:
	$$
	\phi^{t}(\phi^{s}) = \phi^{t+s}
	$$
	da cui è facile verificare l'associatività e la commutatività (essendo la addizione tra reali associativa e commutativa). L'esistenza dell'unità è assicurata dalla condizione:
	$$
	\phi^{0} = I
	$$
	e la trasformazione identità è chiaramente l'unità del gruppo. L'esistenza dell'inverso è anch'essa facilmente dimostrabile, basta prendere $(\phi^{t})^{-1} = \phi^{-t}$.
	
	Il flusso di fase inteso come trasformazione nello spazio delle fasi costituisce dunque un gruppo abeliano parametrizzato al tempo fisico $t$. Possiamo chiaramente individuare tanti altri gruppi, come ad esempio il gruppo delle rotazioni in $\mathcal{R}^{2}$ che può essere rappresentato come il gruppo delle matrici ortogonali parametrizzate all'angolo di rotazione $\alpha$:
	\begin{equation}
		G = \Bigl\{
		R = 
		\begin{pmatrix}
			\cos\alpha & \sin\alpha \\
			-\sin\alpha & \cos\alpha
		\end{pmatrix}
		,\>\> \alpha \in \mathbb{R}^{3}
		\Bigl\}
	\end{equation}
	che forma un gruppo al variare dell'angolo $\alpha$.
	
	Consideriamo allora un generico gruppo $\phi^{\alpha}$ parametrizzato ad un qualche parametro $\alpha\in\mathbb{R}^{3}$ che rappresenti una trasformazione delle coordinate.
	$$
	x \longrightarrow \phi^{\alpha}(x)
	$$ 
	Richiediamo che anche per questo gruppo (che non deve necessariamente essere quello del flusso di fase) valgano le proprietà:
	$$
	\phi^{\alpha = 0} = I \>\>\>\>\>\>\>\> \phi^{t}(\phi^{s}) = \phi^{t+s}
	$$
	e sappiamo che tali proprietà bastano per garantire la struttura di gruppo abeliano per $\phi?{\alpha}$. 
	
	Diremo che tale gruppo è una \textit{simmetria} per un certo sistema fisico se applicare tale trasformazione alle coordinate lascia invariata la lagrangiana del sistema, cioè:
	\begin{equation}
		\Lambda(\phi^{\alpha}(x),\dfrac{d}{dt}\phi^{\alpha}(x)) = \Lambda(x,\dot{x})
	\end{equation}
	Una simmetria di un sistema è dunque un gruppo di trasformazioni che, da un punto di vista fisico, lo lasciano totalmente inalterato (essendo la lagrangiana la sola rappresentante della fisica di un sistema fisico). 
	
	Facciamo un esempio. Prendiamo una lagrangiana bidimensionale:
	$$
	\Lambda(x,y,\dot{x},\dot{y}) = \dfrac{1}{2}m(\dot{x}^2+\dot{y}^2) - ax
	$$
	tipica di un campo di forze uniforme diretto lungo l'asse $x$. Se considero il gruppo abeliano delle traslazioni lungo l'asse $y$, che posso scrivere come:
	\begin{equation}
		\mathcal{G} = \{\phi^{y_0}: \phi^{y_0}(x,y) = (x,y+y_0)\}
	\end{equation}
	Allora la lagrangiana rimane chiaramente invariata per qualsiasi elemento di $\mathcal{G}$, essendo $\dfrac{d}{dt}\phi^{y_0}(x,y) = \dfrac{d}{dt}(x,y+y_0) = (\dot{x},\dot{y})$. Allora una qualsiasi traslazione lungo l'asse $y$ è una simmetria del sistema.
	\subsection{Generatori di gruppi}
	La richiesta che una simmetria di un sistema abbia la struttura di un gruppo abeliano è necessaria per poter parlare di \textit{generatori del gruppo}, definiti come campi vettoriali $a(x)$:
	\begin{equation}
		a(x) = \dfrac{d}{d\alpha}\Bigl|_{\alpha=0}\phi^{\alpha}(x)
	\end{equation}
	e $a(x)$ diventa uno spazio vettoriale. L'esistenza del generatore è, per l'appunto, strettamente legata alla natura di gruppo della trasformazione $\phi^{\alpha}$.
	
	\subsection{Teorema di Noether}
	Prendiamo un gruppo di simmetria abeliano $\phi^{\alpha}$ per un sistema fisico. Allora:
	\begin{equation}\label{key}
		\Lambda(x,\dot{x}) = \Lambda(\phi^{\alpha}(x), \dfrac{d}{dt}\phi^{\alpha}(x))
	\end{equation}
	Poiché questa proprietà vale per tutti gli elementi del gruppo, cioè vale per tutti gli $\alpha$, allora derivando la Lagrangiana $\Lambda(x,\dot{x})$ rispetto ad $\alpha$ dovremmo ottenere $0$, cioè:
	\begin{equation}\label{key}
		\dfrac{d}{d\alpha}\Lambda(\phi^{\alpha}(x), \dfrac{d}{dt}\phi^{\alpha}(x)) = 0
	\end{equation}
	In particolare dovrà valere che:
	\begin{equation}\label{key}
		\dfrac{d}{d\alpha}\Lambda(\phi^{\alpha}(x), \dfrac{d}{dt}\phi^{\alpha}(x))\Bigl|_{\alpha = 0} = 0
	\end{equation}
	Derivando compositamente, si ottiene:
	\begin{equation}\label{eq8}
		\begin{aligned}
			\dfrac{\partial \Lambda}{\partial x}\dfrac{d}{d\alpha}\phi^{\alpha}(x)\Bigl|_{\alpha = 0} &+ \dfrac{\partial \Lambda}{\partial \dot{x}}\dfrac{d}{d\alpha}\dfrac{d}{dt}\phi^{\alpha}(x)\Bigl|_{\alpha = 0} =0 \\
			\dfrac{\partial \Lambda}{\partial x} a(x) &+ \dfrac{\partial \Lambda}{\partial \dot{x}} \dfrac{d}{dt}a(x) = 0
		\end{aligned}
	\end{equation}
	Ma poiché le soluzioni fisiche sono caratterizzate da
	\begin{equation}\label{key}
		\dfrac{d}{dt}\dfrac{\partial \Lambda}{\partial \dot{x}} = \dfrac{\partial \Lambda}{\partial x}
	\end{equation}
	Allora riscriviamo la (\ref{eq8}) come:
	\begin{equation}\label{key}
		\dfrac{d}{dt}\Bigl(\dfrac{\partial \Lambda}{\partial \dot{x}}\Bigl)a(x) + \dfrac{\partial \Lambda}{\partial \dot{x}}\Bigl( \dfrac{d}{dt}a(x)\Bigl) = 0
	\end{equation}
	Chiamando $\dfrac{\partial \Lambda}{\partial \dot{x}} = p_{x}$, avremo che:
	\begin{equation}\label{key}
		\dfrac{d}{dt}(p_x)a(x) + p_x\Bigl( \dfrac{d}{dt}a(x)\Bigl) = 0
	\end{equation}
	che è equivalente alla derivata temporale del prodotto delle due funzioni, cioè:
	\begin{equation}\label{ThNoether}
		\dfrac{d}{dt}(p_x a(x)) = 0
	\end{equation}
	L'equazione (\ref{ThNoether}) è l'enunciato del Teorema di Noether. Abbiamo infatti ricavato un integrale primo del moto $I$ definito come:
	$$
	I = p_x \> a(x) = \dfrac{\partial \Lambda}{\partial \dot{\vec{x}}}\cdot\vec{a}(\vec{x})$$
	che deriva dall'esistenza di un campo generatore $\vec{a}$ e, quindi, dalla simmetria $\phi$. Il teorema di Noether afferma proprio ciò, cioè che per ogni simmetria di un sistema fisico esiste un integrale primo del moto associato. Esiste dunque un profondo collegamento fra simmetrie fisiche e quantità conservate.
	\subsection{Coordinate cicliche e energia}
	Adesso è più chiaro il concetto di coordinata ciclica. Se una coordinata $q_i$ non compare nella lagrangiana, allora la lagrangiana è invariante per traslazioni rispetto a quella variabile (aggiungere una costante non modifica la derivata temporale di $q_i$). Il generatore di tale simmetria è il campo $a(q) = (0,0, ..., 0, 1, 0, ..., 0)$, non nullo solo nella i-esima posizione. L'integrale primo associato a tale simmetria traslazionale è:
	$$
	I = \dfrac{\partial \Lambda}{\partial \dot{q}}\cdot a(q) = \dfrac{\partial \Lambda}{\partial \dot{q_i}}
	$$
	che è proprio il momento generalizzato coniugato alla coordinata ciclica $q_i$.
	
	E per quanto riguarda l'energia? Esiste una simmetria legata alla conservazione dell'energia? Sì, ed è quella temporale. Il gruppo da considerare è quello del flusso di fase propriamente detto, $\phi^{t}$.  
	\subsection{Esempio di simmetrie}
	Facciamo subito qualche esempio. Consideriamo il gruppo abeliano delle rotazioni attorni all'asse $z$ in $\mathbb{R}^{3}$, rappresentabile dalle matrici ortogonali:
	\begin{equation}\label{key}
		\phi^{\alpha} = \Bigl\{
		\begin{pmatrix}
			\cos\alpha & \sin\alpha & 0 \\
			-\sin\alpha & \cos\alpha & 0 \\
			0 & 0 & 1 \\
		\end{pmatrix}
		, \alpha\in\mathbb{R}^{3}\Bigl\}
	\end{equation}
	Come è fatto il generatore? Per definizione,
	\begin{equation}\label{key}
		\vec{a}(x,y,z) = \dfrac{d}{d\alpha}\phi^{\alpha}(x,y,z)\Bigl|_{\alpha = 0} = 
		\begin{pmatrix}
			0 & 1 & 0 \\
			-1 & 0 & 0 \\
			0 & 0 & 0 \\
		\end{pmatrix}
		\begin{pmatrix}
			x \\ y \\ z
		\end{pmatrix}
		= (y,-x,0)
	\end{equation}
	Prendiamo ora una particella libera nello spazio, la cui lagrangiana è banalmente:
	$$
	\Lambda = \dfrac{1}{2}mv^{2}
	$$
	Poiché le rotazioni $\phi^{\alpha}$ lasciano invariato il modulo dei vettori, allora la Lagrangiana è invariante per tali rotazioni. L'integrale primo del moto che otteniamo tramite il teorema di Noether è:
	\begin{equation}\label{key}
		I = m\vec{v}\cdot\vec{a} = m(\dot{x},\dot{y},\dot{z})\cdot(y,-x,0) = my\dot{x} - mx\dot{y}, 0) = yp_x-xp_y
	\end{equation}
	Che, guarda caso, coincide con la componente lungo $z$ del momento angolare. In generale, se ho un sistema fisico che è invariante per rotazioni attorno ad un certo asse, allora viene conservata la componente su quell'asse del momento angolare\footnote{Che va calcolato imponendo il polo su quell'asse}. Se il sistema è anche simmetrico rispetto agli altri assi di rotazione, come accade per la particella libera, allora tutti e tre le componenti di $\vec{L}$ si conservano e, dunque, si conserva $\vec{L}$ in generale (come già sappiamo debba essere).
	\subsection{Limiti della meccanica lagrangiana}
	Se consideriamo un sistema che è invariante per tutte le rotazioni in $\mathbb{R}^{3}$, detta $R(\alpha)$, incappiamo in un problema. Tale gruppo infatti non è abeliano e applicare Noether risulta impossibile. Vediamo subito un esempio facile ma significativo. Prendiamo una particella libera in $\mathbb{R}^{3}$ in coordinate sferiche, per cui sappiamo
	\begin{equation}\label{key}
		\Lambda = \dfrac{1}{2}m(\dot{r}^2+r^2\dot{\theta}^2+r^2\dot{\varphi}^2\sin^2\theta)
	\end{equation}
	Ma $\varphi$ è coordinata ciclica, quindi $p_\varphi$ si deve conservare:
	\begin{equation}\label{key}
		p_\varphi = mr^2\dot{\varphi}\sin^2\theta = [ \vec{L}]_z
	\end{equation}
	che è anche la componente lungo $z$ del momento angolare. Lo stesso risultato era ottenibile imponendo l'invarianza della Lagrangiana per traslazioni lungo $\varphi$, che coincidono con rotazioni attorno all'asse $z$. Un altro integrale primo del moto è chiaramente l'energia,
	\begin{equation}\label{key}
		H = \Lambda = \dfrac{1}{2}m(\dot{r}^2+r^2\dot{\theta}^2+r^2\dot{\varphi}^2\sin^2\theta)
	\end{equation}
	Sappiamo che la particella libera nello spazio deve essere un sistema perfettamento risolubile e quindi mi aspetto di poter trovare un terzo integrale primo del moto. Eppure non abbiamo altre coordinate cicliche (almeno in forma cartesiana) e abbiamo già sfruttato l'energia; cosa ci manca? 
	
	Proviamo a calcolare $p_\theta$ (che non è integrale primo del moto):
	\begin{equation}\label{key}
		p_{\theta} = mr^2\dot{\theta} 
	\end{equation}
	e lo utilizzo come coordinata, operando dunque un cambio di coordinata $\theta \rightarrow p_\theta$ e $\varphi \rightarrow p_\varphi$:
	\begin{equation}\label{key}
		E = \dfrac{1}{2}m\dot{r}^2 + \dfrac{p_{\theta}^{2}}{2mr^{2}} + \dfrac{p_{\varphi}^2}{2mr^2\sin^2\theta}
	\end{equation}
	moltiplicando tutto per $2mr^{2}$ e riarraggiando i termini:
	\begin{equation}\label{key}
		2mr^2 (E - \dfrac{1}{2}m\dot{r}^2)  =  p_{\theta}^{2} + \dfrac{p_{\varphi}^2}{\sin^2\theta}
	\end{equation}
	Il termine a destra è solo funzione di $\theta$ ed è sempre uguale al termine di sinistra, funzione unicamente di $r$. Allora necessariamente:
	$$
	p_{\theta}^{2} + \dfrac{p_{\varphi}^2}{\sin^2\theta}
	$$
	deve essere invariante rispetto al tempo e dunque costituisce l'ultimo integrale primo del moto che cercavamo per risolvere il problema. Notiamo che, in questo caso, l'ultimo integrale primo non ci è stato suggerito da alcuna simmetria del sistema (solo $\varphi$ era coordinata ciclica). Tale inconveniente verrà risolto con il formalismo Hamiltoniano.
	
	\newpage
	\section{Teoria delle piccole oscillazioni}
	L'equazione caratteristica per il pendolo fisico è:
	$$
	\ddot{\theta} + \omega^2_0 \sin\theta = 0
	$$
	Nonstante questa sembri all'apparenza molto semplice, è incredibilmente trovare una soluzione analitica per la legge oraria $\theta(t)$. Tuttavia, spesso siamo interessati a studiare il comportamente dell'oscillatore fisico in intorni del punto di minimo per il potenziale, ovvero in approssimazione di piccoli angoli. In tal caso, è consuetidune approssimare $\sin\theta \approx \theta$ e si ottiene l'equazione lineare facile da risolvere analiticamente:
	$$
	\ddot{\theta} + \omega^2_0 \theta = 0
	$$
	Quello che abbiamo appena fatto è cercare una soluzione che approssimi sufficientemente bene la reale equazione del problema valida in intorni del punto di minimo potenziale. D'altronde, se il sistema fisico si trova attorno ad un minimo del potenziale, cioè è in equilibrio stabile, allora esiste sempre un intorno del punto di minimo $q_0$ in cui la soluzione del problema non si allontana da $q_0$, non esce dalla buca del potenziale. Questo ci garantisce che l'approssimazione che facciamo non peggiorerà nel tempo, perché il moto è limitato ad intorni dell'equilibrio stabile.
	
	Vogliamo trovare un modo per approssimare alle piccole oscillazioni qualsiasi sistema fisico in prossimità del suo punto di equilibrio stabile lavorando direttamente sulla sua lagrangiana. Tale funzione è, nella sua forma più generale:
	\begin{equation}\label{key}
		\Lambda(q,\dot{q}) = \dfrac{1}{2}m\dot{q}_iG_{ij}(q)\dot{q}_j - V(q) + k A_i(q)\dot{q}_i
	\end{equation}
	avendo incluso anche termini di potenziale generalizzato. Notiamo un fatto di vitale importanza: una lagrangiana puramente quadratica produce sempre equazioni del moto lineari. Infatti, se:
	\begin{equation}\label{key}
		\Lambda(q,\dot{q}) = a\langle \>\dot{\vec{q}},G\dot{\vec{q}} \>\rangle  - b\langle \>\vec{q},H\vec{q} \>\rangle = a \dot{q}_iG_{ij}^{0}\dot{q}_j + bq_iH_{ij}^{0}q_j
	\end{equation}
	Questa è una lagrangiana quadratica poiché presenta termini al massimo quadratici nelle $\dot{q}$ (i cui coefficienti sono costanti e sono raggruppati nella matrice $G^{0}$) e quadratica nei $q$ (i cui coefficienti sono riassunti nella matrice costante $H^{0}$). Allora dalle equazioni di Eulero-Lagrange, otterrei che:
	\begin{equation}\label{key}
		Lag_{q_i}(\Lambda) = 2aG_{ij}^{0}\ddot{q}_j - 2bH_{ij}^{0}q_j = 0
	\end{equation}
	cioè:
	\begin{equation}\label{key}
		G_{ij}^{0}\ddot{q}_j - \dfrac{b}{a}H_{ij}^{0}q_j = 0
	\end{equation}
	che rappresentano delle equazioni differenziali del secondo ordine ma sempre lineari (cioè non includono funzioni analitiche come seno, coseno, esponenziali, ...).
	
	Concludiamo che, se vogliamo linearizzare un problema attorno al punto d'equilibrio, dobbiamo approssimare la Lagrangiana in forma quadratica, espandendo con Taylor tutte le varie componenti. Analizziamo pezzo per pezzo. L'energia cinetica:
	$$
	T = \dfrac{1}{2}m\dot{q}_iG_{ij}(q)\dot{q}_j
	$$ 
	è già quadratica nelle $\dot{q}$, mentre la dipendenza dalle $\dot{q}$ (mediata dalla matrice metrica $G$) deve essere espansa secondo Taylor. Chiaramente espansione oltre l'ordine zero porterebbero a forme di terzo ordine miste fra $\dot{q} \mbox{ e } q$, per cui basta porre $G_{ij}(q) \approx G_{ij}(q_0) = G_{ij}^{0}$ (cioè approssimare la matrice in intorni di $q_0$ al valore assunto nel punto $q_0$). Allora l'energia cinetica diventa:
	$$
	T \approx \dfrac{1}{2}m\dot{q}_iG_{ij}^{0}\dot{q}_j
	$$
	Il potenziale $V(q)$ va sviluppato attorno al punto di equilibrio fino al secondo ordine con Taylor, per cui:
	$$
	V(q) = V(q_o) + \dfrac{\partial V}{\partial q_i}(q_0) (q_i-q_{0,i}) + \dfrac{1}{2}(q_i-q_{0,i})H_{ij}(q_0)(q_j-q_{0,j}) + o(|q-q_0|^2)
	$$
	dove $H$ è la matrice hessiana del potenziale calcolata in $q=q_0$ che indichiamo con $H_{ij}(q_0) = H_{ij}^{0}$. Per definizione, in un punto di minimo per il potenziale, dovrà valere che:
	$$
	\dfrac{\partial V}{\partial q_i}(q_0)  = 0
	$$
	e quindi:
	\begin{equation}\label{key}
		V(q) = V(q_o) + \dfrac{1}{2}(q_i-q_{0,i})H_{ij}(q_0)(q_j-q_{0,j}) + o(||q-q_0||^2)
	\end{equation}
	operando il cambio di variabili $Q = q-q_0$, si avrà che:
	\begin{equation}\label{key}
		V(Q) \approx V(0) + \dfrac{1}{2}Q_i H_{ij}^0 Q_j
	\end{equation}
	Questo cambio di variabili non modifica notevolmente l'energia cinetica che al secondo ordine rimane:
	\begin{equation}\label{key}
		T \approx \dfrac{1}{2}m\dot{Q}_iG_{ij}^{0}\dot{Q}_j
	\end{equation}
	Il potenziale generalizzato invece, si approssima come:
	$$
	A_i(q) = A_{i}^{0} + \dfrac{\partial A_i}{\partial q_j}Q_j 
	$$
	$$
	V_m = kA_{i}^{0}\dot{Q}_i + k\dfrac{\partial A_i}{\partial q_j}(0)Q_j \dot{Q}_i
	$$
	Il primo termine è una derivata temporale, quindi posso ometterlo e, finalmente, la \textit{Lagrangiana delle piccole oscillazioni} diventa, per intorni del minimo $q_0$:
	\begin{equation}
		\Lambda_{PO}(Q,\dot{Q}) = \dfrac{1}{2}m\dot{Q}_iG_{ij}^{0}\dot{Q}_j - \dfrac{1}{2}Q_i H_{ij}^0 Q_j + k\dfrac{\partial A_i}{\partial q_j}(0)Q_j \dot{Q}_i + O(||q-q_0||^{3})
		\label{LagPOG}
	\end{equation}
	e abbiamo omesso il termine $V(0)$ perché costante e quindi ininfluente per la lagrangiana. Per semplicità, consideriamo situazioni in cui non sia presente alcun termine di potenziale generalizzato, dunque avremo:
	\begin{equation}
		\Lambda_{PO}(Q,\dot{Q}) = \dfrac{1}{2}m\dot{Q}_iG_{ij}^{0}\dot{Q}_j - \dfrac{1}{2}Q_i H_{ij}^0 Q_j + O(||q-q_0||^{3})
		\label{LagPO}
	\end{equation}
	Questa è una lagrangiana quadratica e dunque genererà sicuramente equazioni lineari.
	\subsection{Soluzione della Lagrangiana delle piccole oscillazioni}
	Proviamo a risolvere la (\ref{LagPOG}) mantenendo anche il termine generalizzato. Dalle equazioni di Eulero-Lagrange ottengo il set di equazioni lineari:
	\begin{equation}
		mG_{ij}^{0}\ddot{Q}_j + k\dfrac{\partial A_i}{\partial Q_j}\dot{Q}_j+ H_{ij}^{0}Q_{j} - k\dfrac{\partial A_j}{\partial Q_i}\dot{Q}_j = 0
	\end{equation} 
	\begin{equation}
		mG_{ij}^{0}\ddot{Q}_j + H_{ij}^{0}Q_{j} - k\Bigl(\dfrac{\partial A_i}{\partial Q_j}(0)-\dfrac{\partial A_j}{\partial Q_i}(0)\Bigl)\dot{Q}_j = 0
	\end{equation} 
	E quindi l'aggiunta del termine generalizzati non preclude la linearità delle equazioni del moto, se debitamente espanso. Il termine fra parentesi, in fondo, corrisponde proprio alla componente covariante lungo $i$ della forza legata al termine generalizzato. Definisco una nuova matrice $\hat{A}$ che valga:
	\begin{equation}\label{key}
		\hat{A}_{ij} = k\Bigl(\dfrac{\partial A_j}{\partial Q_i}(0)-\dfrac{\partial A_i}{\partial Q_j}(0)\Bigl)
	\end{equation}
	che è una matrice chiaramente antisimmetrica, $\hat{A}=-\hat{A}^{T}$. In altre parole, l'equazione del moto diventa:
	\begin{equation}
		mG_{ij}^{0}\ddot{Q}_j + \hat{A}_{ij}\dot{Q}_j + H_{ij}^{0}Q_{j} = 0
		\label{eq11}
	\end{equation} 
	Cerco una soluzione nella forma $Q(t) = Q_{\lambda}e^{\lambda t}$, con $\lambda\in\mathbb{C}$. Buttando dentro questa forma nella (\ref{eq11}), si ottiene che:
	$$
	mG_{ij}^{0}\lambda^{2}Q_{\lambda,j}e^{\lambda t} + \hat{A}_{ij} \lambda e^{\lambda t}Q_{\lambda,j}+ H_{ij}^{0}Q_{\lambda,j} e^{\lambda t} = 0
	$$
	$$
	mG_{ij}^{0}\lambda^{2}Q_{\lambda,j} + \hat{A}_{ij} \lambda Q_{\lambda,j}+ H_{ij}^{0}Q_{\lambda,j} = 0
	$$
	\begin{equation}
		(m\lambda^{2}G_{ij}^{0}+\lambda \hat{A}_{ij} + H_{ij}^{0})Q_{\lambda,j} = 0,   \>\>\>\>\>\> \forall i
		\label{Eq10}
	\end{equation}
	In altre parole, il vettore $Q_{\lambda}$ è tale da
	\begin{equation}
		(m\lambda^{2}G^{0}+\lambda \hat{A} + H^{0})Q_{\lambda} = 0
		\label{eq12}
	\end{equation}
	Dunque $Q_{\lambda}$ appartiene al kernel della matrice $(m\lambda^{2}G^{0}+\lambda\hat{A}+H^{0})$. Allora necessariamente la matrice $(m\lambda^{2}G^{0}+\lambda\hat{A} + H^{0})$ deve essere non iniettiva, perché se lo fosse il suo kernel sarebbe solo il vettore nullo (e noi sappiamo che fisicamente $Q_{\lambda}$ deve essere diverso dal vettore $\vec{0}$). Allora imponiamo che:
	\begin{equation}
		det(m\lambda^{2}G^{0}+\lambda\hat{A} + H^{0}) = 0
		\label{DetPO}
	\end{equation}
	condizione equivalente alla non-iniettività (cioè alla singolarità) della matrice.
	
	Prendendo la (\ref{eq11}) e moltiplicando per $Q_{\lambda}$, otteniamo una serie di forme quadratiche:
	$$
	m\lambda^{2}Q_{\lambda}G^{0}Q_{\lambda} + \lambda Q_{\lambda}\hat{A}Q_{\lambda} + Q_{\lambda}H^{0}Q_{\lambda} = 0
	$$
	Ma il termine $Q_{\lambda}\hat{A}Q_{\lambda}$, la forma quadratica associata a $\hat{A}$ è nullo perché la matrice è antisimmetrica. Per cui rimane:
	$$
	m\lambda^{2}Q_{\lambda}G^{0}Q_{\lambda} + Q_{\lambda}HQ_{\lambda} = 0
	$$
	e quindi
	\begin{equation}\label{key}
		\lambda^{2} = -\dfrac{Q_{\lambda}H^{0}Q_{\lambda}}{m \> Q_{\lambda}G^{0}Q_{\lambda}}
	\end{equation}
	La matrice metrica è sempre definita positiva (dovendo rappresentare l'energia cinetica, sempre positiva). La matrice hessiana del potenziale è sicuramente definita positiva in $q_0$ poiché l'equilibrio è stabile, cioè il punto $q_0$ è un minimo locale. Ne segue che le forme quadratiche che compaiono nella frazione sono sempre positive e, dunque, il termine $\lambda^{2}$ risulta negativo. Chiamiamo $\omega^{2}=-\lambda^{2}, \lambda = \pm i \omega$ e otteniamo delle soluzioni del tipo:
	\begin{equation}\label{key}
		Q(t) = Q_{\lambda} (Ae^{i\omega t}+Be^{-i\omega t})
	\end{equation}
	e ce ne saranno tante quante la numerosità di $\lambda$ che risolvono la condizione (\ref{DetPO}). Prendiamo solo la parte reale della soluzione così da avere la soluzione fisica:
	\begin{equation}\label{key}
		Q(t) = Q_{\lambda} (A\cos(\omega t)+B\sin(\omega t))
	\end{equation}
	Notiamo che nella determinazione di $\omega$ non c'è traccia del potenziale generalizzato. Infatti la condizione (\ref{DetPO}) può tranquillamente essere riscritta come:
	\begin{equation}
		det(-m\omega^{2}G^{0} + H^{0}) = 0
		\label{DetPO}
	\end{equation}
	
	
	
	\subsection{Ortonormalità delle soluzioni}
	Prendiamo in esame la singola soluzione:
	$$
	Q(t) = Q_{\lambda}(A_{\lambda}\cos(\omega t)+B_{\lambda}\sin(\omega t)).
	$$
	E dimostriamo che i vettori $Q_{\lambda}$ formano una base ortogonale rispetto alla metrica di $G^{0}$. Calcoliamo allora il prodotto scalare fra due autovettori di autospazi diversi attraverso la metrica\footnote{Indichiamo con $\langle \>\>,\>\>\rangle_{G}$ il prodotto scalare individuato dalla metrica $G$}:
	\begin{equation}\label{key}
		Q_{\lambda}^{T}G^{0}Q_{\mu} = \langle Q_{\lambda},Q_{\mu} \rangle_{G}
	\end{equation}
	Io so che:
	$$
	m\omega^{2}(Q_{\lambda}^{T}G^{0}Q_{\mu}) = Q_{\lambda}^{T}(m\omega^{2}G^{0})Q_{\mu} = Q_{\lambda}^{T}H^{0}Q_{\mu} = \langle Q_{\lambda},Q_{\mu} \rangle_{H}
	$$
	Siccome $H$ è simmetrica, allora è autoaggiunta, dunque $H= H^{\dagger}$ e nel prodotto scalare posso scrivere\footnote{Se nel prodotto scalare non si sottintende la metrica, si fa riferimento a quella euclidea standard}:
	$$
	\langle Q_{\lambda},Q_{\mu} \rangle_{H} = \langle Q_{\lambda},H^{0}Q_{\mu} \rangle = \langle H^{0}Q_{\lambda},Q_{\mu} \rangle = H^{0}Q_{\lambda}^{T}Q_{\mu}
	$$
	DIMOSTRAZIONE DA FINIRE
	
	Siamo quindi giunti alla conclusione che:
	$$
	Q_{\lambda}^{T}G^{0}Q_{\mu} = 0
	$$
	e allora i vettori $Q_{\lambda}$ costituiscono una base ortogonali (eventualmente normalizzabile) dello spazio delle configurazioni. Poiché trattasi di vettori ortogonali, allora sono anche linearmente indipendente e la soluzione finale della lagrangiana delle piccole oscillazione è esprimibile come somma degli autovettori ortogonali:
	\begin{equation}\label{key}
		Q(t) = \sum_{\omega}Q_{\omega}(A_{\omega}\cos(\omega t)+B_{\omega}\sin(\omega t))
	\end{equation}
	Gli autovettori $Q_{\lambda}$ sono $n$ e, per ciascuno di esso, ho due costante arbitrarie $A,B$ da determinare, dunque in totale $2n$ costanti iniziali da imporre. Questo ha senso ed è in accordo con i risultati precedenti.
	
	Le $\omega$ sono dette \textit{frequenze delle piccole oscillazioni} e i relativi autovettori nello spazio delle configurazioni $Q_{\omega}$ sono detti \textit{modi normali di oscillazione}
	\subsection{Indipendenza delle soluzioni}
	Operiamo un cambio di variabile:
	\begin{equation}\label{key}
		Q = Tu
	\end{equation} 
	dove $T$ è la matrice del cambio di base che ci porta dalla base dei $Q$ alla nuova base ortogonale appena identificata:
	$$
	T = (Q_{\omega1},Q_{\omega2}, ..., Q_{\omega n})
	$$
	In altre parole il vettore $u$ rappresenta un punto nello spazio delle configurazioni scritto nella base ortogonale dei $Q_{\omega i}$. Cosa succede alla Lagrangiana delle piccole oscillazione senza potenziali generalizzati in seguito a questo cambio di variabili?
	\begin{equation}\label{key}
		\Lambda_{PO} = \dfrac{1}{2}m\dot{Q}G^{0}\dot{Q} - \dfrac{1}{2}Q H^{0} Q
	\end{equation}
	$$
	\Lambda_{PO} = \dfrac{1}{2}mT\dot{u}G^{0}T\dot{u} - \dfrac{1}{2}Tu H^{0} Tu
	$$
	$$
	\Lambda_{PO} = \dfrac{1}{2}m\dot{u}(T^{T}G^{0}T)\dot{u} - \dfrac{1}{2}u(T^{T}H^{0}T)u
	$$
	Questo perché $Tu = uT^{T}$. Ora poiché la matrice $T$ mi porta nella base ortogonale dei $Q_{\omega}$, allora mi aspetto che:
	$$
	T^{T}G^{0} T = I
	$$
	Questa espressione rappresenta come cambia il prodotto scalare nel cambio di basi. $G^{0}$ rappresentava il prodotto scalare standard scritto nella base delle coordinate generalizzate $Q$. Quando passo alla base degli $u = a_{1}Q_{\lambda 1} + a_{2}Q_{\lambda 2} + ... + a_{n}Q_{\lambda n}$, quel prodotto scalare diventa rappresentabile dalla matrice identità in ragione della ortogonalità degli $u$ rispetto a $G$.
	Invece il termine:
	\begin{equation}\label{key}
		T^{T}H^{0}T = \begin{pmatrix}
			\omega_{1}^{2} & 0 & \dots & 0 \\
			0 & \omega_{2}^{2} & \dots & 0 \\
			\vdots & \vdots & \ddots & \vdots \\
			0 & 0 & \dots & \omega_{n}^{2}\\
		\end{pmatrix}
	\end{equation}
	Perciò la Lagrangiana delle piccole oscillazioni diventa 
	:
	\begin{equation}\label{key}
		\Lambda_{PO} = \dfrac{1}{2}\sum_{i=1}^{n}\dot{u}_{i}^{2} + \omega_{i}^{2}u_{i}^{2}
	\end{equation}
	Cioè la lagrangiana finale è la somma di $n$ lagrangiane indipendenti, ciascuna quadratica e aventa frequenza caratteristica $\omega_{i}$. Se le varie frequenze in gioco sono incommensurabili, cioè se ad esempio $\omega_{i}/\omega_{j} = \mathbb{R}/\mathbb{Q}$, allora le orbite non saranno chiuse ma sicuramente limitate. Queste orbite si chiamano quasi-periodiche e riempiono in maniera densa un intorno dell'equilibrio stabile.
	\subsection{Esercizio: il doppio pendolo}
	Proponiamo un esercizio in cui è conveniente linearizzare il problema ricorrendo alla teoria delle piccole perturbazioni. Si consideri un doppio pendolo formato da un'asta rigida incernierata lunga $l$ al cui estremo v'è una massa $m$. A partire da questa massa, si estende un'altra asta lunga $l$ libera di rotare rispetto alla prima che termina con un'altra massa $m$. Rappresentando la dinamica del sistema con le coordinate lagrangiane ($\theta,\varphi$) che rappresentano i relativi angoli rispetto alla verticale, si ricava facilmente l'espressione delle lagrangiana del sistema:
	\begin{equation}\label{key}
		\Lambda(\theta,\dot{\theta},\varphi,\dot{\varphi}) = \dfrac{1}{2}ml^2 (2\dot{\theta}^2+ \dot{\varphi}^2 + 2\dot{\theta}\dot{\varphi}\cos(\theta-\varphi)) + mgl(2\cos\theta + \cos\varphi)
	\end{equation}
	Risolvendo le equazioni di Eulero-Lagrange, otterremmo un sistema non lineare che non siamo in grado di risolvere. Procediamo dunque ad individuare i minimi del potenziale 
	$$
	V(\theta,\varphi) = -mgl(2\cos\theta + \cos\varphi)
	$$
	$$
	\dfrac{\partial V}{\partial \theta} = 0 \>\> \>\> \>\> \>\> \>\> \dfrac{\partial V}{\partial \varphi} = 0
	$$
	e i punti critici sono $\theta =0,\pi$ e $\varphi = 0,\pi$. Chiaramente, nelle quattro possibili combinazioni, solo la coppia $(\theta,\varphi)=(0,0)$ rappresenta il punto di equilibrio stabile. Andiamo dunque a esprimere la lagrangiana delle piccole oscillazione. Per quanto riguarda la parte cinetica, ci basta lasciare inalterati i termini quadratici in $\dot{\theta} \mbox{ e }\dot{\varphi}$ sostituendo banalmente a $\theta = 0 \mbox{ e } \varphi = 0$.
	\begin{equation}
		T_{PO} = \dfrac{1}{2}ml^2 (2\dot{\theta}^2+ \dot{\varphi}^2 + 2\dot{\theta}\dot{\varphi}) =  \dfrac{1}{2}m(\dot{\theta},\dot{\varphi})G^{0}
		\begin{pmatrix}
			\dot{\theta} \\
			\dot{\varphi}
		\end{pmatrix}
	\end{equation}
	La metrica infatti è:
	\begin{equation}
		G(\theta,\varphi) = l^2
		\begin{pmatrix}
			2 & \cos(\theta-\varphi) \\
			\cos(\theta-\varphi) & 1 \\
		\end{pmatrix}
	\end{equation}
	che valutata in $(\theta,\varphi)=(0,0)$ restituisce proprio:
	\begin{equation}
		G^0 = l^2
		\begin{pmatrix}
			2 & 1 \\
			1 & 1 \\
		\end{pmatrix}
	\end{equation}
	Passiamo alla Hessiana del potenziale
	\begin{equation}\label{key}
		H^0 =
		\begin{pmatrix}
			\dfrac{\partial ^2 V}{\partial \theta^2}(0,0) & \dfrac{\partial ^2 V}{\partial \theta\partial \varphi}(0,0)
			\vspace{3mm} \\ 
			\dfrac{\partial ^2 V}{\partial \varphi\partial \theta}(0,0) & 	\dfrac{\partial ^2 V}{\partial \varphi^2}(0,0)
		\end{pmatrix} = 
		\begin{pmatrix}
			2mgl & 0 \\
			0 & mgl \\
		\end{pmatrix} = 
		mgl
		\begin{pmatrix}
			2 & 0 \\
			0 & 1 \\
		\end{pmatrix}
	\end{equation}
	Perciò le frequenze delle piccole oscillazione sono determinate dall'equazione:
	$$
	det(-m\omega^{2}G^0+H^0) = 0
	$$
	$$
	det
	\begin{pmatrix}
		-2ml^2\omega^2 + 2mgl & -m\omega^{2}l^2 \\
		-m\omega^{2}l^{2} & -m\omega^{2}l^2+mgl
	\end{pmatrix} = 0
	$$
	$$
	det
	\begin{pmatrix}
		-2\omega^2 + 2\omega_0^2 & -\omega^{2} \\
		-\omega^{2} & -\omega^{2}+ \omega_0^2
	\end{pmatrix} = 0
	$$
	$$
	det
	\begin{pmatrix}
		2\omega^2 - 2\omega_0^2 & \omega^{2} \\
		\omega^{2} & \omega^{2} - \omega_0^2
	\end{pmatrix} = 0
	$$
	avendo definito $\omega_{0}^{2} = \dfrac{g}{l}$ la pulsazione caratteristica del pendolo approssimato. Risolvendo il determinante, 
	$$
	2(\omega^{2}-\omega_{0}^{2})^2- \omega^{4} = 0
	$$
	$$
	2\omega^{4}+2\omega_{0}^{4} - 4\omega_{0}^2\omega^{2} - \omega^{4} = 0
	$$
	$$
	\omega^{4} - 4\omega_{0}^2\omega^{2} +2 \omega_{0}^{4} = 0
	$$
	Le soluzioni sono
	$$
	\omega_{+} = \sqrt{2+\sqrt{2}}\omega_0 \>\>\>\>\>\>\>\>\> \omega_{-} = \sqrt{2-\sqrt{2}}\omega_0
	$$
	che chiameremo pulsazione veloce e pulsazione lenta. Per capire la dinamica del sistema linearizzato, dobbiamo trovare i modi normali, ossia gli autovettori $Q_{\omega_{+}}, Q_{\omega_{-}}$. In altre parole ricerco i vettori per cui valga la relazione:
	\begin{equation}\label{key}
		(-m\omega^{2}G^0 + H^0)Q_{\lambda} = 0
	\end{equation}
	\begin{equation*}\label{key}
		\begin{pmatrix}
			-2ml^2\omega^2 + 2mgl & -m\omega^{2}l^2 \\
			-m\omega^{2}l^{2} & -m\omega^{2}l^2+mgl
		\end{pmatrix}
		\begin{pmatrix}
			\theta_{\pm} \\ \varphi_{\pm}
		\end{pmatrix} = 0
	\end{equation*}
	
	\begin{equation*}\label{key}
		\begin{pmatrix}
			-mgl(2+2\sqrt{2}) & -mgl(2+\sqrt{2}) \\
			-mgl(2+\sqrt{2}) & -mgl(1+\sqrt{2})
		\end{pmatrix}
		\begin{pmatrix}
			\theta_{\pm} \\ \varphi_{\pm}
		\end{pmatrix} = 0
	\end{equation*}
	\begin{equation*}\label{key}
		\begin{pmatrix}
			2\pm2\sqrt{2} & 2\pm\sqrt{2} \\
			2\pm\sqrt{2} & 1\pm\sqrt{2}
		\end{pmatrix}
		\begin{pmatrix}
			\theta_{\pm} \\ \varphi_{\pm}
		\end{pmatrix} = 0
	\end{equation*}
	cioè:
	$$
	(2\pm2\sqrt{2})\theta_{\pm} + (2\pm\sqrt{2})\varphi_{\pm} = 0
	$$
	e:
	$$
	\varphi_{\pm} = -\theta_{\pm}\dfrac{2\pm2\sqrt{2}}{2\pm\sqrt{2}}
	$$
	o meglio:
	$$
	\varphi_{+} = -\theta_{+}\dfrac{2+2\sqrt{2}}{2+\sqrt{2}}  \>\>\>\>\>\>\>\> \varphi_{-} = \theta_{-}\dfrac{2\sqrt{2}-2}{2-\sqrt{2}}
	$$
	Nella situazione di pulsazione veloce, $\omega_{+}$, le oscillazioni avvengono in maniera discorde, cioè se $\theta$ va verso destra, $\varphi$ va verso sinistra. Al contrario, le oscillazione lenti avvengono in maniera concorde.
	\subsection{Sincronizzazione del pendolo doppio}
	DA FARE
	\subsection{Esercizio: piccole oscillazioni con potenziali generalizzati}
	Consideriamo una guida circolare di raggio $R$ che inizialmente stia nel piano $xy$ sulla quale viene posto un punto materiale di massa $m$ e carica $q$. Viene acceso un campo magnetico $\vec{B} = B_0\hat{z}$. Sapendo che la guida è libera di ruotare attorno all'asse $x$, troviamo la lagrangiana del sistema e calcoliamo la frequenza delle piccole oscillazioni. 
	
	Che coordinate usare compatibili col vincolo olonomo della guida? Conviene impiegare la coppia $(\theta,\varphi)$, dove $\theta$ è l'angolo spazzato dal punto nel piano della spira e $\varphi$ è l'angolo che il piano della spira individua rispetto al piano $xy$. Come individuamo le coordinate del punto materiale in funzione di $\theta, \varphi$? La posizione della carica sulla guida quando questa è parallela al piano $xy$ (cioè $\varphi = 0$) è data da
	\begin{equation}\label{key}
		\vec{x} = 
		\begin{pmatrix}
			R\cos\theta
			\\
			R\sin\theta
			\\0
		\end{pmatrix}
	\end{equation}
	Quando la guida ruota, effettua una rotazione attorno all'asse x di un angolo $\varphi$. Tale rotazione può essere interpretata come una matrice ortogonale
	\begin{equation}\label{key}
		R =
		\begin{pmatrix}
			1 & 0 & 0\\
			0 & \cos\varphi & -\sin\varphi \\
			0 & \sin\varphi & \cos\varphi
		\end{pmatrix}
	\end{equation}
	che applicata al vettore di prima mi consente di ottenere la posizione generica:
	\begin{equation}\label{key}
		\vec{x} = 
		\begin{pmatrix}
			R\cos\theta
			\\
			R\sin\theta\cos\varphi
			\\
			R\sin\theta\sin\varphi
		\end{pmatrix}
	\end{equation}
	che sono le coordinate sferiche con asse polare $x$. Praticamento lo spazio delle possibili configurazioni assumibili dal punto materiale è una sfera di raggio $R$. L'energia cinetica allora è:
	$$
	T = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}\theta)
	$$
	Il potenziale gravitazionale è:
	$$
	V = mgR\sin\theta\sin\varphi
	$$
	Il termine di potenziale generalizzato si scrive, in cartesiane, come:
	$$
	V_m = \dfrac{q}{c}\vec{A}\cdot{v} = \dfrac{q}{2c}(\vec{B}\times\vec{x})\cdot\vec{v}
	$$
	Procedendo a fare il calcolo, otterremmo che:
	\begin{equation}\label{key}
		V_m = \dfrac{qB_0}{2c}R^2(\dot{\theta}\cos\varphi-\dfrac{1}{2}\dot{\varphi}\sin2\theta\sin\varphi)
	\end{equation}
	e allora la lagrangiana del sistema è
	\begin{equation}\label{key}
		\Lambda(\theta,\varphi,\dot{\theta},\dot{\varphi}) = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}\sin^{2}\theta) - mgR\sin\theta\sin\varphi + \dfrac{qB_0}{2c}R^2(\dot{\theta}\cos\varphi-\dfrac{1}{2}\dot{\varphi}\sin2\theta\sin\varphi)
	\end{equation}
	Cerchiamo una soluzione approssimata alle piccole oscillazioni. Cerchiamo dapprima i minimi del potenziale, imponendo:
	$$
	\dfrac{\partial V}{\partial \theta} = \dfrac{\partial V}{\partial \varphi} = 0 
	$$
	questo capita per diversi valori della coppia $(\theta,\varphi)$, ma l'unico palesemente di minimo è $(\theta,\varphi) = \Bigl(\dfrac{3\pi}{2}, \dfrac{\pi}{2}\Bigl)$. L'energia cinetica diventa allora:
	$$
	T_{PO} = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2})
	$$
	e la metrica nel minimo è:
	\begin{equation}\label{key}
		G^0 =
		\begin{pmatrix}
			R^2 & 0 \\
			0 & R^2 
		\end{pmatrix}
	\end{equation}
	calcoliamo l'hessiana del potenziale gravitazionale,
	\begin{equation}\label{key}
		H^0 =mgR
		\begin{pmatrix}
			1 & 0 \\
			0 & 1
		\end{pmatrix}
	\end{equation}
	e il potenziale approssimato diventa:
	\begin{equation}\label{key}
		V = \dfrac{1}{2}mgR(\Theta^{2}+\Phi^{2})
	\end{equation}
	dove intendiamo per $\Theta = \theta - \dfrac{3}{2}\pi \mbox{ e } \Phi = \varphi - \dfrac{1}{2}\pi$. Per comodità, confonderemo $\theta,\varphi$ con $\Theta,\Phi$ e scriveremo semplicemente: 
	\begin{equation}\label{key}
		V = \dfrac{1}{2}mgR(\theta^{2}+\varphi^{2})
	\end{equation}
	intendendo come coordinate gli scarti dai valori assunti nel minimo.
	Ci rimane da approssimare il potenziale generalizzato. Per farlo, sviluppiamo fino al primo ordine (così da avere forme quadratiche) i termini in $\theta$ e in $\varphi$ nel potenziale generalizzato. In particolare,
	\begin{equation}\label{key}
		\begin{aligned}
			\cos\varphi &\approx - \varphi
			\\
			\sin2\theta &\approx -2\theta \\
			\sin\varphi &\approx 1 
		\end{aligned}
	\end{equation}
	e diventa allora:
	\begin{equation}\label{key}
		V_{m} \approx  -\dfrac{qB_0}{2c}R^2(\dot{\theta}\varphi-\dot{\varphi}\theta)
	\end{equation}
	e la lagrangiana delle piccole oscillazioni diventa:
	\begin{equation}\label{key}
		\Lambda_{PO} = \dfrac{1}{2}mR^{2}(\dot{\theta}^{2}+\dot{\varphi}^{2}) - \dfrac{1}{2}mgR(\theta^{2}+\varphi^{2}) -\dfrac{qB_0}{2c}R^2(\dot{\theta}\varphi-\dot{\varphi}\theta)
	\end{equation}
	Se il termine magnetico non esistesse, otterremo una lagrangiana in forma già diagonale, cioè sovrapposizione di due lagrangiane indipendenti. In tal caso i moti su $\theta$ e su $\varphi$ sono perfettamente indipendenti e, perturbando inizialmente il sistema solo su $\theta$, mi aspetto che $\varphi$ rimanga inalterato, cioè che la guida non cominci ad oscillare se spingo il punto materiale (effettivamente ha senso, purché vi sia solo il peso a spingere verso il basso). Al contrario, forzando la guida ad oscillare solo su $\varphi$, il punto materiale rimarrebbe sempre a $\theta = \dfrac{3}{2}\pi$. Queste oscillazioni puramente gravitazionali avrebbero una frequenza pari a $\omega^2 = g/R$ e, calcolando i modi normali, otterremmo proprio i vettori ortogonali e linearmente indipendenti $(1,0), (0,1)$ che puntano nella solo direzione di $\theta$ o di $\varphi$.
	
	
	L'aggiunta del termine magnetico impedisce la diretta diagonalizzazione della lagrangiana e dunque genera effetti di precessione, cioè mischia i due moti su $\theta$ e $\varphi$ che non sono più indipendenti. Le frequenze delle piccole oscillazioni rimangono le stesse di prima, ma cambiano gli autovettori, che devono risolvere l'equazione in cui compare anche la matrice $\hat{A}$.
	\subsection{Esercizio: lagrangiana su superficie toroidale}
	Consideriamo una superficie toroidale che funga da guida per un punto materiale $m$. Usiamo le coordinate $\theta,\varphi$ per descrivere lo spazio delle configurazioni. La coordinata $\varphi$ rappresenta l'angolo che la sezione circolare sulla quale si trova istantaneamente il corpo individua rispetto all'asse x, mentre l'angolo $\theta$ individua l'angolo nella circonferenza stessa. Vale che $(\theta,\varphi) \in [0,2\pi]\times[0,2\pi]$. Notiamo, ad esempio, che questo spazio delle configurazioni coincide con quello del pendolo fisico: in effetti entrambi i casi hanno la stessa varietà, ma nel pendolo fisico la metrica indotta sul toro è legata all'energia cinetica, mentre in questa situazione (in cui il toro è un vincolo geometrico) la metrica è quella indotta dall'immersione in $\mathbb{R}^{3}$. Conviene parametrizzare la posizione di un punto così:
	\begin{equation}\label{key}
		\vec{x}
		\begin{pmatrix}
			(R+a\cos\theta)\cos\varphi \\
			(R+a\cos\theta)\sin\varphi \\
			a\sin\theta
		\end{pmatrix}
	\end{equation}
	dove $R$ è il raggio medio del toro e $a$ è il raggio interno. Calcoliamo la metrica indotta sul toro passando per le basi dello spazio tangente:
	$$
	\vec{e}_{\theta} = \dfrac{\partial \vec{x}}{\partial \theta} = (-a\sin\theta\cos\varphi, a\sin\theta\sin\varphi, a\cos\theta)
	$$
	$$
	\vec{e}_{\varphi} = \dfrac{\partial \vec{x}}{\partial \theta} = (-(R+a\cos\theta)\sin\varphi, (R+a\cos\theta)\cos\varphi, 0)
	$$
	\begin{equation}\label{key}
		G = 
		\begin{pmatrix}
			a^2 & 0 \\
			0 & (R+a\cos\theta)^2 
		\end{pmatrix}
	\end{equation}
	Allora la lagrangiana si scrive:
	\begin{equation}\label{key}
		\Lambda = \dfrac{1}{2}m(a^{2}\dot{\theta}^{2}+(R+a\cos\theta)^{2}\dot{\varphi}^{2}) - mga\sin\theta
	\end{equation}
	La coordinata $\varphi$ è ciclica, quindi un integrale primo del moto è:
	$$
	p_{\varphi} = m\dot{\varphi}(R+a\cos\theta)^{2}
	$$
	Allora l'energia del sistema può essere semplificata con l'equazione:
	$$
	E = \dfrac{1}{2}ma^2\dot{\theta}^{2} + \dfrac{p_{\varphi}^{2}}{2m(R+a\cos\theta)^2} + mga\sin\theta
	$$
	Esistono orbite circolari? Proviamo a cercare i minimi del potenziale efficace, dunque cerchiamo:
	$$
	\dfrac{\partial V_{eff}}{\partial \theta} = 0
	$$
	$$
	\dfrac{a\sin\theta p_{\varphi}^{2}}{2m(R+a\cos\theta)^3} + mga\cos\theta = 0
	$$
	\begin{equation}
		\dfrac{\sin\theta p_{\varphi}^{2}}{2m(R+a\cos\theta)^3} + mg\cos\theta = 0
		\label{eq13}
	\end{equation}
	Le soluzioni di questa equazioni sono difficili da valutare analiticamente. C'è un modo per capire sei valori di $\theta$ che risolvono questa equazione sono minimo o massimi? La derivata del potenziale efficace valutata in $\theta=0$ è positivo, per $\theta = \pi$ è negativo mentre ritorna positivo per $\theta = 2\pi$. In altre parole, per l'equazione (\ref{eq13}) devono esistere almeno due zeri, uno nell'intervallo $[0,\pi]$ e l'altro nell'intervallo $[\pi, 2\pi]$. Chiamiamo $\theta_1$ e $\theta_2$ questi due punti. Poiché le soluzioni di massimi/minimi devono alternarsi, allora necessariamente almeno uno dei due valori di $\theta_{1,2}$ è un minimo (e l'altro è un massimo). Per esserne sicuro, basterebbe valutare il segno di:
	$$
	\dfrac{\partial^{2}V_{eff}}{\partial \theta^{2}}
	$$
	e scopriamo che $\theta_1$ è instabile mentre $\theta_2$ è stabile. Per quanto riguarda $\varphi$? Poiché vale che:
	$$
	\dot{\varphi} = \dfrac{p_{\varphi}}{m(R+a\cos\theta)^2}
	$$
	se $\theta$ è costante, allora $\varphi$ varia linearmente con velocità angolare costante.
	\newpage
	
	\section{Dinamica del corpo rigido}
	Il corpo rigido è un'astrazione fisica utile per caratterizzare l'evoluzione dinamica dei corpi estesi la cui distanza fra punti interni rimane invariata nel corso del tempo. Si tratta dunque di un vincolo olonomo, che limita la varietà delle configurazioni 6-dimensionale a:
	$$
	\mathcal{M} = \mathbb{R}^{3}\times SO(3)
	$$
	Dove $SO(3)$ è lo spazio speciale ortogonale in cui vivono tutte le matrici ortogonali a determinante unitario che ben rappresentano le rotazione nello spazio tridimensionale.  In relatività, il corpo rigido è un'astrazione irrealizzabile poiché è impossibile che l'informazione del vincolo si propaghi istantaneamente. 
	
	
	Cominciamo allora a studiare un corpo rigido con punto fisso\footnote{La richiesta dell'esistenza di un punto fisso non è restrittiva. Basta infatti fattorizzare la lagrangiana del sistema in due, valutando il moto del centro di massa (che diventa il punto fisso $O$) e il moto relativo. Posso cioè mettermi nel sistema di riferimento in cui il centro di massa è istantaneamente fermo (e al massimo dovrò aggiungere forze fittizie se il centro di massa è in accelerazione)} $O$ dotandoci di due sistemi di riferimento diversi:
	\begin{itemize}
		\item Un sistema di riferimento inerziale $S$ fisso nello spazio centrato in $O$
		\item Un sistema di riferimento $S'$ non inerziale rotante solidale col corpo rigido centrato in $O$. In questo sistema di riferimento, il corpo è fermo per tutti i tempi.
	\end{itemize}
	Allora, detto $P$ un punto generico del corpo rigido, vale la relazione già studiata:
	$$
	\vec{X}(t) = R(t)\vec{x}(t)
	$$
	e ricordiamo che $\vec{X}$ descrive la posizione di un punto scritta nella base inerziale mentre $\vec{x}$ fa riferimento al sistema rotante. Sappiamo dalle relazioni di trasformazione delle velocità che:
	$$
	R^{T}\vec{V} = \dot{\vec{x}} +  \vec{\omega}\times\vec{x} 
	$$
	cioè la velocità assoluta di un corpo\footnote{Quella che conta ai fini dinamic} osservata dal sistema rotante è uguale alla velocità propria del sistema rotante scritta nelle coordinate rotanti più un termine aggiuntivo. Se analizziamo dei punti del corpo rigido stesso, allora $\dot{\vec{x}} = 0$ per definizione, cioè visto da $S'$, ogni punto del corpo è fermo. Dunque la velocità assoluta dei punti del corpo rigido nella base rotante è\footnote{Questa equazione dice qualcosa di molto importante. Il vettore $\vec{\omega}$, definito come $\dfrac{d\vec{\varphi}}{dt}$, rappresenta una rotazione \textit{attorno ad un asse}. Il fatto che una generica rotazione di un corpo con un punto fisso possa essere scritta attraverso $\vec{\omega}$ ci dice che il moto del corpo può essere rappresentato in un dato istante come una semplice rotazione infinitesima attorno ad un asse, detto \textit{asse di istanteanea rotazione}. L'asse di rotazione istanteanea passa chiaramente per il punto $O$ e la sua direzione è quella di $\vec{\omega}$. Quando il corpo si muove, variano in generale il modulo e la direzione di $\vec{\omega}$, dunque varia l'asse istantaneo di rotazione. Il vettore $\vec{\omega}$ può variare nel sistema rotante, chiaramente.}:
	\begin{equation}
		R^{T}\vec{V}_{P} = \vec{\omega}\times\vec{x}_{P}
		\label{TrasfVelo}
	\end{equation}
	Chiamiamo per comodità $\vec{v}_{P} = R^{T}\vec{V}_{p}$ (la velocità assoluta scritta nel sistema rotante). Ora scrivo l'energia cinetica nel sistema del corpo:
	$$
	T = \dfrac{1}{2}\int_{K}(v_{p})^{2}\rho dx_{p} = \dfrac{1}{2}\int_{K}(\vec{\omega}\times\vec{x}_{P})^{2}\rho dx_{p}
	$$
	Il modulo quadro della velocità vale:
	$$
	(\vec{v}_{p})^{2} = (\vec{\omega}\times\vec{x}_{p})^2 = (\vec{\omega}\times\vec{x}_{p})\cdot(\vec{\omega}\times\vec{x}_{p}) = \vec{\omega}\cdot(\vec{x}_{p}\times(\vec{\omega}\times\vec{x}_{p}))
	$$
	quindi la cinetica diventa:
	\begin{equation}
		T = \dfrac{1}{2}\int_{K}\vec{\omega}\cdot(\vec{x}_{p}\times(\vec{\omega}\times\vec{x}_{p}))\rho dx_{p} = \dfrac{1}{2}\vec{\omega}\cdot\int_{K}\vec{x}_{p}\times(\vec{\omega}\times\vec{x}_{p})\rho dx_{p}
	\end{equation}
	Riconosco nell'integrale il momento angolare (rispetto al punto fisso $O$):
	\begin{equation}
		\vec{L} = \int_{K} \vec{x}_{p}\times(\rho \vec{v}_{p}dx) =  \int_{K}(\vec{x}_{p}\times(\vec{\omega}\times\vec{x}_{p}))\rho dx
		\label{MomAng}
	\end{equation}
	Questa definizione del momento angolare mette in luce una proprietà interessante. Il momento angolare, infatti, è lineare in $\vec{\omega}$, nel senso che:
	$$
	\vec{L}(\alpha\vec{\omega}_{1} + \beta\vec{\omega}_{2}) = \alpha \vec{L}(\omega_1) + \beta \vec{L}(\omega_2)
	$$
	Allora scrivo semplicemente:
	\begin{equation}
		\vec{L} = I\vec{\omega}
		\label{TrasfLin}
	\end{equation}
	\subsection{Tensore d'inerzia}
	Chiamo genericamente $I$ la trasformazione lineare che porta $\vec{\omega}$ a $\vec{L}$ in (\ref{TrasfLin}). In fondo $I$ dipende solo dalle coordinate $\vec{x}_{p}$ che sono chiaramente costanti (poiché riferite al sistema solidale al corpo rigido). Quindi tale relazione vale nel sistema rotante, mi consente di trovare $\vec{L}$ nel sistema rotante e vale \textbf{solo} nel sistema rotante (solo lì $I$ è costante e lineare). Dunque l'energia cinetica diventa:
	\begin{equation}\label{key}
		T = \dfrac{1}{2}\vec{\omega}I\vec{\omega}
	\end{equation}
	Torniamo alla (\ref{MomAng}). Applicando la regola bac-cab, si ottiene:
	\begin{equation}
		\vec{L} = \int_{K} \vec{x}_{p}\times(\rho \vec{v}_{p}dx) =  \int_{K}(\vec{x}_{p}\times(\vec{\omega}\times\vec{x}_{p}))\rho dx
		= \int_{K}(\vec{\omega}(x_{p}^{2}) - \vec{x}_{p}(\vec{x}_{p}\cdot\vec{\omega}))\rho dx
	\end{equation}
	Proiettando, ad esempio, lungo la componente $i$:
	\begin{equation}
		\begin{aligned}
			L_i &=  \int_{K}(\omega_{i}(x_{j}x_{j}) - x_{i}(x_{j}\omega_j))\rho dx \\
			L_i &=  \int_{K}\omega_j (\delta_{ij}(x_{j}x_{j}) - x_{i}x_{j})\rho dx  \\
			L_i &=  \omega_j \int_{K} (\delta_{ij}x_{j}x_{j} - x_{i}x_{j})\rho dx 
		\end{aligned}
	\end{equation}
	Ho trovato dunque l'espressione per gli elementi matriciale del tensore di inerzia:
	\begin{equation}\label{key}
		I_{ij} = \int_{K} (\delta_{ij}x_{P}^{2} - x_{i}x_{j})\rho dx  
	\end{equation}
	Ad esempio, in coordinate cartesiane, ottengo che:
	\begin{equation}\label{key}
		\begin{cases}
			I_{xx} = \int_{K}(x^{2}+y^{2}+z^{2}-x^{2})\rho dxdydz = \int_{K}(y^{2}+z^{2})\rho dxdydz \\
			I_{yy} = \int_{K}(x^{2}+y^{2}+z^{2}-y^{2})\rho dxdydz = \int_{K}(x^{2}+z^{2})\rho dxdydz \\
			I_{zz} = \int_{K}(x^{2}+y^{2}+z^{2}-z^{2})\rho dxdydz = \int_{K}(x^{2}+y^{2})\rho dxdydz
		\end{cases}
	\end{equation}
	Questi risultati sono equivalenti al momento d'inerzia rispetto ad un asse. Questo è sempre vero: gli elementi diagonali del tensore d'inerzia sono i momenti di inerzia rispetto agli assi del sistema rotante. Alcuni esempi di elementi antidiagonali sono:
	\begin{equation}\label{key}
		\begin{cases}
			I_{xy} = \int_{K}(-xy)\rho dxdydz  \\
			I_{xz} = \int_{K}(-xz)\rho dxdydz \\
			I_{zy} = \int_{K}(-zy)\rho dxdydz 
		\end{cases}
	\end{equation}
	Chiaramente il tensore d'inerzia è simmetrico, poiché $I_{ij} = I_{ji}$. Si noti anche che il tensore di inerzia dipende dal punto fisso (poiché dipenda da $\vec{x}_p$).
	
	Se il corpo rigido è costituito da un solo punto (dunque ricadiamo nella descrizione del punto materiale), la relazione fra momento angolare e velocità angolare è semplice poiché il tensore di inerzia è proporzionale all'identità:
	
	$$
	\vec{L} = I\vec{\omega}^{2} = mR^{2} \vec{\omega}^{2}
	$$
	e vale che $\vec{L} \parallel \vec{\omega}$. Questo però non è sempre vero perché non sempre l'operatore I, detto \textit{tensore di inerzia}, è generalmente diverso da un semplice scalare.
	\subsection{Momento di inerzia}
	Ipotizziamo che il corpo $K$ ruoti con velocità angolare rispetto ad un asse fisso $\hat{\omega}$. Nel caso precedente, la rotazione era libera e richiedeva solo l'esistenza di un punto fisso. Ora invece ci concentriamo su rotazioni attorno ad un asse: l'asse di rotazione istanteaneo diventa costanteg. Vien bene definire allora il momento di inerzia rispetto all'asse di rotazione come avevamo fatto sopra:
	$$
	I_{\omega} = \int_{K}d^{2}\rho dx
	$$
	dove $d$ è la distanza di un punto del corpo rigido rispetto all'asse. Se possediamo l'informazione del tensore di inerzia rispetto ad una generica terna cartesiana $xyz$ e vogliamo calcolare il momento di inerzia rispetto ad un asse $\hat{\omega}$, basta operare:
	$$
	I_{\omega} = \hat{\omega}I\hat{\omega}
	$$
	e chiaramente otteniamo che gli elementi diagonali del tensore di inerzia sono i momenti di inerzia rispetto agli assi cartesiani. D'altronde l'energia cinetica del corpo in rotazione attorno ad un asse può essere riscritta come:
	\begin{equation}
		T = \dfrac{1}{2}I_{\omega}\omega^{2}
		\label{MomInerzia}
	\end{equation}
	ed è facile farlo vedere. Sfruttando il tensore di inerzia (definito rispetto ad una terna cartesiana solidale col corpo), avremo che:
	$$
	T = \dfrac{1}{2}\vec{\omega}I\vec{\omega}
	$$
	Se $\vec{\omega}$ è costante, $\vec{\omega}=\hat{\omega}\omega$ e :
	$$
	T = \dfrac{1}{2}\omega^{2}\hat{\omega}I\hat{\omega}
	$$
	Confrontando questa con la (\ref{MomInerzia}), dovrà per l'appunto essere:
	$$
	I_{\omega} = \hat{\omega}I\hat{\omega}
	$$
	Questo però non vuol dire che $\vec{L}$ sia necessariamente parallelo a $\hat{\omega}$, poiché in generale:
	$$
	\vec{L} = I\vec{\omega}
	$$
	e $I$ è individuato una volta stabilito il sistema di riferimento rotante.
	
	
	\subsubsection{Teorema di Steiner}
	Sia $K$ un corpo rigido. Se conosco il momento di inerzia di $K$ rispetto ad un asse $\hat{\omega}$ passante per il centro di massa, posso calcolare il momento di inerzia rispetto ad un asse parallelo a $\hat{\omega}$ distante $d$ dal centro di massa come:
	$$
	I_{\omega} = I_{\omega, CM} + Md^{2}
	$$
	\subsection{Diagonalizzazione del tensore di inerzia}
	Ripetiamo quanto appena scoperto. Dato un sistema di riferimento rotante solidale al corpo rigido $K$ con punto fisso, posso definire una matrice covariante detta \textit{tensore di inerzia} i cui elementi sono:
	$$
	I_{ij} = \int_{K}(\delta_{ij}x_j x_j - x_i x_j)\rho dx
	$$
	Il tensore di inerzia mi consente di calcolare l'energia cinetica di $K$ nel sistema rotante:
	$$
	T = \dfrac{1}{2}\vec{\omega}I\vec{\omega}
	$$
	e il momento angolare:
	$$
	\vec{L} = I\vec{\omega}
	$$
	Il tensore di inerzia va calcolato nel sistema solidale al corpo e, in tal caso, è una sola proprietà della geometria del corpo e del punto fisso.
	Dalla definizione, ricaviamo che $I$ è un tensore covariante simmetrico e definito positivo. Perciò, applicando il teorema spettrale, possiamo trovare una terna cartesiana ortogonale (sempre solidale col corpo perché in rotazione $\vec{\omega}$) in cui il tensore abbia forma diagonale:
	\begin{equation}\label{key}
		I =
		\begin{pmatrix}
			I_{x} & 0 & 0 \\
			0 & I_{y} & 0 \\
			0 & 0 & I_{z} 
		\end{pmatrix}
	\end{equation}
	Questi assi del sistema rotante sono chiamati \textit{assi principali} del corpo e, in questa base, l'energia cinetica si scrive agevolmente come:
	$$
	T = \dfrac{1}{2}(I_{x}\omega_{x}^{2}+I_{y}\omega_{y}^{2}+I_{z}\omega_{z}^{2})
	$$ 
	dove $\vec{\Omega}$ viene espressa nella base rotante. Non solo: se prendo $\hat{\omega}$ e lo metto su di uno di questi assi, cioè imprimo al corpo una rotazione attorno ad uno dei suoi assi principali di inerzia (ad esempio l'asse $x$), allora $\vec{\omega} = (\omega,0,0)$ e:
	$$
	\vec{L} = I\vec{\omega} = (I_{x}\omega,0,0) = I_{x}\vec\omega
	$$
	cioè il momento angolare è parallelo al vettore di velocità angolora (e dunque punta nell'asse principale di rotazione). Questa proprietà non era generalmente valida se $\hat{\omega}$ non è parallelo ad un asse principale. In tal caso, infatti, detto $\hat{\omega} = (\omega_1, \omega_2, \omega_3)$ nella base degli assi principali, avremo generalmente:
	$$
	\vec{L} = I\vec{\omega} = (I_{x}\omega_1,I_y \omega_2, I_z \omega_3)
	$$
	
	Inoltre, per i momenti di inerzia principali vale la relazione triangolare:
	$$
	I_x+I_y \geq I_z
	$$
	e analogamente per gli altri assi. Insomma, il valore di uno dei momenti principali d'inerzia non può superare la somma degli altri due
	\subsection{Teorema di König e corpo rigido libero}
	Consideriamo un corpo rigido che si muove nello spazio, senza imporre punti fissi vincolati. Come valutiamo la sua energia cinetica? Nelle sezioni precedenti avevamo assunto che esistesse un punto fisso, cioè fermo rispetto al sistema inerziale. Se invece il corpo rigido non solo è in rotazione ma sta anche traslando, allora il punto fisso potrebbe non esistere (rispetto ad un sistema inerziale). Tuttavia il moto complicato del corpo rigido può sempre essere fattorizzato nel moto del centro di massa e nella rotazione attorno a esso. Se non ho punti fissi dati da vincoli fisici, è comodo considerare il sistema di riferimento in cui il centro di massa è fermo (e vedremo perché) di fatto eleggendo tale punto come fisso. L'energia cinetica del corpo rigido allora si scriverà come:
	\begin{equation}
		T = T_{CM} + \dfrac{1}{2}MV_{CM}^{2}
		\label{Konig}
	\end{equation}
	dove il primo termine è l'energia cinetica di rotazione vista nel sistema di riferimento in cui il centro di massa è un punto fisso (dunque energia di rotazione attorno al centro di massa). Il secondo termine è invece l'energia cinetica del centro di massa, come se tutta la massa del corpo fosse ivi concentrata. 
	Vediamo perché è vera la (\ref{Konig}). Prendiamo al solito un sistema di riferimento inerziale fisso e un sistema di riferimento centrato nel centro di massa del corpo solidale ad esso. La velocità assoluta di un punto è (intendendo tutti questi vettore come scritti nella base rotante):
	$$
	(R^{T}\vec{V}_{ass}) = \vec{v} = \vec{V}_{cm} + \vec{\omega}\times\vec{x}
	$$
	ed è la somma della velocità con cui si muove il centro di massa e della velocità di rotazione rispetto al centro di massa. Allora l'energia cinetica si costruisce come integrale di contributi del tipo:
	$$
	T = \int \dfrac{1}{2}\rho dx (\vec{V}_{cm} + \vec{\omega}\times\vec{x})^{2} = \int \dfrac{1}{2}\rho dx (V_{cm})^{2} + \int \rho dx \vec{V}_{cm}\cdot(\vec{\omega}\times\vec{x}) + \dfrac{1}{2}\int \rho dx (\vec\omega \times \vec{x})^{2} =
	$$
	$$
	= \dfrac{1}{2}MV_{CM}^{2} + \dfrac{1}{2}\vec{V}_{cm}\cdot\int\rho(\vec\omega \times\vec{x}) dx+ \dfrac{1}{2}\int \rho dx (\vec\omega \times \vec{x})^{2}
	$$
	Il termine del doppio prodotto è, ciclando i termini del prodotto misto:
	$$
	\dfrac{1}{2}\vec{V}_{cm}\cdot\int(\rho\vec\omega \times\vec{x}) = \dfrac{1}{2} \int\rho\vec{x}\cdot(\vec\omega \times \vec{V}_{CM}) = (\vec\omega \times \vec{V}_{CM})\int \rho\vec{x} dx = 0
	$$
	perché $\int \rho\vec{x} dx = 0$ se $\vec{x}$ è riferito al centro di massa (equivale a calcolare la posizione del centro di massa nel suo stesso sistema di riferimento). Allora l'energia cinetica diventa semplicemente:
	$$
	T = \dfrac{1}{2}MV_{CM}^{2} + \dfrac{1}{2}\int \rho dx (\vec\omega \times \vec{x})^{2}
	$$
	Il termine a destra è uguale a quello valutato nelle prime pagine di questa sezione e, introducendo il tensore di inerzia rispetto al centro di massa, avremo finalmente che:
	\begin{equation}\label{key}
		T = \dfrac{1}{2}MV_{CM}^{2} + \dfrac{1}{2}\vec{\omega}I_{CM}\vec\omega
	\end{equation}
	Questo è il teorema di König, utile per calcolare l'energia cinetica di un corpo rigido sfruttando le proprietà del centro di massa. Il tensore di inerzia va chiaramente riferimento al centro di massa (e magari è bene orientarlo nelle direzioni degli assi principali//orientato in maniera parallela al sistema inerziale).
	\subsection{Ellissoide di inerzia}
	Sia $K$ un corpo rigido. Esiste un metodo molto efficace e semplice per comprendere la dinamica rotazionale di un corpo rigido arbitrariamente complicato che passa per il concetto di \textit{ellissoide di inerzia}. Infatti, associamo ad ogni corpo rigido $K$ la forma quadratica:
	$$
	\vec{x}I\vec{x} = 1
	$$
	dove $\vec{x}$ è un vettore di $\mathbb{R}^{3}$ (e, di nuovo, deve esistere un punto fisso, così che $I$ sia ben definito). Tale equazione identifica nello spazio un ellissoide generalmente ruotato rispetto agli assi del sistema solidale al corpo $K$. Se scelgo il sistema di assi principali, allora la forma quadratica è un ellissoide "diritto"\footnote{L'ellissoide è univocamente definito una volta stabilito il tensore di inerzia, quindi è sempre lo stesso, anche se cambio l'orientamente degli assi rotanti. Semplicemente se mi metto negli assi principali, l'ellissoide appare lungo gli assi stessi, mentre rispetto a qualsiasi altro orientamento degli assi (purché il punto fisso rimanga lo stesso) l'ellissoide appare ruotato.} dato dalla equazione:
	$$
	x^{2}I_{x} + y^{2}I_{y}+ z^{2}I_{z} = 1
	$$
	$$
	\dfrac{x^{2}}{1/I_x} + \dfrac{y^{2}}{1/I_y} + \dfrac{z^{2}}{1/I_z} = 1
	$$
	$$
	\dfrac{x^{2}}{1/I_x} + \dfrac{y^{2}}{1/I_y} + \dfrac{z^{2}}{1/I_z} = 1
	$$
	che per l'appunto rappresenta un ellissoide con semiassi:
	$$
	a_{x} = \dfrac{1}{\sqrt{I_x}} \quad a_{y} = \dfrac{1}{\sqrt{I_y}} \quad a_{z} = \dfrac{1}{\sqrt{I_z}}
	$$
	Dunque ad ogni corpo rigido posso associare un ellissoide ed è possibile dimostrare che tale figura geometrica riassume perfettamente tutte le proprietà dinamiche del corpo in esame. Posso, cioè, ridurre il corpo $K$ ad un ellissoide e studiare l'evoluzione di questa particolare figura, per poi ritornare in ultimo al corpo rigido. 
	
	
	
	Vediamo come può tornare utile questa proprietà dei corpi rigidi. Prendiamo un cubo e studiamone il tensore di inerzia ponendo il centro del cubo come punto fisso. Il cubo sarà rappresentabile da un ellissoide. Ma il cubo gode di simmetrie per rotazioni di $\pi/2$ attorno a tutti e tre gli assi passanti per il centro. Questa proprietà deve valere anche per l'ellissoide che rappresenta il cubo, cioè se lo ruoto di $\pi/2$ rispetto all'asse $x,y,z$, l'ellissoide rimane invariato. L'unico modo per cui ciò può accadere è che l'ellissoide si riduca ad una sfera. Di conseguenza, il cubo ha, nel sistema dei suoi assi principali, tutti e tre i momenti di inerzia perfettamente uguali. Il cubo è, ai fini dinamici, perfettamente assimilabile ad una sfera.\footnote{Questo vale solo se il punto fisso $O$ è posto nel centro del cubo. Così facendo, il cubo gode davvero di quelle simmetrie discrete. Se il punto fisso è diverso dal centro di massa, l'ellissoide rappresentativo non è più una perfetta sfera.} In generale, infatti, ogni asse di simmetria di un corpo è anche asse principale per quest'ultimo.
	\subsection{Equazioni di Eulero per il corpo rigido libero}
	Ritorniamo al caso di un corpo rigido con un punto fisso $O$. Allora so che:
	$$
	\vec{L} = I_{O}\vec\omega
	$$
	dove, ricordiamolo, $\vec{L}$ è il momento angolare calcolato nel sistema rotante (e non nel sistema inerziale!). Nel sistema degli assi principali, la relazione di sopra si semplifica e diventa:
	$$
	(L_x,L_y,L_z) = (I_x\omega_x,I_y\omega_y,,I_z\omega_z)
	$$
	Studiamo ora il moto del corpo rigido libero, sul quale, cioè, non sono applicate forze o momenti torcenti esterni. In tal caso, mi aspetto che il momento angolare \textbf{rispetto al sistema inerziale} $\vec{l}$ sia conservato, cioè:
	$$
	\dfrac{d}{dt}\vec{l} = 0
	$$
	In questo caso, $\vec{l}$ è il vettore del momento angolare assoluto. Questo chiaramente si conserva, ma solo nel sistema inerziale (un po' come per le forze. In sistemi inerziali, l'assenza di forze implica, ad esempio, la conservazione della quantità di moto. Se mi metto in un sistema accelerato, la quantità di moto non si conserva più poiché vedo apparire una forza d'inerzia. Le leggi della meccanica valgano nei sistemi inerziali, sempre). Vorrei dunque trovare una connessione fra $\vec{l}$ e $\vec{L}$. Ricordando che:
	$$
	R^{T}\dot{\vec{X}} = \vec{\omega}\times\vec{x} + \dot{\vec{x}}
	$$
	possiamo affermare la medesima legge di trasformazione anche per il momento angolare ($\vec{x} \rightarrow \vec{L}, \vec{X}\rightarrow\vec{l}$):
	\begin{equation}\label{key}
		R^{T}\dfrac{d}{dt}\vec{l} = \vec{\omega}\times\vec{L} + \dot{\vec{L}} 
	\end{equation}
	Ma:
	$$
	\dfrac{d}{dt}\vec{l} = 0
	$$
	e quindi otteniamo l'\textit{equazione cardinale} della meccanica scritta nel corpo:
	\begin{equation}
		\dfrac{d}{dt}\vec{L} = -\vec{\omega}\times\vec{L}
		\label{EqCard}
	\end{equation}
	dove, lo ricordiamo, tutte le quantità sono viste nel sistema del corpo. Notiamo che, in tale sistema. $\vec{L}$ non è conservato, ma questo non costituisce un problema poiché il sistema non è inerziale. Se il corpo rigido non fosse libero ma animato da un momento torcente che, visto dal sistema del corpo è $\vec{\tau}$, allora nel sistema inerziale scriveremo:
	$$
	\dfrac{d}{dt}\vec{l} = R\vec\tau
	$$
	inserendo nell'equazione di trasformazione per $\vec{L}$, si ottiene l'equazione cardinale generalizzata:
	\begin{equation}
		\dfrac{d}{dt}\vec{L} = \vec{\tau} - \vec{\omega}\times\vec{L}
	\end{equation}
	Il termine aggiuntivo, $-\vec{\omega}\times\vec{L}$ rappresenta dunque una sorta di momento torcente fittizio la cui natura è inerziale che bisogna includere nell'equazione della dinamica quando si studia un sistema da un sistema di riferimento non inerziale.
	
	
	Ricordando che $\vec{L} = I\vec{\omega}$, allora $\vec{\omega} = I^{-1}\vec{L}$ e la (\ref{EqCard}) diventa:
	\begin{equation}
		\dfrac{d}{dt}\vec{L} = -I^{-1}\vec{L}\times\vec{L}
		\label{EqCard}
	\end{equation}
	Nel sistema non inerziale degli assi principali,
	\begin{equation}\label{key}
		I^{-1} = 
		\begin{pmatrix}
			\dfrac{1}{I_{x}} & 0 & 0 \\
			0 & \dfrac{1}{I_y} & 0 \\
			0 & 0 & \dfrac{1}{I_z} \\
		\end{pmatrix}
	\end{equation}
	e l'equazione cardinale si riduce al sistema:
	\begin{equation}
		\begin{cases}
			\dfrac{dL_x}{dt} = \Bigl(\dfrac{1}{I_z}-\dfrac{1}{I_y}\Bigl) L_yL_z \\
			\dfrac{dL_y}{dt} = \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl) L_zL_x \\
			\dfrac{dL_z}{dt} = \Bigl(\dfrac{1}{I_y}-\dfrac{1}{I_x}\Bigl) L_xL_y
		\end{cases}
		\label{EqEulero}
	\end{equation}
	Chiamate anche \textit{equazioni di Eulero} per il corpo rigido. La risoluzione di questo sistema di equazioni differenziali consente di ricavare la legge $\vec{L}(t)$, essendo i momenti di inerzia chiaramente costanti nel sistema rotante.\footnote{Ok, posso trovare $\vec{L}$, ma come ricavo la matrice $R$, che è quella che mi interessa? Potrei ricavarla cercando $R(t)$ tale che $\vec{l} = R(t)\vec{L}$, ma noi non ce ne occuperemo.}
	\subsection{Soluzione delle equazioni di Eulero}
	Le equazioni di Eulero (\ref{EqEulero}) sono abbastanza complicate da risolvere analiticamente. Tuttavia esiste un metodo più veloce per avere almeno un'idea qualitativa delle soluzioni di tale sistema differenziale. Infatti, poiché $\vec{l}$ è conservato, allora anche il suo modulo si conserva nel tempo. Ma il modulo di un vettore è uno scalare per rotazione degli assi, e dunque $|L(t)| = |l|$. Necessariamente, allora, la quantità:
	$$
	|L|^{2} = L_x^2 + L_y^2 +L_z^2 = const
	$$
	rappresenta un integrale primo del moto. L'altro integrale primo è l'energia, che nel sistema solidale al corpo è:
	$$
	E = T = \dfrac{1}{2}\vec{\omega}I\vec{\omega} = \dfrac{1}{2}\vec{\omega}\cdot\vec{L} = \dfrac{1}{2}\Bigl(\dfrac{L_x^2}{I_x} +\dfrac{L_y^2}{I_y}+\dfrac{L_z^2}{I_z}\Bigl) = const
	$$
	La conservazione del momento angolare descrive una sfera nello spazio delle configurazioni $(L_x,L_y,L_z)$ mentre la conservazione dell'energia impone un ellissoide nello stesso spazio: le soluzioni del sistema stanno dunque nell'intersezioni fra tale sfera e l'ellissoide.
	DA FINIRE
	\subsection{Stabilità degli assi principali}
	I punti di equilibrio di un corpo rigido libero (con tutti i momenti di inerzia diversi) sono quelli per cui il momento angolare è inizialmente lungo uno degli assi principali di inerzia:
	$$
	\vec{L} = (L_x,0,0), (0,L_y,0), (0,0,L_z)
	$$
	e basta verificarlo tramite le (\ref{EqEulero}). Così facendo, il momento angolare $\vec{L}$ rimane sempre costante. Questo vuol dire, nel sistema inerziale, che il corpo rigido rimane indefinitamente in rotazione attorno al suo asse principale, senza iniziare altre rotazioni.
	
	Che tipo di equilibrio è? Studio la stabilità dei punti di equilibrio appena individuati. Supponiamo che $I_x<I_y<I_z$.
	Sia 
	$$
	\vec{L} = (L_x^0 + \varepsilon\delta L_x, \varepsilon\delta L_y,\varepsilon\delta L_z)
	$$
	una minima variazione dal valore di equilibrio sull'asse di inerzia $x$. Sostituisco tale formula nelle equazioni di Eulero conservando fino al primo ordine di $\varepsilon$
	\begin{equation}\label{key}
		\begin{cases}
			\dfrac{d}{dt}L_x = \Bigl(\dfrac{1}{I_z}-\dfrac{1}{I_y}\Bigl) \varepsilon^{2}\delta L_y\delta L_z \\
			\dfrac{d}{dt}L_y =\varepsilon \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl)(L_x+\varepsilon\delta L_x)\delta L_z \\
			\dfrac{d}{dt}L_z = \Bigl(\dfrac{1}{I_y}-\dfrac{1}{I_x}\Bigl)(L_x+\varepsilon\delta L_x)\delta L_y
		\end{cases}
	\end{equation}
	\begin{equation}\label{key}
		\begin{cases}
			\varepsilon\dfrac{d}{dt}\delta L_x =O(\varepsilon^2)\\
			\varepsilon\dfrac{d}{dt}\delta L_y =\varepsilon \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl)L_x^{0}\delta L_z + O(\varepsilon^2) \\
			\varepsilon \dfrac{d}{dt}\delta L_z =\varepsilon \Bigl(\dfrac{1}{I_y}-\dfrac{1}{I_x}\Bigl)L_x^{0}\delta L_y + O(\varepsilon^2)
		\end{cases}
	\end{equation}	
	\begin{equation}\label{key}
		\begin{cases}
			\dfrac{d}{dt}\delta L_x =O(\varepsilon)\\
			\dfrac{d}{dt}\delta L_y = \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl)L_x^{0}\delta L_z + O(\varepsilon) \\
			\dfrac{d}{dt}\delta L_z = \Bigl(\dfrac{1}{I_y}-\dfrac{1}{I_x}\Bigl)L_x^{0}\delta L_y + O(\varepsilon)
		\end{cases}
	\end{equation}	
	Definiamo allora per comodità:
	\begin{equation}\label{key}
		a = \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl) > 0 
	\end{equation}
	\begin{equation*}\label{key}
		b =- \Bigl(\dfrac{1}{I_y}-\dfrac{1}{I_x}\Bigl) > 0
	\end{equation*}
	e dunque, troncando i termini al primo ordine in $\varepsilon$
	\begin{equation}\label{key}
		\begin{cases}
			\dfrac{d}{dt}\delta L_x =0\\
			\dfrac{d}{dt}\delta L_y = aL_x^{0}\delta L_z \\
			\dfrac{d}{dt}\delta L_z =- bL_x^{0}\delta L_y
		\end{cases}
	\end{equation}
	da cui si ricava facilmente che, ad esempio,
	\begin{equation}\label{key}
		\dfrac{d^2}{dt^2}\delta L_y = -ab (L_x^{0})^2\delta L_y
	\end{equation}
	\begin{equation}\label{key}
		\dfrac{d^2}{dt^2}\delta L_z = -ab (L_x^{0})^2\delta L_z
	\end{equation}
	Queste sono le equazioni di un oscillatore armonico e, dunque, il punto di equilibrio è stabile. Una piccola perturbazione lungo i due assi non rotanti, dunque, genere piccole perturbazioni armoniche e non fa divergere indefinitamente il moto. Potremmo fare le stesse considerazioni anche per rotazioni attorno agli altri assi e otterremmo un risultato fondamentale: \textit{la rotazione attorno ai due assi di inerzia minore e maggiore è stabile, mentre la rotazione attorno all'asse intermedio è instabile} (teorema dell'asse intermedio o della racchetta da tennis).
	\subsection{Descrizione del moto secondo Poinsot}
	Le equazioni di Eulero permettono, in teoria, di risolvere le variabili cinematiche del corpo nel sistema solidal a quest'ultimo (ottengo cioè $\vec{L}$ e $\vec{\omega}$). Come faccio a visualizzare il moto del corpo nello spazio inerziale? Dovrei ottenere la matrice $R$, che identifica la rotazione istantanea degli assi non inerziali (possibilmente principali). Esiste però un metodo alternativo per raffigurarsi la dinamica di un corpo rigido nello spazio inerziale senza risolvere per $R$.
	
	Riprendiamo la dinamica del corpo rigido schematizzandola col suo ellissoide di inerzia $\mathcal{I}\in S'$:
	$$
	\vec{x}I\vec{x} = 1
	$$
	con $\vec{x}\in S'$. Nel sistema degli assi principali, la forma quadratica diventa semplice:
	$$
	I_x x^2 + I_y y^2 + I_z z^2  = 1
	$$
	Proviamo a calcolarci la normale a tale varietà in $S'$:
	$$
	\hat{n} = grad\>\mathcal{I} = (2I_x x,2I_y y,2I_z z)
	$$
	Consideriamo ora il piano $\pi$ perpendicolare a $\vec{l}$ (cioè il momento angolare nel sistema inerziale, che tanto è costante se il corpo è libero). Anche l'energia è chiaramente una costante del problema e, dunque, definendo il vettore:
	$\vec{x}_{\omega} = \dfrac{\vec{\omega}}{\sqrt{2E}} $, questo sicuramente appartiene all'ellissoide:
	$$
	\vec{x}_{\omega}I\vec{x}_{\omega} = \dfrac{1}{2E} \vec{\omega}I\vec{\omega} = \dfrac{1}{E} \dfrac{1}{2}\vec{\omega}\cdot\vec{L} = 1
	$$
	e chiaramente $\vec{x}_{\omega} \parallel \vec{\omega}$. La normale all'ellissoide nel punto $\vec{x}_{\omega}$ vale:
	$$
	\hat{n}_{\omega} =\dfrac{1}{\sqrt{2E}} (2I_x \omega_{x},2I_y \omega_y,2I_z \omega_z) = \dfrac{2}{\sqrt{2E}}\vec{L}
	$$
	Naturalmente $\hat{n}_{\omega}$, dunque per tornare nel sistema inerziale:
	$$
	\hat{N}_{\omega} = R\hat{n}_{\omega} =\sqrt{\dfrac{2}{E}}R\vec{L} = \sqrt{\dfrac{2}{E}}\vec{l}
	$$
	essendo l'energia uno scalare la trasformazione $R$ non la modifica. Abbiamo dunque ottenuto il seguente risultato: se prendo il punto $R\vec{x}_{\omega}$ dell'ellissoide, questo naturalmente varierà nel tempo (invece $\vec{x}_{\omega}$) no perché appartiene allo spazio solidale $S'$) ma in tale punto l'ellissoide ha normale che è collineare con $\vec{l}$. Tuttavia $\vec{l}$ è costante e, dunque, esiste un piano $\pi \in S$ costante nel tempo sul quale l'ellissoide è sempre tangente, per tutti i tempi, nonostante si muova. Il punto di tangenza si trova sull'asse istantaneo di rotazione (perché proporzionale a $\vec{\omega}$) e dunque è istantaneamente fermo. In altre parole, visto da $S$, l'ellissoide di inerzia sta rotolando senza strisciare sul piano costante $\pi$. Per altro, detto $O$ il punto fisso del corpo rigido, la distanza di $O$ dal piano $\pi$ è sempre costante essendo questa pari a:
	$$
	OH = \dfrac{\vec{L}}{|\vec{L}|}\cdot\vec{x}_{\omega} = \dfrac{\vec{L}\cdot\vec{\omega}}{L\sqrt{2E}} = \dfrac{\sqrt{2E}}{L} = const
	$$
	Questo è proprio l'enunciato del teorema di Poinsot. L'ellissoide di inerzia rotola senza strisciare sul piano ortogonale a $\vec{l}$ e tangente ad esso.
	\subsection{Moto della trottola lagrangiana}
	Analizziamo la dinamica di un sistema per cui vale:
	$$
	I_x = I_y \neq I_z
	$$
	Un esempio classico di un corpo siffatto è la trottola, per la quale esiste una simmetria fra asse principale $x \mbox{ e }y$. In questo caso, le equazioni di Eulero si riducono a:
	\begin{equation}
		\begin{cases}
			\dfrac{dL_x}{dt} = \Bigl(\dfrac{1}{I_z}-\dfrac{1}{I_x}\Bigl) L_yL_z \\
			\dfrac{dL_y}{dt} = \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl) L_zL_x \\
			\dfrac{dL_z}{dt} = 0
		\end{cases}
	\end{equation}
	Allora $L_z$ è un integrale primo del moto. Chiamando:
	$$
	\omega = \Bigl(\dfrac{1}{I_x}-\dfrac{1}{I_z}\Bigl)
	$$
	e assumendo $I_z > I_x$, allora $\omega > 0$ e:
	\begin{equation}
		\begin{cases}
			\dfrac{dL_x}{dt} = -\omega L_yL_z \\
			
			\dfrac{dL_y}{dt} = \omega L_zL_x  \\
			
			L_z (t) = L_z^{0}
		\end{cases}
	\end{equation}
	equivalente alle equazioni caratteristiche di un rotatore: 
	\begin{equation}
		\begin{cases}
			\dfrac{d^2L_x}{dt^2} = -\omega^2 L_{z}^{0} L_x \\
			\dfrac{d^2L_y}{dt^2} = -\omega^2 L_{z}^{0} L_y \\ 
		\end{cases}
	\end{equation}
	\begin{equation}
		\begin{cases}
			L_x(t) = L_x^0 \cos(\omega L_z^0 t) - L_y^0 \sin(\omega L_z^0 t)\\
			L_y(t) = L_x^0 \sin(\omega L_z^0 t) + L_y^0 \cos(\omega L_z^0 t) \\ 
		\end{cases}
	\end{equation}
	cioè, nel sistema solidale alla trottola, il momento angolare lungo $z$ rimane invariato mentre i momenti angolari lungo gli altri due assi variano armonicamente. Tale moto combinato produce il classico effetto di precessione del vettore del momento angolare attorno all'asse $z$
	
	Per visualizzare il moto della trottola appena descritto nello spazio inerziale possiamo avvalerci della rappresentazione alla Poinsot. 
	
	Se invece vogliamo studiare la dinamica di una trottola in un campo di forze gravitazionale con punto fisso, non possiamo più usare le equazioni di Eulero (valide se il corpo è libero). Proviamo a costruire la lagrangiana del sistema cercando in primis delle coordinate lagrangiane che mappino lo spazio $SO(3)$. Cerco, cioè, 3 numeri che rappresentino in maniera biunivoca una qualsiasi rotazioni dello spazio tridimensionale\footnote{Omomorfo allo spazio proiettivo}. Impiego allora i cosiddetti \textit{angoli di Eulero} $\varphi,\theta,\psi$. La loro definizione è la seguente:
	\begin{itemize}
		\item Parto dal sistema non ruotato con gli assi $x,y,z$. Ruoto attorno a $z$ di un angolo $\varphi$: ottengo un nuovo sistema $x',y',z$. L'asse $x'$ è chiamato anche \textit{linea dei nodi}
		\item Ora applico una rotazione attorno alla linea dei nodi (il nuovo asse $x$) di un angolo $\theta$. L'asse $z$ è diventato $z'$
		\item Infine, ruoto attorno al nuovo asse $z'$ di $\psi$
	\end{itemize}
	Si può dimostrare che tali operazioni\footnote{È importante farle in sequenza corretta!} permettono di definire un qualunque stato di rotazione del sistema cartesiano (una trasformazione $S\rightarrow S'$) e, dunque, la terna $\varphi,\theta,\psi$ costituisce effettivamente una terna di coordinate lagrangiane (mappano tutto lo spazio delle configurazioni). Vale che:
	$$
	\varphi, \psi \in (0,2\pi), \quad 	\theta \in (0,\pi)
	$$
	La trottola costruita in questo modo, detta trottola di Lagrange, gode di evidenti simmetrie. Il sistema è infatti invariante per rotazioni attorno all'asse $z$ (quello fisso) e quindi sappiamo che la proiezione sull'asse $z$ di $\vec{l}$ (questo perché il campo di forze gravitazionale è diretto verso $-\hat{z}$). Dunque $L_z$ è sicuramente un integrale primo del moto. Anche l'energia $E$ è un integrale primo del moto, perciò siamo a quota due. E il terzo?
	
	Costruiamo il sistema rotante $S'$ di modo che sia il sistema degli assi principali della trottola chiamando l'asse $z'$ quello relativo al momento di inerzia diverso (si veda la figura). Costruito così il sistema, è chiaro che esiste allora anche una simmetria rotazionale attorno all'asse $z'$. Dunque si dovrà conservare anche la componento lungo $z'$ del momento angolare ($L_{z'}$)\footnote{Che io consideri la proiezione di $L$ o $l$, non cambia nulla: il vettore momento angolare è sempre lo stesso, è un'entità geometrica intrinseca, cambia solo il modo in cui lo rappresento. In alternativa, la proeizione su di un asse equivale ad un prodotto scalare, che è un invariante per rotazioni. Dunque che io prenda l'espressione di $\vec{L}$ e lo proietti su $z$ o che io prenda $\vec{l}$ e lo proietti su $z$ (che in $S'$ ha un'altra forma analitica), otterrei due risultati uguali}. Ricapitolando, i tre integrali primi del moto sono:
	$$
	E, L_{z}, L_{z'}
	$$
	Il problema della trottola ha 3 gradi di libertà (lo spazio delle configurazioni è $SO(3)$), poiché ho imposto un punto fisso. Allora la trottola lagrangiana deve essere completamente integrabile. In generale, un corpo rigido non ha simmetrie lungo $z'$, motivo per cui la risoluzione generica di un corpo rigido soggetto alla gravità è impossibile.
	
	
	Dalla definizione stessa di angoli di Eulero, abbiamo che $\theta$ è l'angolo che esiste fra $z$ e $z'$. L'angolo euleriano $\varphi$ gestisce le rotazioni attorno all'asse $z$, ed essendo il sistema invariante per tali trasformazioni, allora $\varphi$ deve essere una coordinata ciclica. Stesso discorso per $\psi$, coordinata ciclica poiché il sistema è simmetrico per rotazioni attorno a $z'$. Allora la Lagrangiana del sistema avrà la forma:
	\begin{equation}\label{key}
		\Lambda = \Lambda(\dot{\theta},\dot{\varphi},\dot{\psi}, \theta)
	\end{equation}
	
	Siccome la lagrangiana non dipende da $\varphi,\psi$, valuto l'energia cinetica nella configurazione in cui $\varphi=0, \psi=0$. In tale configurazione, $x' = x $ (la linea dei nodi) e $z'$ forma un angolo di $\theta$ rispetto a $z$. L'energia cinetica si trova con la formula:
	$$
	T =\dfrac{1}{2} \vec{\omega}I\vec{\omega}
	$$
	e $I$ va riferito al punto di contatto (il punto fisso). Allora avremo:
	$$
	T = \dfrac{1}{2}(I_x(\omega_{x'}^2+\omega^{2}_{y'})+I_z\omega^{2}_{z'})
	$$
	Esprimo $\vec{\omega}$ nelle coordinate euleriano. Ci accorgiamo che:
	\begin{itemize}
		\item $\dot{\varphi}$ punta verso $z$.
		\item $\dot{\theta}$ punta verso la linea dei nodi, che in questo caso è $x = x'$
		\item $\dot{\psi}$ punta verso $z'$
	\end{itemize}
	L'asse $z$ nel sistema $S'$ si proietta su $z'$ moltiplicando per $\cos\theta$ e su $y'$ moltiplicando per $\sin\theta$. Allora la velocità angolare in $S'$ diventa\footnote{La formula più generale è $\vec{\omega} = (\dot{\varphi}\sin\theta\sin\psi + \dot\theta\cos\psi, \dot{\varphi}\sin\theta\cos\psi - \dot{\theta}\sin\psi, \dot{\varphi}\cos\theta + \dot{\psi})$}:
	$$
	\vec{\omega} = (\dot{\theta},\dot{\varphi}\sin\theta, \dot{\varphi}\cos\theta + \dot{\psi})_{S'}
	$$
	Allora l'energia cinetica diventa:
	\begin{equation}\label{key}
		T = \dfrac{1}{2}I_x (\dot{\theta}^{2}+ \dot{\varphi}^2\sin^{2}\theta)+\dfrac{1}{2}I_z(\dot{\varphi}^{2}\cos^{2}\theta+\dot{\psi}^{2}+2\dot{\varphi}\dot{\psi}\cos\theta)
	\end{equation}
	L'energia potenziale è, detta $d$ la distanza del centro di massa dal punto fisso,
	$$
	V = mgd\cos\theta
	$$
	e finalmente la Lagrangiana diventa
	\begin{equation}\label{key}
		\Lambda(\dot{\varphi},\dot{\theta},\dot{\psi},\theta) = \dfrac{1}{2}I_x (\dot{\theta}^{2}+ \dot{\varphi}^2\sin^{2}\theta)+\dfrac{1}{2}I_z(\dot{\varphi}^{2}\cos^{2}\theta+\dot{\psi}^{2}+2\dot{\varphi}\dot{\psi}\cos\theta) - mgd\cos\theta
	\end{equation}
	Procedo a ricercare gli integrali primi del moto relativi alle coordinate cicliche:
	$$
	p_{\varphi} = (\vec{L})_{z} = I_x\dot{\varphi}\sin^2\theta + I_z\dot{\varphi}\cos^{2}\theta + I_z \dot{\psi}\cos\theta = I_x \dot{\varphi}\sin^2\theta + I_z \cos\theta(\dot{\varphi}\cos\theta+\dot{\psi})
	$$
	$$
	p_{\psi} = (\vec{L})_{z'} =  I_z\dot{\psi} + I_z \dot{\varphi}\cos\theta
	$$
	che corrispondono alle due proiezioni del momento angolare. Uso $p_{\psi}$ nella formula di $p_{\varphi}$, 
	$$
	p_{\varphi} = I_x \dot{\varphi}\sin^2\theta + \cos\theta p_{\psi}
	$$
	da cui:
	$$
	\dot{\varphi}\sin^2\theta = \dfrac{p_{\varphi}- p_{\psi}\cos\theta}{I_x}
	$$
	Prendendo l'espressione dell'energia e sostituendo dappertutto fino ad ottenere solo $\theta$:
	\begin{equation}\label{key}
		\begin{aligned}
			E &= \dfrac{1}{2}I_x (\dot{\theta}^{2}+ \dot{\varphi}^2\sin^{2}\theta)+\dfrac{1}{2}I_z(\dot{\varphi}^{2}\cos^{2}\theta+\dot{\psi}^{2}+2\dot{\varphi}\dot{\psi}\cos\theta) + mgd\cos\theta \\
			&= \dfrac{1}{2}I_x\dot{\theta}^{2} + \dfrac{(p_{\varphi}- p_{\psi}\cos\theta)^2}{2I_x\sin^2\theta} + \dfrac{p_{\psi}^{2}}{2I_z} + Mgd\cos\theta \\
		\end{aligned}
	\end{equation}
	Il potenziale efficace in $\theta$ vale:
	$$
	V_{eff}(\theta) = \dfrac{(p_{\varphi}- p_{\psi}\cos\theta)^2}{2I_x\sin^2\theta} + Mgd\cos\theta 
	$$
	ha delle singolarità per $\theta = 0,\pi$, che però sono dovute alla singolarità delle coordinate impiegate. Modifichiamo un po' l'espressione dell'energia esplicitando $\sin^2\theta = 1-\cos^2\theta$ e chiamando $E' = E - \dfrac{p_{\psi}^2}{2I_z}$:
	
	$$
	E'I_x(1-\cos^2\theta) = \dfrac{1}{2}I_x^{2}\sin^2\theta\>\dot{\theta}^{2}+ \dfrac{(p_{\varphi}- p_{\psi}\cos\theta)^2}{2} + MgdI_x\cos\theta(1-\cos^2\theta) 
	$$
	definisco $u = \cos\theta$, $-1<u<1$, si ha che:
	$$
	\dot{u} = -\sin\theta \dot{\theta}
	$$
	e quindi l'energia:
	$$
	E'I_x(1-u^2) = \dfrac{1}{2}I_x^{2}\dot{u}^{2}+ \dfrac{(p_{\varphi}- p_{\psi}u)^2}{2} + MgdI_x u (1-u^2) 
	$$
	isolando la derivata,
	$$
	\dfrac{1}{2}I_x^{2} \dot{u}^2 = -f(u)
	$$
	dove $f(u)$ è una funzione polinomiale di terzo grado, cioè:
	$$
	f(u) = \dfrac{1}{2}(p_{\varphi}-p_{\psi}u)^2 + I_x(1-u^2)(Mgdu - E')
	$$
	Dovrò dunque usare funzioni ellittiche per risolvere tale moto. Poiché $f(-1) = f(1) = \dfrac{1}{2}(p_{\varphi}-p_{\psi})^2$, allora mi aspetto un punto stazionario nell'intervallo $[-1,1]$. Poiché la soluzione fisica esiste solo per i valori di $f(u)<0$, e sicuramente deve esistere una soluzione fisica, allora il punto stazionario di cui sopra sarà un minimo $\theta_{0}$. Dunque esiste una soluzione in cui la trottola si mantiene ad un'inclinazione $\theta$ costante, $\theta(t) = \theta_0$. Essendo:
	\begin{equation}
		\dot{\varphi} = \dfrac{p_{\varphi}-p_{\psi}\cos\theta}{I_x \sin^2\theta}
		\label{phidot}
	\end{equation}
	se $\theta$ è costante, allora anche $\varphi$ è costante e quindi $\varphi$ varia linearmente nel tempo. Se $\theta$ non è costante, $\dot{\varphi}$ può addirittura cambiare segno (la trottola è come se tornasse indietro!). Invece $\dot{\psi}$? Anche lui è costante, dunque si ha una rotazione uniforme attorno all'asse $z'$ (esattamente come ci aspettiamo)
	
	
	Se la soluzione di $\theta$ non è costante, sappiamo tuttavia che il moto su $\theta$ è confinato fra due valori, $\theta_1<\theta <\theta_2$ (moto di \textit{nutazione}). Dalla (\ref{phidot}), osserviamo che il segno di $\dot{\varphi}$ non è sempre positivo e può succedere che diventi negativo per certi angoli $\theta$. In tal caso, l'asse di rotazione $z'$ sembra tornare indietro e tracciare curve su di una sfera centrata in $O$ con dei riccioli. In caso contrario, la curva tracciata appare monotona, quasi sinusoidale. 
	
	In generale, dunque, il moto di una trottola lagrangiana è composto da tre moti angolari indipendenti e periodici: nutazione ($\theta$), precessione ($\varphi$) e rotazione ($\psi$). Se le loro frequenze di oscillazione sono commensurabili, allora la trottola percorre orbite tridimensionali chiuse, altrimenti riempie densamente lo spazio delle configurazioni concesso e non torna mai nello stato iniziale.
	Notiamo che se togliamo il termine di gravità, il polinomio si riduce di un grado e il problema può essere integrato senza ricorrere a funzioni esotiche. 
	\subsubsection{Trottola addormentata}
	E se inizialmente $\theta = 0$? Il potenziale della trottola lagrangiana è singolare in questo punto e quindi il problema va ripensato perché il set di coordinate euleriane non funziona adeguatamente per questi poli. 
	DA FINIRE 
	\newpage 
	\subsection{Esempi ed esercizi}
	\subsubsection{Tensore di inerzia di un corpo bidimensionale}
	Lavoriamo momentaneamente con corpi bidimensionale e definiamo il sistema rotante di modo che $z$ sia l'asse uscente dalla figura. Allora $z_{p} = 0$ in tutti i tempi e quindi:
	$$
	I_{xz} = I_{zx} = I_{yz} = I_{zy} = 0
	$$  
	poiché in questi elementi del tensore di inerzia compare sempre la variabile $z$, nulla per costruzione. Questo basta per affermare che l'asse $z$ è un'asse principale di inerzia. Scegliamo allora gli assi $x,y$ di modo da avere un sistema di assi principali: il momento di inerzia lungo $z$ è:
	$$
	I_{z} = \int_{K}(x^2+y^2)\rho(\vec{x}) d\vec{x}
	$$
	Invece 
	$$
	I_{x} = \int_{K}(y^2)\rho(\vec{x}) d\vec{x} \quad I_{y} = \int_{K}(x^2)\rho(\vec{x}) d\vec{x}
	$$
	e otteniamo il risultato notevole:
	\begin{equation}\label{key}
		I_z = I_x + I_y
	\end{equation}
	Così, nel sistema degli assi principali:
	\begin{equation}\label{key}
		I = 
		\begin{pmatrix}
			I_x & 0 & 0 \\
			0 & I_y & 0 \\
			0 & 0 & I_x + I_y
		\end{pmatrix}
	\end{equation}
	\subsubsection{Tensore di inerzia del disco omogeneo}
	Prendiamo un disco omogeneo. È un corpo bidimensionale, quindi valgono le relazioni esposte sopra. Un asse principale è chiaramente l'asse $z$ (che è anche asse di simmetria), mentre l'orientamento $x,y$ è arbitrario. Calcoliamo ad esempio $I_z$:
	\begin{equation*}\label{key}
		I_{z} = \int_{K}(x^2+y^{2})\sigma dxdy =\sigma \int_{0}^{R}\int_{0}^{2\pi}r^{3}drd\theta = \sigma\int_{0}^{R}r^3 dr \int_{0}^{2\pi} d\theta = \dfrac{\pi}{2}\sigma R^{4} = \dfrac{\pi}{2}\dfrac{M}{\pi R^{2}}R^{4} = \dfrac{1}{2}MR^{2}
	\end{equation*}
	Il momento di inerzia lungo $x$ è uguale al momento di inerzia lungo $y$ perché il disco è simmetrico rispetto a rotazione discrete di $\pi/2$ attorno all'asse z. Quindi
	$$
	I_x + I_y = 2I_x = I_z
	$$
	$$
	I_x = I_y = \dfrac{1}{4}MR^2
	$$
	\subsubsection{Tensore di inerzia di un'asta omogenea}
	Troviamo il tensore di inerzia di un'asta omogenea rispetto al centro di massa lunga $a$. Prendiamo un sistema di riferimento (che sarà quello rotante) con l'asse $y$ disposto lungo l'asta stessa e gli assi $x,z$ arbitrariamente. L'asta è simmetrica per rotazioni attorno all'asse $y$, dunque $I_x = I_z$. Invece $I_y = 0$, poiché:
	$$
	I_y = \int_{K}(x^2+z^2)dxdydz = 0
	$$
	poiché $x_{P} = z_{P} = 0$. Invece:
	$$
	I_{x} = \int_{-a/2}^{a/2}\lambda y^2 dy = \dfrac{M}{3a}{a^3}{8} = \dfrac{1}{12}Ma^{2}
	$$
	L'asta è anche una figura bidimensionale rispetto al piano $zy$ oppure $xy$. Gli assi uscenti sarebbero allora l'asse x e l'asse z e quindi dovrebbe valere:
	$$
	I_{z} = I_{x} + I_{y}
	$$
	$$
	I_x = I_y + I_z
	$$
	cosa che è effettivamente vera (e dalla quale avremmo potuto ricavare che necessariamente $I_y = 0$).
	\subsubsection{Tensore di inerzia di un rettangolo omogeneo}
	\subsubsection{Disco su di una guida rotante}
	Consideriamo un problema in cui vi sia una guida circolare di raggio $2R$ inizialmente nel piano $xy$ al cui interno può ruotare un altro disco omogeneo di raggio $R$. Il disco si muove sotto l'effetto della forza peso. Ad un certo punto la guida viene messa in rotazione attorno all'asse verticale con velocità angolare costante $\vec{\Omega}$. Il disco è vincolato a ruotare senza strisciare all'interno della guida.
	
	Definiamo in primis le coordinate lagrangiana del sistema. Sia $\varphi$ l'angolo della retta passante per il centro di massa mentre $\theta$ è l'angolo di rotolamento proprio del disco (posto $\theta = 0$ quando il disco poggia a $\varphi = 0$). Perché si abbia la condizione di rototraslazione, deve verificarsi che:
	$$
	2R\theta = -R\varphi
	$$
	$$
	2\theta = -\varphi
	$$
	Il segno meno è necessario perché se $\theta$ si sposta in senso antioraio, allora $\varphi$ si sposta in senso orario. Un altro modo per ricavare la stessa relazione passava per la nullità della velocità del punto di contatto, che è uguale alla velocità del disco dovuta alla sua rotazione attorno al centro di massa ($R\dot{\theta}$) e alla rotazione del disco intero rispetto al centro della circonferenza ($2R\dot{\varphi}$). Da questa seguiva la condizione di rototraslazione sulle velocità:
	$$
	\dot{\theta} = -2\dot{\varphi}
	$$
	Passiamo a costruire l'energia cinetica usando il teorema di Konig. Il centro di massa del disco sta nella posizione:
	$$
	\vec{x}_{CM}= (-R\cos\varphi, -R\sin\varphi)
	$$
	e quindi:
	$$
	\vec{v}_{CM} = (R\dot{\varphi}\sin\varphi, -R\dot{\varphi}\cos\varphi)
	$$
	$$
	T_{CM} = \dfrac{1}{2}mR^{2}\dot{\varphi}^{2}
	$$
	Ora devo valutare l'altro contributo. Mi metto nel sistema rotante solidale col disco e calcolo l'energia cinetica rispetto a questo usando il tensore di inerzia. Il disco ruota di $\theta+\varphi$, quindi
	DA COMPLETARE 
	\subsubsection{Disco tagliato su piano}
	\subsubsection{Ruota quadrata}
	
	\newpage
	
	
	\section{Principi variazionali}
	Esiste un modo alternativa per formulare i principi della meccanica classica. Siamo, infatti, partiti dal Principio di Newton:
	$$\vec{F} = m\vec{a}$$
	per poi approdare alla versione lagrangiana del medesimo principio:
	\begin{equation}\label{key}
		\Bigl(\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_i}-\dfrac{\partial}{\partial q_i}\Bigl)(\Lambda(q,\dot{q})) = 0
	\end{equation}
	Il motivo della loro validità è ignoto (sono principi fondamentali, \textit{lo chieda al padre eterno}), ma sappiamo che se vale l'uno, vale anche l'altro. Vogliamo, a questo punto, dimostrare che esiste una terza formulazione possibile della meccanica classica che pone come assioma fondamentale un \textit{principio di carattere variazionale}, il \textit{principio di minima azione}
	\subsection{Funzionali ed estremanti}
	In primis, un po' di definizioni. Sia $q(t)$ una generica traiettoria nello spazio delle configurazioni tale che, ai tempi $t_A \mbox{ e } t_B$, valga $q_A = q(t_A), q_B = q(t_B)$. Definisco allora l'insieme $Q$ di tutte le possibili traiettorie nello spazio i cui estremi negli istanti temporali $t_A, t_B$ siano gli stessi, e cioè:
	\begin{equation}
		Q = \{q(t)\in C^{(2)}(t_A,t_B): q(t_A) = q_A, \> q(t_B) = q_B\}
	\end{equation}
	e richiediamo anche le traiettorie $q$ siano di classe $C^{(2)}$. A questo punto, definiamo un \textit{funzionale} $\tilde{F}$ come un'applicazione che ad ogni traiettoria $q \in Q$ restituisce un numero reale:
	$$
	\tilde{F} : Q \rightarrow \mathbb{R}
	$$
	definita come:
	$$
	\tilde{F}(q(t)) = \int_{t_A}^{t_B}F(q,\dot{q},t) dt
	$$
	Attenzione a non confondersi. Il simbolo $F(q,\dot{q},t)$ è una generica funzione che combina la traiettoria $q$ ed eventualmente la sua derivata $\dot{q}$ e il tempo stesso $t$. Quindi $F$ prende una traiettoria in $Q$ e restituisce una generica funzione in una variabile (che va integrata):
	$$
	F : Q \rightarrow \mathbb{R}^{\mathbb{R}}
	$$
	Invece il funzionale associa ad ogni traiettoria un numero pure reale. Un esempio di funzionale è quello della lunghezza della curva che connette due punti nello spazio. Detta $q(t)$ la curva parametrizzata a $t\in[a,b]$, allora la sua lunghezza è:
	$$
	L = \int_{\gamma}ds = \int_{a}^{b}\sqrt{\dot{q}_j \dot{q}_j}dt
	$$
	con $q_j$ coordinate cartesiane. Se impiegassimo altre coordinate generalizzate, allora avremmo genericamente
	$$
	L = \int_{\gamma}ds = \int_{a}^{b}\sqrt{\dot{q}_j G\dot{q}_j}dt
	$$
	con $G$ matrice metrica dello spazio delle configurazioni con le coordinate generalizzate. La lunghezza è dunque un funzionale (associa ad una curva un numero). 
	
	Definiamo ora cosa intendiamo per \textit{estremale} di un funzionale. Detto $\tilde{F}$ un funzionale, allora $q\in Q$ si dice traiettoria estremale o, semplicemente, estremale per $\tilde{F}$ se:
	\begin{equation}\label{key}
		\tilde{F}(q+\delta q) = \tilde{F}(q) + O(||\delta q||^2)
	\end{equation}
	dove $\delta q$ è una piccola funzione variazione nella traiettoria per la quale $\delta q (t_A) = \delta q(t_B) = 0$. Cosa intendiamo per piccola? Per dare un senso a questa frase, associamo alla funzione $\delta q $ una norma e richiediamo che tale norma sia piccola (e così possiamo usare la solita notazione degli O grande)\footnote{Questo è possibile perché lo spazio in cui vivono tutte le varia variazioni $\delta q$ è uno spazio vettoriale a tutti gli effetti e quindi posso normarlo. D'altronde, sommando due variazioni $\delta q$ otterrei ancora una variazione che si annulla in $t_A \mbox{ e } t_B$ (cosa non vero per lo spazio $Q$).} In un certo senso, una traiettoria estremale rende stazionario il valore del funzionale (non possiamo usare i concetti dell'analisi, come la derivata, che in questo caso non avrebbe senso). Dunque come definizione alternativa (ma ugualmente valida) richiediamo che spostandoci in intorni di $q$ (e il concetto di intorno è sensato perché ho normato lo spazio, dunque è topologico) la variazione che osservo nel funzionale è di ordine $2$ rispetto alla variazione stessa. 
	
	
	Vediamo come calcolare esplicitamente l'estremale di un generico funzionale $\tilde{F}$. Valuto allora:
	$$
	\tilde{F}(q+\delta q) = \int_{t_A}^{t_B}F(q+\delta q, \dot{q}+\delta \dot{q},t)dt
	$$
	A questo punto sviluppo con Taylor la funzione $F$ attorno a $(q,	\dot{q})$\footnote{Non è detto che se $\delta q $ è piccolo allora anche $\delta \dot{q}$ lo sia. In realtà andrebbe dimostrato. Per ora lo assumiamo}:
	$$
	\tilde{F}(q+\delta q) = \tilde{F} (q) + \int_{t_B}^{t_A}\Bigl(\dfrac{\partial F}{\partial q}\delta q+\dfrac{\partial F}{\partial \dot{q}}\delta \dot{q}\Bigl)dt + O(\delta q^2)
	$$
	Considero il termine:
	$$
	\int_{t_B}^{t_A}\dfrac{\partial F}{\partial \dot{q}}\delta \dot{q}dt
	$$
	e integro per parti:
	$$
	\int_{t_B}^{t_A}\dfrac{\partial F}{\partial \dot{q}}\delta \dot{q}dt = \dfrac{\partial F}{\partial \dot{q}}\delta q \Bigl|_{t_B}^{t_A} - \int_{t_B}^{t_A}\Bigl(\dfrac{d}{dt}\dfrac{\partial F}{\partial \dot{q}}\Bigl)\delta qdt = - \int_{t_B}^{t_A}\Bigl(\dfrac{d}{dt}\dfrac{\partial F}{\partial \dot{q}}\Bigl)\delta q dt
	$$
	e quindi:
	$$
	\tilde{F}(q+\delta q) = \tilde{F} (q) + \int_{t_B}^{t_A}\Bigl(\dfrac{\partial F}{\partial q}-\dfrac{d}{dt}\dfrac{\partial F}{\partial \dot{q}}\Bigl)\delta qdt + O(\delta q^2)
	$$
	Dunque, perché ci $q$ sia davvero un estremale, allora richiediamo che:
	$$
	\int_{t_B}^{t_A}\Bigl(\dfrac{\partial F}{\partial q}-\dfrac{d}{dt}\dfrac{\partial F}{\partial \dot{q}}\Bigl)\delta qdt = 0, \qquad \forall \delta q
	$$
	Un teorema che non dimostreremo afferma che tale richiesta è perfettamente equivalente all'avere l'integrando sempre nullo, e cioè l'estremale $q$ rispetta la condizione
	$$
	\dfrac{\partial F}{\partial q}-\dfrac{d}{dt}\dfrac{\partial F}{\partial \dot{q}} = 0
	$$
	detta equazione di Eulero. Questa equazione ricorda da vicino le equazioni di Lagrange che già abbiamo visto. Infatti, se costruiscono un funzionale con $F= \Lambda$:
	\begin{equation}\label{key}
		S = \int_{t_B}^{t_A} \Lambda(q,\dot{q},t) dt
	\end{equation}
	detto \textit{funzionale d'azione}, allora avremo che, dato un insieme di traiettorie nello spazio delle configurazioni tali che $q(t_A) = q_A, q(t_B) = q_B$, la traiettoria fisica (cioè quella effettivamente compiuta) sarà tale da rispettare le equazioni di Lagrange e, dunque, anche l'equazione di Eulero. In altre parole, le traiettorie fisiche sono sempre estremali per il funzionale d'azione. Questo è il contenuto del \textbf{Principio di minima azione}\footnote{Perché minima? In realtà, ci basta che la traiettoria sia un estremale. Tuttavia si può dimostrare che, se $[t_A, t_B]$ è abbastanza piccolo, allora davvero si tratta di minimi.}, simbolicamente riassumibile in:
	\begin{equation}\label{key}
		\delta \int_{t_A}^{t_B}\Lambda \> dt = 0
	\end{equation}
	Il principio di minima azione si presta ad una vastità di applicazioni che permettono di risolvere problemi impossibili da comprendere tramite la meccaninca lagrangiana. Inoltre, consente di intravedere una sorprendente analogia fra meccanica e geometria.
	
	Notiamo, in ultimo, che nell'usare correttamente il principio dobbiamo imporre due condizioni di contorno, non più propriamente iniziali. Se nella formulazione lagrangiana ci preoccupavamo di conoscere lo stato iniziale (posizione e impulso), qua richiediamo di sapere le posizione in due istanti temporali differenti.
	\subsubsection{Esempio: la catenaria}
	\subsection{Proprietà del funzionale d'azione}
	Tramite il principio di minima azione è possibile ricavare alcune proprietà già verificate in precedenza. Ad esempio, sappiamo che la lagrangiana è invariante per gauge, cioè data $\Lambda'$:
	$$
	\Lambda' = \Lambda + \dfrac{dF}{dt}
	$$
	se $Lag(\Lambda)=0$ necessariamente anche $Lag(\Lambda')=0$. Vediamo cosa succede a livello del funzionale d'azione.
	Sia $S$ l'azione per $\Lambda$:
	$$
	S = \int_{t_A}^{t_B} \Lambda dt
	$$
	e 
	$$
	S' = \int_{t_A}^{t_B} \Lambda' dt = \int_{t_A}^{t_B} \Lambda dt + \int_{t_A}^{t_B} \dfrac{dF}{dt} dt
	$$
	Per il teorema fondamentale del calcolo integrale:
	$$
	S' = S + (F(t_B)-F(t_A))
	$$
	e l'ultimo termine è chiaramente costante. Se $q$ è la traiettoria fisica che congiunge $q_A, q_B$ ai tempi $t_A, t_B$, allora sarà un estremale per $S$. Tuttavia, essendo:
	$$
	\delta S = \delta S'
	$$
	allora la $q(t)$ è anche soluzione per $\Lambda'$, cioè è dimostrata l'invarianza per gauge. Alla luce di questo nuovo principio, l'invarianza della lagrangiana per pure derivate del tempo si spiega in maniera molto naturale.
	\subsection{Geodetiche e geometria}
	Cerchiamo di approfondire meglio la connessione fra geometria e meccanica. Consideriamo un problema dinamico di cui abbiamo individuato lo spazio delle configurazioni $\Sigma$. Ricordiamo che lo spazio delle configurazioni dipende dalle coordinate che scegliamo per rappresentare gli stati dinamici del sistema in esame. Sia poi $G$ la metrica dello spazio $\Sigma$ (la matrice che permette di fare i prodotti scalari e le norme dei vettori in $\Sigma$). Allora, dato un punto materiale di massa unitaria, scriveremo la sua lagrangiana $\Lambda$ come:
	\begin{equation}\label{key}
		\Lambda = T = \dfrac{1}{2}\dot{q}_iG_{ij}\dot{q}_j
	\end{equation}
	Dal principio di minima azione, avremo che la traiettoria nello spazio delle configurazioni $q(t)\in\Sigma$ che il punto materiale segue (dati due estremi) rende stazionaria l'azione, cioè tale da soddisfare l'equazione simbolica:
	\begin{equation}\label{key}
		\delta \int_{t_A}^{t_B}\Lambda dt = 0
	\end{equation}
	o, equivalentemente,
	\begin{equation}
		\delta \int_{t_A}^{t_B}\dot{q}_iG_{ij}\dot{q}_j dt = 0
		\label{PrincipioMinimaAzione}
	\end{equation}
	Ora vogliamo dimostrare un fatto molto importante. La traiettoria $q(t)$ fisica (cioè quella che fisicamente compie il punto materiale libero) coincide con una curva geodetica, ovvero con la curva che congiunge $q_A \mbox{ e } q_B$ avente la minore lunghezza possibile. Come lo dimostro? Partiamo dal definire la curva geodetica. Immaginiamo di parametrizzare la curva $\gamma$ con un parametro generico $t$ (che non è necessariamente il tempo fisico). Il differenziale di lunghezza vale:
	$$
	ds = \sqrt{\dot{q}_iG_{ij}\dot{q}_j}dt
	$$
	Ricordiamo ancora una volta che $t$ è un parametro a caso che genera la curva, non necessariamente $t$, il tempo fisico. La lunghezza della curva è allora:
	$$
	L = \int_{\gamma} ds = \int_{t_A}^{t_B}\sqrt{\dot{q}_iG_{ij}\dot{q}_j}dt 
	$$ 
	se la curva $\gamma$ è geodetica, la lunghezza deve essere minima quindi:
	\begin{equation}
		\delta \int_{t_A}^{t_B}\sqrt{\dot{q}_iG_{ij}\dot{q}_j}dt  = 0
		\label{Geod}
	\end{equation}
	La relazione (\ref{PrincipioMinimaAzione}) permette di individuare la \textit{traiettoria fisica}, mentre la relazione (\ref{Geod}) permette di individuare la curva geodetica, una proprietà puramente geometrica. Le due relazioni non sembrano uguali, non sembra che le curve fisiche siano anche geodetiche. Le traiettorie fisiche, infatti, sono determinate dal modulo quadro della velocità, $v^2$, mentre le curve geodetiche sono definite a partire dal modulo della velocità, $|v|$. Notiamo, infine, che nella definizione del funzionale d'azione $S$ il tempo è un parametro privilegiato, non posso sostituirlo senza compromettere la validità delle equazioni. Al contrario, nella definizione del funzionale lunghezza, il tempo è solo un parametro con cui descrivo una curva (e sappiamo che una curva è una classe di equivalenza, indipendente dalla sua parametrizzazione). Introdurlo come parametro è una scelta arbitraria.
	
	Vediamo come procedere. Riprendo in mano il funzionale d'azione $S$:
	$$ 
	S = \int_{t_A}^{t_B}\dot{q}_iG_{ij}\dot{q}_j dt
	$$
	So che l'energia è un integrale primo del moto, cioè:
	$$
	\dfrac{d}{dt}\dot{q}_iG_{ij}\dot{q}_j = 0
	$$
	Allora la curva viene percorsa a velocità costante poiché:
	$$
	v = \dfrac{ds}{dt} = \dfrac{\sqrt{\dot{q}_iG_{ij}\dot{q}_j}dt}{dt} = \sqrt{\dot{q}_iG_{ij}\dot{q}_j} = const
	$$
	Ora passo al funzionale geometrico, cioè la lunghezza, per cui so che vale:
	\begin{equation}
		\delta \int_{t_A}^{t_B}\sqrt{\dot{q}_iG_{ij}\dot{q}_j}dt  = 0
	\end{equation}
	Svincoliamoci dalla richiesta che il parametro della curva sia necessariamente $t$ e, anzi, chiamiamolo $\lambda$:
	\begin{equation}
		\delta \int_{\lambda_A}^{\lambda_B}\sqrt{q'_iG_{ij}q'_j}d\lambda  = 0
	\end{equation}
	dove però chiaramente $q'_i= \dfrac{dq_i}{d\lambda}$ (il puntino sopra è riservato alla specifica derivata temporale). Per determinare la curva estremale (la geodesica), uso le equazioni di Eulero e ottengo:
	$$
	\dfrac{d}{d\lambda}\dfrac{\partial}{\partial q'_i}\sqrt{q'_iG_{ij}q'_j} - \dfrac{\partial}{\partial q_i}\sqrt{q'_iG_{ij}q'_j} = 0
	$$
	Ora ritorno a $\lambda = t$ (poiché solo con il tempo posso imporre $\dfrac{d}{dt}(\dot{q}G\dot{q})=0$):
	$$
	\dfrac{d}{dt}\dfrac{\partial}{\partial \dot{q}_i}\sqrt{\dot{q}_iG_{ij}\dot{q}_j} - \dfrac{\partial}{\partial q_i}\sqrt{\dot{q}_iG_{ij}\dot{q}_j} = 0
	$$
	$$
	\dfrac{d}{dt}\dfrac{1}{2\sqrt{\dot{q}_iG_{ij}\dot{q}_j}} G_{ij}\dot{q}_j - \dfrac{1}{2\sqrt{\dot{q}_i G_{ij}\dot{q}_j}} \dot{q}_i \frac{\partial G_{ij} }{\partial q_i} \dot{q}_j 0
	$$
	Dalla conservazione dell'energia, possiamo tirare fuori dalla prima derivata un termine
	$$
	\dfrac{d}{dt}\dfrac{1}{2\sqrt{\dot{q}G\dot{q}}}G_{ij} \dot{q}_j =\dfrac{1}{2\sqrt{\dot{q}G\dot{q}}} \dfrac{d}{dt}G_{ij} \dot{q}_j
	$$
	e quindi:
	$$
	\dfrac{1}{2\sqrt{\dot{q}_iG_{ij}\dot{q}_j}}\dfrac{d}{dt}\ G_{ij}\dot{q}_j - \dfrac{1}{2\sqrt{\dot{q}_i G_{ij}\dot{q}_j}} \dot{q}_i \frac{\partial G_{ij} }{\partial q_i} \dot{q}_j 0
	$$
	\begin{equation}
		\dfrac{d}{dt} G_{ij}\dot{q}_j -\dot{q}_i \frac{\partial G_{ij} }{\partial q_i} \dot{q}_j = 0	\label{SoluzGeom}
	\end{equation}
	Ora invece costruiamo la soluzione meccanica, applicando le equazioni di Lagrange sulla lagrangiana fisica:
	$$
	\dfrac{d}{dt}\dfrac{\partial }{\partial \dot{q}_i}\dot{q}_i G_{ij} \dot{q}_j - \dfrac{\partial }{\partial q_i}\dot{q}_i G_{ij} \dot{q}_j = 0 
	$$
	$$
	\dfrac{d}{dt}G_{ij} \dot{q}_j - \dot{q}_i \frac{\partial G_{ij}}{\partial q_i} \dot{q}_j
	$$
	Ma questa equazione è proprio uguale alla (\ref{SoluzGeom}), e dunque avranno le stesse soluzioni. Allora, almeno finché il corpo è libero, le curve fisiche tracciate nello spazio delle configurazioni coincidono anche con le geodetiche di questo spazio. Possiamo dire, in un certo senso, che la dinamica è una specificazione della geometria, nel senso che si specifica l'esistenza di parametro privilegiato per descrivere le traiettorie, ossia il \textit{tempo}. Una curva geodetica, dunque, costituisce la traiettoria di un problema fisica e se sceglio di parametrizzarla col tempo $t$, allora la geodetica non solo è traiettoria, ma è anche la curva del moto.
	
	
	Almeno per problemi senza potenziali, il principio di minima azione (e quindi la fisica) è equivalente al principio delle geodesiche. Se, ad esempio, definissimo una nuova lagrangiana, suggerita direttamente dal lato geometrico che abbiamo appena scoperto,
	\begin{equation}\label{key}
		\Lambda_{g} = \sqrt{\dot{q}G\dot{q}}
	\end{equation}
	Il principio delle geodesiche mi dice che la curva di minima lunghezza deve essere estremale per l'azione costruita con $\Lambda_g$. Ma sappiamo che tale curva è equivalentemente anche fisica, quindi sembra che esista una forma alternativa della funzione lagrangiana che abbiamo introdotto sezioni fa. Se così fosse, potremmo ricavarci un nuovo integrale primo del moto, un'energia di origine geometrica:
	\begin{equation}\label{key}
		H_{g} = \dfrac{\partial \Lambda_g}{\partial \dot{q}_i}\dot{q}_i - \Lambda_g
	\end{equation}
	Sfortunatamente, questa espressione è identicamente nullo, otteniamo dunque che $0$ deve rimanere costante nel tempo, affermazione banale. Questa nuova lagrangiana di origine geometrica, per quanto equivalente a quella fisica per corpi liberi, non sembra suggerire nuovi integrali primi del moto. L'esistenza dell'integrale primo energia dunque è strettamente legato al fatto che, nell'interpretazione fisica, esiste un parametro privilegiato, il tempo. L'energia esiste solo se esiste il tempo (e fra le due grandezze comincia a sorgere una strana relazione).
	\subsection{Un esempio: la metrica di Poincaré}
	Proponiamo un esempio. Prendiamo uno spazio delle configurazioni $\Sigma$ descritto da due variabili $x,y$ in cui la metrica è:
	$$
	ds^2 = \dfrac{dx^2 + dy^2}{y^2}
	$$
	In precedenza abbiamo fornito la metrica come matrice che permette di fare il prodotto scalare fra elementi di $\Sigma$ (di modo che siano compatibili con qualche altre spazio, ad esempio $\mathbb{R}^3$ nei problemi dinamici). Sappiamo però che, definendo un prodotto scalare, abbiamo gratis anche la norma dello spazio (e viceversa). Se specifico allora come costruire la norma di elementi di $\Sigma$, allora in automatico do informazioni sul prodotto scalare e, allora, definisco una metrica. In questo caso diamo la definizione di lunghezza d'arco $ds$, che serve a costruire la lunghezza di curve in $\Sigma$. Anche questa quantità è strettamente imparentata con le nozioni geometriche di prodotto scalare e, dunque, si tratta di un modo alternativo per definire una metrica. La matrice $G$ associata sarebbe:
	\begin{equation}\label{key}
		G(x,y) = 
		\begin{pmatrix}
			\dfrac{1}{y^2} & 0 \\
			0 & \dfrac{1}{y^2}
		\end{pmatrix}
	\end{equation}
	Chiarito questo dubbio, procediamo oltre. Scriviamo la Lagrangiana per particelle libere, che ha la forma:
	\begin{equation}\label{key}
		\Lambda = \dfrac{m}{2y^2}(\dot{x}^2+\dot{y}^2)
	\end{equation}
	Un integrale primo del moto è l'energia
	\begin{equation}\label{key}
		E = \dfrac{m}{2y^2}(\dot{x}^2+\dot{y}^2)
	\end{equation}
	ma anche il momento coniugato rispetto a $x$:
	\begin{equation}\label{key}
		p_{x} = \dfrac{\partial \Lambda}{\partial \dot{x}} = \dfrac{m\dot{x}}{y^2} \longrightarrow \dot{x} = \dfrac{y^2 p_x}{m}
	\end{equation}
	e, sostituendo nell'energia,
	\begin{equation}\label{key}
		E = \dfrac{m\dot{y}^2}{2y^2} + \dfrac{p_x^2}{2m}y^2
	\end{equation}
	$$
	2Ey^2 = m\dot{y}^2+ p_x^{2} y^4
	$$
	$$
	m\dot{y}^2 = 2Ey^2 - p_x^{2} y^4 
	$$
	Risolvendo tale equazione differenziale otteniamo la legge oraria $y(t)$ (da cui poi possiamo ricavare $x(t)$ tramite momento di $x$).
	\subsection{Principio di Maupertuis}
	Nella sezione precedente abbiamo visto che è possibile ridurre la meccanica in assenza di forze a semplici principi di geometria dello spazio delle configurazioni. E se aggiungessi potenziali esterni sul sistema? La versione aggiornata con potenziali di questa sorprendente analogia fisica-geometria passa sotto il nome di \textit{principio di Maupertuis}. Vediamo come arrivarci.
	
	Sappiamo che se la lagrangiana del sistema non dipende dal tempo, allora $H$ definito come:
	$$
	H = \dfrac{\partial \Lambda}{\partial \dot{q}_i}\dot{q}_i - \Lambda
	$$
	è integrale primo del moto. Le soluzioni fisiche sono allora caratterizzate da $H = E = const$. Dati due estremi del moto, $q_A$ e $q_B$ in $\Sigma$, allora è ben definita l'energia del sistema (che deve conservarsi). Perciò, quando definisco il dominio del funzionale d'azione posso restringere la scelta delle traiettoria $q(t) \subset \Sigma$ limitandola a quelle per cui l'energia si conserva:
	$$
	Q = \{q(t)\subset\Sigma: t\in [t_A,t_B], q(t_A) = q_A, q(t_B)=q_B, H(q(t),\dot{q}(t)) = E\}
	$$
	e il principio fisico (di minima azione) afferma che la traiettoria soluzione è quella per cui:
	$$
	\delta S = \delta \int_{t_A}^{t_B}\Lambda dt = 0
	$$
	Tuttavia, in genere, modificare il dominio può modificare il principio variazionale. Se ora riscrivo la lagrangiana come:
	$$
	\Lambda = \dfrac{\partial \Lambda}{\partial \dot{q}_i}\dot{q}_i - H
	$$
	e sostituisco nel principio variazionale:
	\begin{equation}\label{key}
		\delta S = \delta \int_{t_A}^{t_B}\Lambda t = 0 = \delta \int_{t_A}^{t_B} \dfrac{\partial \Lambda}{\partial \dot{q}_i} dt -\delta \int_{t_A}^{t_B} E dt = \delta \int_{t_A}^{t_B} \dfrac{\partial \Lambda}{\partial \dot{q}_i} \dot{q}_idt
	\end{equation}
	cioè il nuovo principio variazionale recita allora
	\begin{equation}
		\delta \int_{t_A}^{t_B} \dfrac{\partial \Lambda}{\partial \dot{q}_i} \dot{q}_i dt = 0
		\label{Mauper}
	\end{equation}
	Il principio (\ref{Mauper}), dunque, caratterizza le soluzioni fisiche di un problema meccanico. 
	
	Se $\Lambda = \dfrac{1}{2}\dot{q}G\dot{q} - V(q)$, dunque se si ha un potenziale, allora abbiamo dimostrato che:
	$$
	H = \dfrac{1}{2}\dot{q}G\dot{q} + V(q)
	$$
	e quindi l'argomento dell'integrale di (\ref{Mauper}) diventa:
	$$
	\dfrac{\partial \Lambda}{\partial \dot{q}_i} \dot{q}_i = \dot{q}_iG_{ij}\dot{q}_j
	$$
	Ricordando che la lunghezza d'arco $ds$ è riscrivibile come:
	$$
	ds = \sqrt{\dot{q}_i G_{ij} \dot{q}_j} dt
	$$
	allora otteniamo che:
	$$
	\dfrac{\partial \Lambda}{\partial \dot{q}_i} \dot{q}_i = \dot{q}_iG_{ij}\dot{q}_j = \Bigl(\dfrac{ds}{dt}\Bigl)^2 (= v^2)
	$$
	ma allora 
	$$
	\dfrac{\partial \Lambda}{\partial \dot{q}_i} \dot{q}_i dt = \Bigl(\dfrac{ds}{dt}\Bigl)^2 dt = v \cdot vdt = v ds = \Bigl(\dfrac{ds}{dt}\Bigl) ds
	$$
	Dalle legge di conservazione dell'energia, posso riscrivere $v$ cercando di sbarazzarmi della coordinata tempo:
	$$
	v = \sqrt{\dfrac{2}{m}(E-V(q))}
	$$
	e quindi il principio (\ref{Mauper}), detto di Maupertuis, viene riformulato come
	\begin{equation}
		\delta \int_{q_A}^{q_B} \sqrt{2(E-V(q))} ds = 0
		\label{Mauper2}
	\end{equation}
	Questa equazione ci dice che, dati due estremi $q_A, q_B$, la traiettoria $q(t)$ fisicamente realizzata è quella per cui quel funzionale è stazionario. Notiamo che, se $V(q)=0$, allora la (\ref{Mauper2}) diventa semplicemente:
	\begin{equation}\label{key}
		\delta \int_{q_A}^{q_B}  ds = 0
	\end{equation}
	che è la relazione costitutiva di una geodetica (lunghezza minima). Se invece esiste anche un potenziale, è come stessimo modificando la metrica dello spazio delle configurazioni (in base al potenziale stesso). Se infatti definisco una nuova metrica:
	$$
	d\sigma = \sqrt{2(E-V(q))} ds 
	$$
	il Principio di Maupertuis asserisce la stazionarietà delle traiettorie fisiche rispetto a questa nuova metrica nello spazio delle configurazioni (che infatti si riduce a $d\sigma = ds$ se $V(q)=0$. L'effetto del potenziale è quello di deformare localmente la metrica. \footnote{C'è in realtà $E$ di mezzo, ma tanto è costante durante il moto e, ai fini variazionali, è ininfluente}. Questo concetto verrà ripreso in relatività generale). 
	
	
	Con tale principio, posso costruire le soluzioni del problema fisico ricercando le geodesiche per la metrica deformata. Per re-introdurre il tempo, mi basta cercare quel parametro della curva tale per cui l'energia $E$ presente nel principio è conservata lungo il moto.
	\subsection{Applicazione nel problema di Keplero}
	Usiamo le coordinate polari $(r,\theta)$ per descrivere il moto di un corpo soggetto al potenziale di keplero. La metrica dello spazio delle configurazioni $\Sigma = \{(r,\theta), r>0, 0 <\theta < 2\pi\}$ è data da:
	$$
	ds^2 = dr^2 + r^2d\theta^2
	$$
	e, quindi, la metrica deformata dal potenziale kepleriano è, data un'energia $E$:
	$$
	d\sigma = \sqrt{2(E+\dfrac{k}{r})} \sqrt{dr^2 + r^2d\theta^2}
	$$
	\subsection{Particella relativistica}
	DA FARE
	
	\newpage
	
	\section{Formulazione Hamiltoniana}
	Esiste un'ultima formulazione della meccanica classica che prende il nome dal suo scopritore, \textit{Hamilton}. La formulazione hamiltoniana della meccanica classica permette di generalizzare ulteriormente i risultati della dinamica e, in alcuni casi, si rivela molto più potente della lagrangiana. Così tanto che la meccanica quantistica ne ha rubato i metodi, cambiando però i principi fondamentali.
	
	Partiamo dalla lagrangiana di un sistema, $\Lambda$. Abbiamo definito i \textit{momenti generalizzati} $p_k$ come:
	\begin{equation}
		p_{k} = \dfrac{\partial \Lambda}{\partial \dot{q}_k}(q,\dot{q})
		\label{defMom}
	\end{equation}
	I momenti $p_k$ sono covarianti, mentre le velocità generalizzate $\dot{q}_k$ sono controvarianti. Questo vuol dire che se costruisco la forma:
	$$
	\dot{q}_k p_k
	$$
	ottengo uno scalare che è invariante. L'affermazione di principio risiede nell'equazione di Eulero-Lagrange:
	\begin{equation}\label{key}
		\dfrac{d}{dt} \dfrac{\partial \Lambda}{\partial \dot{q}_k} - \dfrac{\partial \Lambda}{\partial q_k} = 0
	\end{equation}
	$$
	\dot{p}_k = \dfrac{\partial \Lambda}{\partial q_k}
	$$
	che è la forma covariante dell'equazione di Newton. A partire dall'equazione (\ref{defMom}) possiamo, ad esempio, invertire e ricavarci $\dot{q}_k$ in funzione di $q_k,p_k$:
	$$
	\dot{q}_k = \dot{q}_k (q,p,t)
	$$
	L'invertibilità di questa forma è garantita dal fatto che la matrice metrica è essa stessa invertibile. Definiamo a questo punto la \textit{trasformata di Legendre}, una speciale trasformazione che, partendo da $\Lambda$, permette di ottenere una nuova funzione $\mathcal{H}$, detta \textit{hamiltoniana}, funzione delle sole coordinate e relativi momenti:
	\begin{equation}\label{key}
		\Lambda \rightarrow \mathcal{H}
	\end{equation}
	\begin{equation}\label{key}
		\mathcal{H} = p_{k}\dot{q}_k(q,p,t) - \Lambda 
	\end{equation}
	Mentre la lagrangiana è definita sullo spazio delle configurazioni ($q, \dot{q}$, coordinate indipendenti), la hamiltoniana è definita nello spazio delle fasi ($q,p$, anch'esse indipendenti). Notiamo che l'hamiltoniana ha la stessa forma dell'energia poiché:
	$$
	\mathcal{H} = \dfrac{\partial \Lambda}{\partial \dot{q}_k}\dot{q}_k - \Lambda = H 
	$$
	L'hamiltoniana, dunque, ha il significato di un'energia meccanica ma non è solamente un integrale primo del moto. È qualcosa di più, esattamente come lo era la lagrangiana, perché a partire da essa è possibile derivare interamente la dinamica di un sistema dinamico. Vediamo come ricavare le equazioni del moto a partire dall'hamiltoniana.
	\subsection{Equazioni di Hamilton}
	La funzione hamiltoniana $\mathcal{H}$ è funzione delle coordinate generalizzate e dei relativi momenti:
	$$
	\mathcal{H} = \mathcal{H}(q,p,t)
	$$
	Ne calcolo ora il differenziale, tenendo in mente da cosa dipende:
	\begin{equation}\label{key}
		d\mathcal{H} = \dfrac{\partial \mathcal{H}}{\partial q_k}dq_k +\dfrac{\partial \mathcal{H}}{\partial p_k}dp_k + \dfrac{\partial \mathcal{H}}{\partial t}
	\end{equation}
	Ora invece consideriamo la definizione di $\mathcal{H} = p_k\dot{q}_k  -\Lambda(q,\dot{q})$ e applichiamo i differenziali qui abbiamo che
	\begin{equation}
		\begin{aligned}
			d\mathcal{H} &= \dot{q}_k dp_k + p_k d\dot{q}_k -\dfrac{\partial \Lambda}{\partial q_k}dq_k -\dfrac{\partial \Lambda}{\partial \dot{q}_k}d\dot{q}_k - \dfrac{\partial \Lambda}{\partial t} =\\
			&= \dot{q}_k dp_k + p_k d\dot{q}_k - \dot{p}_k dq_k - p_k d\dot{q}_k - \dfrac{\partial \Lambda}{\partial t} \\
			&= \dot{q}_k dp_k -  \dot{p}_k dq_k - \dfrac{\partial \Lambda}{\partial t} 
		\end{aligned}
	\end{equation}
	Confrontando le due espressioni, otteniamo le \textit{equazioni canoniche di Hamilton}, che costituiscono la versione hamiltoniana delle equazioni del moto:
	\begin{equation}\label{key}
		\begin{cases}
			\dot{q}_k = \dfrac{\partial \mathcal{H}}{\partial p_k}\vspace{2mm}   \\
			
			\dot{p}_k = -\dfrac{\partial \mathcal{H}}{\partial q_k}
		\end{cases}
	\end{equation}
	e anche che, collateralmente,
	\begin{equation}\label{key}
		\dfrac{\partial \mathcal{H}}{\partial t}(q,p) = - \dfrac{\partial \Lambda}{\partial t}(q,\dot{q})
	\end{equation}
	Così se la lagrangiana non dipende esplicitamente dal tempo, neppure l'hamiltoniana ne dipende esplicitamente. 
	\subsection{Principio variazionale con l'hamiltoniana}
	Come possiamo riscrivere il principio di minima azione sfruttando la definizione appena data di Hamiltoniana? Tale principio recita:
	\begin{equation}\label{key}
		\delta \int_{t_A}^{t_B} \Lambda dt = 0
	\end{equation}
	essendo $\mathcal{H} = \dot{q}_k p_k - \Lambda$, allora
	\begin{equation}\label{key}
		\delta \int_{t_A}^{t_B}(\dot{q}_k p_k-\mathcal{H}) dt = 0
	\end{equation}
	In questo caso, però, il dominio su cui si cerca il minimo è un po' diverso (rimane sempre la condizione $q(t_A)=q_A, q(t_B)=q_B$, ma su $p$ non c'è vincolo alcuno). Prendiamo degli incremente sulle variabili della hamiltoniana, $\delta q, \delta p$ e, espandendo con Taylor fino al primo ordine, avremo che
	\begin{equation}\label{key}
		\int_{t_A}^{t_B}\Bigl(\dot{q}dp+p\delta \dot{q} - \dfrac{\partial \mathcal{
				H}}{\partial q}\delta q - \dfrac{\partial \mathcal{
				H}}{\partial p}\delta p\Bigl)dt = 0
	\end{equation}
	Integro per parti:
	\begin{equation}\label{key}
		\int_{t_A}^{t_B}p\delta\dot{q} = (p\delta q)\Bigl|^{t_B}_{t_A}- \int_{t_B}^{t_A}\dot{p}\delta q dt=-\int_{t_B}^{t_A}\dot{p}\delta q dt 
	\end{equation}
	Allora, 
	\begin{equation}\label{key}
		\begin{aligned}
			\delta \int_{t_A}^{t_B}(\dot{q}_k p_k-\mathcal{H}) dt &= \int_{t_A}^{t_B}(\dot{q}\delta p - \dot{p}\delta q - \dfrac{\partial \mathcal{
					H}}{\partial q}\delta q - \dfrac{\partial \mathcal{
					H}}{\partial p}\delta p) = \\
			&= \int_{t_B}^{t_A}\Bigl(-\delta q \Bigl(\dot{p}+\dfrac{\partial \mathcal{H}}{\partial q} \Bigl)+ \delta p \Bigl(\dot{q}-\dfrac{\partial \mathcal{H}}{\partial p}\Bigl)\Bigl)dt = 
			\\ &= 0
		\end{aligned}
	\end{equation}
	Perché questo sia vero per qualsiasi incremento $\delta q, \delta p$, allora otteniamo che 
	\begin{equation}
		\begin{cases}
			\dot{q}_k = \dfrac{\partial \mathcal{H}}{\partial p_k}\vspace{2mm}   \\
			
			\dot{p}_k = -\dfrac{\partial \mathcal{H}}{\partial q_k}
		\end{cases}
	\end{equation}
	che sono proprio le equazioni di Hamilton caratteristiche della meccanica hamiltoniana. Abbiamo confermato, nuovamente, l'equivalenza logica fra principio di minima azione e equazioni di Hamilton.
	
	A questo punto, viene bene un nuovo funzionale $\mathcal{F}$ in termini dell'hamiltoniana che però vive nello spazio delle fasi:
	$$
	\mathcal{F} = \int_{t_A}^{t_B}(p\dot{q}-\mathcal{H}) dt 
	$$
	e le soluzioni fisiche sono caratterizzate da:
	$$
	\delta \mathcal{F}(p,q) = 0
	$$
	Riscriviamo meglio $\mathcal{F}$ moltiplicando per $dt$:
	\begin{equation}\label{key}
		\mathcal{F}(q(t),p(t)) = \int_{A}^{B}(pdq-\mathcal{H}dt)
	\end{equation}
	Cioè l'integrale di una \textit{1-forma differenziale lineare} :
	$$
	\omega = pdq-\mathcal{H}dt
	$$
\end{document}
